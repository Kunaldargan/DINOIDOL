Command Line Args: Namespace(config_file='projects/IDOL/configs/EV18_DINOIDOL_r50.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50171', opts=[])
tcp://127.0.0.1:50171
[05/26 01:40:52 detectron2]: Rank of current process: 0. World size: 1
[05/26 01:40:56 detectron2]: Environment info:
-------------------------------  -------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.10.8 (main, Nov 24 2022, 14:13:03) [GCC 11.2.0]
numpy                            1.23.4
detectron2                       0.6 @/DATA/scratch/kunal/Projects/baselines/video_instance_segmentation/VNEXT_MASKDINO/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 11.5
detectron2 arch flags            8.0
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.2.1 @/home/kunal/anaconda3/envs/DINOIDOL/lib/python3.10/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA A100 80GB PCIe (arch=8.0)
Driver version                   495.29.05
CUDA_HOME                        /usr/local/cuda
Pillow                           9.2.0
torchvision                      0.17.1 @/home/kunal/anaconda3/envs/DINOIDOL/lib/python3.10/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221122
iopath                           0.1.9
cv2                              4.6.0
-------------------------------  -------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.2 (Git Hash 2dc95a2ad0841e29db8b22fbccaf3e5da7992b01)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.2.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[05/26 01:40:56 detectron2]: Command line arguments: Namespace(config_file='projects/IDOL/configs/EV18_DINOIDOL_r50.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50171', opts=[])
[05/26 01:40:56 detectron2]: Contents of args.config_file=projects/IDOL/configs/EV18_DINOIDOL_r50.yaml:
MODEL:
  META_ARCHITECTURE: "DINOIDOL" #"IDOL"
  WEIGHTS: "/home/kunal/scratch/Projects/baselines/video_instance_segmentation/VNext/projects/IDOL/cocopretrain_R50.pth"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: True
  RESNETS:
    DEPTH: 50
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  IDOL:
    NUM_CLASSES: 7
    MULTI_CLS_ON: False
  SEM_SEG_HEAD:
    NAME: "MaskDINOHead"
    IGNORE_VALUE: 255
    NUM_CLASSES: 7
    LOSS_WEIGHT: 1.0
    CONVS_DIM: 256
    MASK_DIM: 256
    NORM: "GN"
    PIXEL_DECODER_NAME: "MaskDINOEncoder"
    DIM_FEEDFORWARD: 1024
    NUM_FEATURE_LEVELS: 3
    TOTAL_NUM_FEATURE_LEVELS: 3
    IN_FEATURES: ["res2", "res3", "res4", "res5"]
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES: ["res3", "res4", "res5"]
    COMMON_STRIDE: 4
    TRANSFORMER_ENC_LAYERS: 6
  MaskDINO:
    TRANSFORMER_DECODER_NAME: "MaskDINODecoder"
    DEEP_SUPERVISION: True
    NO_OBJECT_WEIGHT: 0.1
    CLASS_WEIGHT: 4.0
    MASK_WEIGHT: 5.0
    DICE_WEIGHT: 5.0
    BOX_WEIGHT: 5.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    NUM_OBJECT_QUERIES: 300
    NHEADS: 8
    DROPOUT: 0.0
    DIM_FEEDFORWARD: 2048
    ENC_LAYERS: 0
    PRE_NORM: False
    ENFORCE_INPUT_PROJ: False
    SIZE_DIVISIBILITY: 32
    DEC_LAYERS: 9
    TRAIN_NUM_POINTS: 12544
    OVERSAMPLE_RATIO: 3.0
    IMPORTANCE_SAMPLE_RATIO: 0.75
    INITIAL_PRED: True
    TWO_STAGE: True
    DN: "seg"
    DN_NUM: 100
    INITIALIZE_BOX_TYPE: "bitmask"
    TEST:
      SEMANTIC_ON: False
      INSTANCE_ON: True
      PANOPTIC_ON: False
      OVERLAP_THRESHOLD: 0.8
      OBJECT_MASK_THRESHOLD: 0.25

DATASETS:
  TRAIN: ("endovis_dataset_train",)
  TEST: ("endovis_dataset_val",)


SOLVER:
  IMS_PER_BATCH: 4 #8 #4 #2  #2 #6 #8 #32
  BASE_LR: 0.0001
  STEPS: (8000,)
  MAX_ITER: 12000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  CHECKPOINT_PERIOD: 1000
  
INPUT:
  IMAGE_SIZE: 1024
  MIN_SCALE: 0.1
  MAX_SCALE: 2.0
  SAMPLING_FRAME_NUM: 2
  SAMPLING_FRAME_RANGE:  10
  # MIN_SIZE_TRAIN_SAMPLING : ["range", "choice", "range_by_clip", "choice_by_clip"]
  MIN_SIZE_TRAIN_SAMPLING: "choice_by_clip"
  # RANDOM_FLIP : ["none", "horizontal", "flip_by_clip"]. "horizontal" is set by default.
  RANDOM_FLIP: "flip_by_clip"
  # AUGMENTATIONS: []
  # MIN_SIZE_TRAIN: (360, 480)
  MIN_SIZE_TRAIN: (320, 352, 392, 416, 448, 480, 512, 544, 576, 608, 640)
  MAX_SIZE_TRAIN: 768
  MIN_SIZE_TEST: 480
  CROP:
    ENABLED: False #True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"

DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: True #False
  NUM_WORKERS: 8 #8  #32 #8 #1 #0 #4 #0 #2 #8 #0 #8

VERSION: 2
OUTPUT_DIR: ./ID8L_YTVIS19_twocrop_768_crop_lr1_r1

TEST:
  EVAL_PERIOD: 1000

[05/26 01:40:56 detectron2]: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - endovis_dataset_val
  TRAIN:
  - endovis_dataset_train
Default_loading: true
FIND_UNUSED_PARAMETERS: true
GLOBAL:
  HACK: 1.0
INPUT:
  AUGMENTATIONS: []
  COCO_PRETRAIN: false
  CROP:
    ENABLED: false
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  DATASET_MAPPER_NAME: MaskDINO_semantic
  FORMAT: RGB
  IMAGE_SIZE: 1024
  MASK_FORMAT: polygon
  MAX_SCALE: 2.0
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 768
  MIN_SCALE: 0.1
  MIN_SIZE_TEST: 480
  MIN_SIZE_TRAIN:
  - 320
  - 352
  - 392
  - 416
  - 448
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  MIN_SIZE_TRAIN_SAMPLING: choice_by_clip
  PRETRAIN_SAME_CROP: false
  RANDOM_FLIP: flip_by_clip
  SAMPLING_FRAME_NUM: 2
  SAMPLING_FRAME_RANGE: 10
  SAMPLING_FRAME_SHUFFLE: false
  SAMPLING_INTERVAL: 1
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  IDOL:
    ADD_NEW_SCORE: 0.2
    APPLY_CLS_THRES: 0.05
    BATCH_INFER_LEN: 10
    CLASS_WEIGHT: 2.0
    CLIP_STRIDE: 1
    DEC_LAYERS: 6
    DEC_N_POINTS: 4
    DEEP_SUPERVISION: true
    DICE_WEIGHT: 5.0
    DIM_FEEDFORWARD: 1024
    DROPOUT: 0.1
    ENC_LAYERS: 6
    ENC_N_POINTS: 4
    FOCAL_ALPHA: 0.25
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    INFERENCE_FW: true
    INFERENCE_SELECT_THRES: 0.1
    INFERENCE_TW: true
    L1_WEIGHT: 5.0
    MASK_STRIDE: 4
    MASK_WEIGHT: 2.0
    MATCH_STRIDE: 4
    MEMORY_LEN: 3
    MERGE_ON_CPU: true
    MULTI_CLS_ON: false
    NHEADS: 8
    NMS_PRE: 0.5
    NUM_CLASSES: 7
    NUM_FEATURE_LEVELS: 4
    NUM_OBJECT_QUERIES: 300
    REID_WEIGHT: 2.0
    SET_COST_BOX: 5
    SET_COST_CLASS: 2
    SET_COST_GIOU: 2
    TEMPORAL_SCORE_TYPE: mean
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: true
  META_ARCHITECTURE: DINOIDOL
  MaskDINO:
    BOX_LOSS: true
    BOX_WEIGHT: 5.0
    CLASS_WEIGHT: 4.0
    COST_BOX_WEIGHT: 5.0
    COST_CLASS_WEIGHT: 4.0
    COST_DICE_WEIGHT: 5.0
    COST_GIOU_WEIGHT: 2.0
    COST_MASK_WEIGHT: 5.0
    DEC_LAYERS: 9
    DEEP_SUPERVISION: true
    DICE_WEIGHT: 5.0
    DIM_FEEDFORWARD: 2048
    DN: seg
    DN_NOISE_SCALE: 0.4
    DN_NUM: 100
    DROPOUT: 0.0
    ENC_LAYERS: 0
    ENFORCE_INPUT_PROJ: false
    EVAL_FLAG: 1
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    IMPORTANCE_SAMPLE_RATIO: 0.75
    INITIALIZE_BOX_TYPE: bitmask
    INITIAL_PRED: true
    LEARN_TGT: false
    MASK_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_OBJECT_QUERIES: 300
    OVERSAMPLE_RATIO: 3.0
    PANO_BOX_LOSS: false
    PRED_CONV: false
    PRE_NORM: false
    SEMANTIC_CE_LOSS: false
    SIZE_DIVISIBILITY: 32
    TEST:
      INSTANCE_ON: true
      OBJECT_MASK_THRESHOLD: 0.25
      OVERLAP_THRESHOLD: 0.8
      PANOPTIC_ON: false
      PANO_TEMPERATURE: 0.06
      PANO_TRANSFORM_EVAL: true
      SEMANTIC_ON: false
      SEM_SEG_POSTPROCESSING_BEFORE_INFERENCE: false
      TEST_FOUCUS_ON_BOX: false
    TRAIN_NUM_POINTS: 12544
    TRANSFORMER_DECODER_NAME: MaskDINODecoder
    TWO_STAGE: true
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 256
    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES:
    - res3
    - res4
    - res5
    DEFORMABLE_TRANSFORMER_ENCODER_N_HEADS: 8
    DEFORMABLE_TRANSFORMER_ENCODER_N_POINTS: 4
    DIM_FEEDFORWARD: 1024
    FEATURE_ORDER: high2low
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    LOSS_WEIGHT: 1.0
    MASK_DIM: 256
    NAME: MaskDINOHead
    NORM: GN
    NUM_CLASSES: 7
    NUM_FEATURE_LEVELS: 3
    PIXEL_DECODER_NAME: MaskDINOEncoder
    TOTAL_NUM_FEATURE_LEVELS: 3
    TRANSFORMER_ENC_LAYERS: 6
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    USE_CHECKPOINT: false
    WINDOW_SIZE: 7
  WEIGHTS: /home/kunal/scratch/Projects/baselines/video_instance_segmentation/VNext/projects/IDOL/cocopretrain_R50.pth
OUTPUT_DIR: ./output_EV18
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 12000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 8000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 1000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[05/26 01:40:56 detectron2]: Full config saved to ./output_EV18/config.yaml
[05/26 01:40:56 d2.utils.env]: Using a generated random seed 59489703
False
Inits:  9 LayerNorm((256,), eps=1e-05, elementwise_affine=True) hidden dim: 256 query dim: 4 num_feature_levels: 3 dec_layer_share: False
[05/26 01:40:58 d2.engine.defaults]: Model:
DINOIDOL(
  (detr): CondInst_segm(
    (reid_embed_head): MLP(
      (layers): ModuleList(
        (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): HungarianMatcher()
  )
)
[05/26 01:40:58 d2.projects.idol.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(320, 352, 392, 416, 448, 480, 512, 544, 576, 608, 640), max_size=768, sample_style='choice_by_clip', clip_frame_cnt=2), RandomFlip(clip_frame_cnt=2)]
[05/26 01:40:59 d2.projects.idol.data.datasets.ytvis]: Loading ./datasets/EV18/train.json takes 1.06 seconds.
[05/26 01:40:59 d2.projects.idol.data.datasets.ytvis]: Loaded 11 videos in YTVIS format from ./datasets/EV18/train.json
[05/26 01:40:59 d2.projects.idol.data.build]: Removed 0 images with no usable annotations. 11 images left.
[05/26 01:40:59 d2.projects.idol.data.build]: Using training sampler TrainingSampler
[05/26 01:40:59 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[05/26 01:40:59 d2.data.common]: Serializing 11 elements to byte tensors and concatenating them all ...
[05/26 01:40:59 d2.data.common]: Serialized dataset takes 40.24 MiB
[05/26 01:40:59 d2.data.build]: Making batched data loader with batch_size=4
[05/26 01:40:59 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from /home/kunal/scratch/Projects/baselines/video_instance_segmentation/VNext/projects/IDOL/cocopretrain_R50.pth ...
[05/26 01:40:59 fvcore.common.checkpoint]: [Checkpointer] Loading from /home/kunal/scratch/Projects/baselines/video_instance_segmentation/VNext/projects/IDOL/cocopretrain_R50.pth ...
WARNING [05/26 01:40:59 fvcore.common.checkpoint]: The checkpoint state_dict contains keys that are not used by the model:
  detr.detr.transformer.level_embed
  detr.detr.transformer.encoder.layers.0.self_attn.sampling_offsets.{bias, weight}
  detr.detr.transformer.encoder.layers.0.self_attn.attention_weights.{bias, weight}
  detr.detr.transformer.encoder.layers.0.self_attn.value_proj.{bias, weight}
  detr.detr.transformer.encoder.layers.0.self_attn.output_proj.{bias, weight}
  detr.detr.transformer.encoder.layers.0.norm1.{bias, weight}
  detr.detr.transformer.encoder.layers.0.linear1.{bias, weight}
  detr.detr.transformer.encoder.layers.0.linear2.{bias, weight}
  detr.detr.transformer.encoder.layers.0.norm2.{bias, weight}
  detr.detr.transformer.encoder.layers.1.self_attn.sampling_offsets.{bias, weight}
  detr.detr.transformer.encoder.layers.1.self_attn.attention_weights.{bias, weight}
  detr.detr.transformer.encoder.layers.1.self_attn.value_proj.{bias, weight}
  detr.detr.transformer.encoder.layers.1.self_attn.output_proj.{bias, weight}
  detr.detr.transformer.encoder.layers.1.norm1.{bias, weight}
  detr.detr.transformer.encoder.layers.1.linear1.{bias, weight}
  detr.detr.transformer.encoder.layers.1.linear2.{bias, weight}
  detr.detr.transformer.encoder.layers.1.norm2.{bias, weight}
  detr.detr.transformer.encoder.layers.2.self_attn.sampling_offsets.{bias, weight}
  detr.detr.transformer.encoder.layers.2.self_attn.attention_weights.{bias, weight}
  detr.detr.transformer.encoder.layers.2.self_attn.value_proj.{bias, weight}
  detr.detr.transformer.encoder.layers.2.self_attn.output_proj.{bias, weight}
  detr.detr.transformer.encoder.layers.2.norm1.{bias, weight}
  detr.detr.transformer.encoder.layers.2.linear1.{bias, weight}
  detr.detr.transformer.encoder.layers.2.linear2.{bias, weight}
  detr.detr.transformer.encoder.layers.2.norm2.{bias, weight}
  detr.detr.transformer.encoder.layers.3.self_attn.sampling_offsets.{bias, weight}
  detr.detr.transformer.encoder.layers.3.self_attn.attention_weights.{bias, weight}
  detr.detr.transformer.encoder.layers.3.self_attn.value_proj.{bias, weight}
  detr.detr.transformer.encoder.layers.3.self_attn.output_proj.{bias, weight}
  detr.detr.transformer.encoder.layers.3.norm1.{bias, weight}
  detr.detr.transformer.encoder.layers.3.linear1.{bias, weight}
  detr.detr.transformer.encoder.layers.3.linear2.{bias, weight}
  detr.detr.transformer.encoder.layers.3.norm2.{bias, weight}
  detr.detr.transformer.encoder.layers.4.self_attn.sampling_offsets.{bias, weight}
  detr.detr.transformer.encoder.layers.4.self_attn.attention_weights.{bias, weight}
  detr.detr.transformer.encoder.layers.4.self_attn.value_proj.{bias, weight}
  detr.detr.transformer.encoder.layers.4.self_attn.output_proj.{bias, weight}
  detr.detr.transformer.encoder.layers.4.norm1.{bias, weight}
  detr.detr.transformer.encoder.layers.4.linear1.{bias, weight}
  detr.detr.transformer.encoder.layers.4.linear2.{bias, weight}
  detr.detr.transformer.encoder.layers.4.norm2.{bias, weight}
  detr.detr.transformer.encoder.layers.5.self_attn.sampling_offsets.{bias, weight}
  detr.detr.transformer.encoder.layers.5.self_attn.attention_weights.{bias, weight}
  detr.detr.transformer.encoder.layers.5.self_attn.value_proj.{bias, weight}
  detr.detr.transformer.encoder.layers.5.self_attn.output_proj.{bias, weight}
  detr.detr.transformer.encoder.layers.5.norm1.{bias, weight}
  detr.detr.transformer.encoder.layers.5.linear1.{bias, weight}
  detr.detr.transformer.encoder.layers.5.linear2.{bias, weight}
  detr.detr.transformer.encoder.layers.5.norm2.{bias, weight}
  detr.detr.transformer.decoder.layers.0.cross_attn.sampling_offsets.{bias, weight}
  detr.detr.transformer.decoder.layers.0.cross_attn.attention_weights.{bias, weight}
  detr.detr.transformer.decoder.layers.0.cross_attn.value_proj.{bias, weight}
  detr.detr.transformer.decoder.layers.0.cross_attn.output_proj.{bias, weight}
  detr.detr.transformer.decoder.layers.0.norm1.{bias, weight}
  detr.detr.transformer.decoder.layers.0.self_attn.{in_proj_bias, in_proj_weight}
  detr.detr.transformer.decoder.layers.0.self_attn.out_proj.{bias, weight}
  detr.detr.transformer.decoder.layers.0.norm2.{bias, weight}
  detr.detr.transformer.decoder.layers.0.linear1.{bias, weight}
  detr.detr.transformer.decoder.layers.0.linear2.{bias, weight}
  detr.detr.transformer.decoder.layers.0.norm3.{bias, weight}
  detr.detr.transformer.decoder.layers.1.cross_attn.sampling_offsets.{bias, weight}
  detr.detr.transformer.decoder.layers.1.cross_attn.attention_weights.{bias, weight}
  detr.detr.transformer.decoder.layers.1.cross_attn.value_proj.{bias, weight}
  detr.detr.transformer.decoder.layers.1.cross_attn.output_proj.{bias, weight}
  detr.detr.transformer.decoder.layers.1.norm1.{bias, weight}
  detr.detr.transformer.decoder.layers.1.self_attn.{in_proj_bias, in_proj_weight}
  detr.detr.transformer.decoder.layers.1.self_attn.out_proj.{bias, weight}
  detr.detr.transformer.decoder.layers.1.norm2.{bias, weight}
  detr.detr.transformer.decoder.layers.1.linear1.{bias, weight}
  detr.detr.transformer.decoder.layers.1.linear2.{bias, weight}
  detr.detr.transformer.decoder.layers.1.norm3.{bias, weight}
  detr.detr.transformer.decoder.layers.2.cross_attn.sampling_offsets.{bias, weight}
  detr.detr.transformer.decoder.layers.2.cross_attn.attention_weights.{bias, weight}
  detr.detr.transformer.decoder.layers.2.cross_attn.value_proj.{bias, weight}
  detr.detr.transformer.decoder.layers.2.cross_attn.output_proj.{bias, weight}
  detr.detr.transformer.decoder.layers.2.norm1.{bias, weight}
  detr.detr.transformer.decoder.layers.2.self_attn.{in_proj_bias, in_proj_weight}
  detr.detr.transformer.decoder.layers.2.self_attn.out_proj.{bias, weight}
  detr.detr.transformer.decoder.layers.2.norm2.{bias, weight}
  detr.detr.transformer.decoder.layers.2.linear1.{bias, weight}
  detr.detr.transformer.decoder.layers.2.linear2.{bias, weight}
  detr.detr.transformer.decoder.layers.2.norm3.{bias, weight}
  detr.detr.transformer.decoder.layers.3.cross_attn.sampling_offsets.{bias, weight}
  detr.detr.transformer.decoder.layers.3.cross_attn.attention_weights.{bias, weight}
  detr.detr.transformer.decoder.layers.3.cross_attn.value_proj.{bias, weight}
  detr.detr.transformer.decoder.layers.3.cross_attn.output_proj.{bias, weight}
  detr.detr.transformer.decoder.layers.3.norm1.{bias, weight}
  detr.detr.transformer.decoder.layers.3.self_attn.{in_proj_bias, in_proj_weight}
  detr.detr.transformer.decoder.layers.3.self_attn.out_proj.{bias, weight}
  detr.detr.transformer.decoder.layers.3.norm2.{bias, weight}
  detr.detr.transformer.decoder.layers.3.linear1.{bias, weight}
  detr.detr.transformer.decoder.layers.3.linear2.{bias, weight}
  detr.detr.transformer.decoder.layers.3.norm3.{bias, weight}
  detr.detr.transformer.decoder.layers.4.cross_attn.sampling_offsets.{bias, weight}
  detr.detr.transformer.decoder.layers.4.cross_attn.attention_weights.{bias, weight}
  detr.detr.transformer.decoder.layers.4.cross_attn.value_proj.{bias, weight}
  detr.detr.transformer.decoder.layers.4.cross_attn.output_proj.{bias, weight}
  detr.detr.transformer.decoder.layers.4.norm1.{bias, weight}
  detr.detr.transformer.decoder.layers.4.self_attn.{in_proj_bias, in_proj_weight}
  detr.detr.transformer.decoder.layers.4.self_attn.out_proj.{bias, weight}
  detr.detr.transformer.decoder.layers.4.norm2.{bias, weight}
  detr.detr.transformer.decoder.layers.4.linear1.{bias, weight}
  detr.detr.transformer.decoder.layers.4.linear2.{bias, weight}
  detr.detr.transformer.decoder.layers.4.norm3.{bias, weight}
  detr.detr.transformer.decoder.layers.5.cross_attn.sampling_offsets.{bias, weight}
  detr.detr.transformer.decoder.layers.5.cross_attn.attention_weights.{bias, weight}
  detr.detr.transformer.decoder.layers.5.cross_attn.value_proj.{bias, weight}
  detr.detr.transformer.decoder.layers.5.cross_attn.output_proj.{bias, weight}
  detr.detr.transformer.decoder.layers.5.norm1.{bias, weight}
  detr.detr.transformer.decoder.layers.5.self_attn.{in_proj_bias, in_proj_weight}
  detr.detr.transformer.decoder.layers.5.self_attn.out_proj.{bias, weight}
  detr.detr.transformer.decoder.layers.5.norm2.{bias, weight}
  detr.detr.transformer.decoder.layers.5.linear1.{bias, weight}
  detr.detr.transformer.decoder.layers.5.linear2.{bias, weight}
  detr.detr.transformer.decoder.layers.5.norm3.{bias, weight}
  detr.detr.transformer.decoder.bbox_embed.0.layers.0.{bias, weight}
  detr.detr.transformer.decoder.bbox_embed.0.layers.1.{bias, weight}
  detr.detr.transformer.decoder.bbox_embed.0.layers.2.{bias, weight}
  detr.detr.transformer.decoder.bbox_embed.1.layers.0.{bias, weight}
  detr.detr.transformer.decoder.bbox_embed.1.layers.1.{bias, weight}
  detr.detr.transformer.decoder.bbox_embed.1.layers.2.{bias, weight}
  detr.detr.transformer.decoder.bbox_embed.2.layers.0.{bias, weight}
  detr.detr.transformer.decoder.bbox_embed.2.layers.1.{bias, weight}
  detr.detr.transformer.decoder.bbox_embed.2.layers.2.{bias, weight}
  detr.detr.transformer.decoder.bbox_embed.3.layers.0.{bias, weight}
  detr.detr.transformer.decoder.bbox_embed.3.layers.1.{bias, weight}
  detr.detr.transformer.decoder.bbox_embed.3.layers.2.{bias, weight}
  detr.detr.transformer.decoder.bbox_embed.4.layers.0.{bias, weight}
  detr.detr.transformer.decoder.bbox_embed.4.layers.1.{bias, weight}
  detr.detr.transformer.decoder.bbox_embed.4.layers.2.{bias, weight}
  detr.detr.transformer.decoder.bbox_embed.5.layers.0.{bias, weight}
  detr.detr.transformer.decoder.bbox_embed.5.layers.1.{bias, weight}
  detr.detr.transformer.decoder.bbox_embed.5.layers.2.{bias, weight}
  detr.detr.transformer.reference_points.{bias, weight}
  detr.detr.class_embed.0.{bias, weight}
  detr.detr.class_embed.1.{bias, weight}
  detr.detr.class_embed.2.{bias, weight}
  detr.detr.class_embed.3.{bias, weight}
  detr.detr.class_embed.4.{bias, weight}
  detr.detr.class_embed.5.{bias, weight}
  detr.detr.bbox_embed.0.layers.0.{bias, weight}
  detr.detr.bbox_embed.0.layers.1.{bias, weight}
  detr.detr.bbox_embed.0.layers.2.{bias, weight}
  detr.detr.bbox_embed.1.layers.0.{bias, weight}
  detr.detr.bbox_embed.1.layers.1.{bias, weight}
  detr.detr.bbox_embed.1.layers.2.{bias, weight}
  detr.detr.bbox_embed.2.layers.0.{bias, weight}
  detr.detr.bbox_embed.2.layers.1.{bias, weight}
  detr.detr.bbox_embed.2.layers.2.{bias, weight}
  detr.detr.bbox_embed.3.layers.0.{bias, weight}
  detr.detr.bbox_embed.3.layers.1.{bias, weight}
  detr.detr.bbox_embed.3.layers.2.{bias, weight}
  detr.detr.bbox_embed.4.layers.0.{bias, weight}
  detr.detr.bbox_embed.4.layers.1.{bias, weight}
  detr.detr.bbox_embed.4.layers.2.{bias, weight}
  detr.detr.bbox_embed.5.layers.0.{bias, weight}
  detr.detr.bbox_embed.5.layers.1.{bias, weight}
  detr.detr.bbox_embed.5.layers.2.{bias, weight}
  detr.detr.query_embed.weight
  detr.detr.input_proj.0.0.{bias, weight}
  detr.detr.input_proj.0.1.{bias, weight}
  detr.detr.input_proj.1.0.{bias, weight}
  detr.detr.input_proj.1.1.{bias, weight}
  detr.detr.input_proj.2.0.{bias, weight}
  detr.detr.input_proj.2.1.{bias, weight}
  detr.detr.input_proj.3.0.{bias, weight}
  detr.detr.input_proj.3.1.{bias, weight}
  detr.detr.backbone.0.backbone.stem.conv1.weight
  detr.detr.backbone.0.backbone.stem.conv1.norm.{bias, running_mean, running_var, weight}
  detr.detr.backbone.0.backbone.res2.0.shortcut.weight
  detr.detr.backbone.0.backbone.res2.0.shortcut.norm.{bias, running_mean, running_var, weight}
  detr.detr.backbone.0.backbone.res2.0.conv1.weight
  detr.detr.backbone.0.backbone.res2.0.conv1.norm.{bias, running_mean, running_var, weight}
  detr.detr.backbone.0.backbone.res2.0.conv2.weight
  detr.detr.backbone.0.backbone.res2.0.conv2.norm.{bias, running_mean, running_var, weight}
  detr.detr.backbone.0.backbone.res2.0.conv3.weight
  detr.detr.backbone.0.backbone.res2.0.conv3.norm.{bias, running_mean, running_var, weight}
  detr.detr.backbone.0.backbone.res2.1.conv1.weight
  detr.detr.backbone.0.backbone.res2.1.conv1.norm.{bias, running_mean, running_var, weight}
  detr.detr.backbone.0.backbone.res2.1.conv2.weight
  detr.detr.backbone.0.backbone.res2.1.conv2.norm.{bias, running_mean, running_var, weight}
  detr.detr.backbone.0.backbone.res2.1.conv3.weight
  detr.detr.backbone.0.backbone.res2.1.conv3.norm.{bias, running_mean, running_var, weight}
  detr.detr.backbone.0.backbone.res2.2.conv1.weight
  detr.detr.backbone.0.backbone.res2.2.conv1.norm.{bias, running_mean, running_var, weight}
  detr.detr.backbone.0.backbone.res2.2.conv2.weight
  detr.detr.backbone.0.backbone.res2.2.conv2.norm.{bias, running_mean, running_var, weight}
  detr.detr.backbone.0.backbone.res2.2.conv3.weight
  detr.detr.backbone.0.backbone.res2.2.conv3.norm.{bias, running_mean, running_var, weight}
  detr.detr.backbone.0.backbone.res3.0.shortcut.weight
  detr.detr.backbone.0.backbone.res3.0.shortcut.norm.{bias, running_mean, running_var, weight}
  detr.detr.backbone.0.backbone.res3.0.conv1.weight
  detr.detr.backbone.0.backbone.res3.0.conv1.norm.{bias, running_mean, running_var, weight}
  detr.detr.backbone.0.backbone.res3.0.conv2.weight
  detr.detr.backbone.0.backbone.res3.0.conv2.norm.{bias, running_mean, running_var, weight}
  detr.detr.backbone.0.backbone.res3.0.conv3.weight
  detr.detr.backbone.0.backbone.res3.0.conv3.norm.{bias, running_mean, running_var, weight}
  detr.detr.backbone.0.backbone.res3.1.conv1.weight
  detr.detr.backbone.0.backbone.res3.1.conv1.norm.{bias, running_mean, running_var, weight}
  detr.detr.backbone.0.backbone.res3.1.conv2.weight
  detr.detr.backbone.0.backbone.res3.1.conv2.norm.{bias, running_mean, running_var, weight}
  detr.detr.backbone.0.backbone.res3.1.conv3.weight
  detr.detr.backbone.0.backbone.res3.1.conv3.norm.{bias, running_mean, running_var, weight}
  detr.detr.backbone.0.backbone.res3.2.conv1.weight
  detr.detr.backbone.0.backbone.res3.2.conv1.norm.{bias, running_mean, running_var, weight}
  detr.detr.backbone.0.backbone.res3.2.conv2.weight
  detr.detr.backbone.0.backbone.res3.2.conv2.norm.{bias, running_mean, running_var, weight}
  detr.detr.backbone.0.backbone.res3.2.conv3.weight
  detr.detr.backbone.0.backbone.res3.2.conv3.norm.{bias, running_mean, running_var, weight}
  detr.detr.backbone.0.backbone.res3.3.conv1.weight
  detr.detr.backbone.0.backbone.res3.3.conv1.norm.{bias, running_mean, running_var, weight}
  detr.detr.backbone.0.backbone.res3.3.conv2.weight
  detr.detr.backbone.0.backbone.res3.3.conv2.norm.{bias, running_mean, running_var, weight}
  detr.detr.backbone.0.backbone.res3.3.conv3.weight
  detr.detr.backbone.0.backbone.res3.3.conv3.norm.{bias, running_mean, running_var, weight}
  detr.detr.backbone.0.backbone.res4.0.shortcut.weight
  detr.detr.backbone.0.backbone.res4.0.shortcut.norm.{bias, running_mean, running_var, weight}
  detr.detr.backbone.0.backbone.res4.0.conv1.weight
  detr.detr.backbone.0.backbone.res4.0.conv1.norm.{bias, running_mean, running_var, weight}
  detr.detr.backbone.0.backbone.res4.0.conv2.weight
  detr.detr.backbone.0.backbone.res4.0.conv2.norm.{bias, running_mean, running_var, weight}
  detr.detr.backbone.0.backbone.res4.0.conv3.weight
  detr.detr.backbone.0.backbone.res4.0.conv3.norm.{bias, running_mean, running_var, weight}
  detr.detr.backbone.0.backbone.res4.1.conv1.weight
  detr.detr.backbone.0.backbone.res4.1.conv1.norm.{bias, running_mean, running_var, weight}
  detr.detr.backbone.0.backbone.res4.1.conv2.weight
  detr.detr.backbone.0.backbone.res4.1.conv2.norm.{bias, running_mean, running_var, weight}
  detr.detr.backbone.0.backbone.res4.1.conv3.weight
  detr.detr.backbone.0.backbone.res4.1.conv3.norm.{bias, running_mean, running_var, weight}
  detr.detr.backbone.0.backbone.res4.2.conv1.weight
  detr.detr.backbone.0.backbone.res4.2.conv1.norm.{bias, running_mean, running_var, weight}
  detr.detr.backbone.0.backbone.res4.2.conv2.weight
  detr.detr.backbone.0.backbone.res4.2.conv2.norm.{bias, running_mean, running_var, weight}
  detr.detr.backbone.0.backbone.res4.2.conv3.weight
  detr.detr.backbone.0.backbone.res4.2.conv3.norm.{bias, running_mean, running_var, weight}
  detr.detr.backbone.0.backbone.res4.3.conv1.weight
  detr.detr.backbone.0.backbone.res4.3.conv1.norm.{bias, running_mean, running_var, weight}
  detr.detr.backbone.0.backbone.res4.3.conv2.weight
  detr.detr.backbone.0.backbone.res4.3.conv2.norm.{bias, running_mean, running_var, weight}
  detr.detr.backbone.0.backbone.res4.3.conv3.weight
  detr.detr.backbone.0.backbone.res4.3.conv3.norm.{bias, running_mean, running_var, weight}
  detr.detr.backbone.0.backbone.res4.4.conv1.weight
  detr.detr.backbone.0.backbone.res4.4.conv1.norm.{bias, running_mean, running_var, weight}
  detr.detr.backbone.0.backbone.res4.4.conv2.weight
  detr.detr.backbone.0.backbone.res4.4.conv2.norm.{bias, running_mean, running_var, weight}
  detr.detr.backbone.0.backbone.res4.4.conv3.weight
  detr.detr.backbone.0.backbone.res4.4.conv3.norm.{bias, running_mean, running_var, weight}
  detr.detr.backbone.0.backbone.res4.5.conv1.weight
  detr.detr.backbone.0.backbone.res4.5.conv1.norm.{bias, running_mean, running_var, weight}
  detr.detr.backbone.0.backbone.res4.5.conv2.weight
  detr.detr.backbone.0.backbone.res4.5.conv2.norm.{bias, running_mean, running_var, weight}
  detr.detr.backbone.0.backbone.res4.5.conv3.weight
  detr.detr.backbone.0.backbone.res4.5.conv3.norm.{bias, running_mean, running_var, weight}
  detr.detr.backbone.0.backbone.res5.0.shortcut.weight
  detr.detr.backbone.0.backbone.res5.0.shortcut.norm.{bias, running_mean, running_var, weight}
  detr.detr.backbone.0.backbone.res5.0.conv1.weight
  detr.detr.backbone.0.backbone.res5.0.conv1.norm.{bias, running_mean, running_var, weight}
  detr.detr.backbone.0.backbone.res5.0.conv2.weight
  detr.detr.backbone.0.backbone.res5.0.conv2.norm.{bias, running_mean, running_var, weight}
  detr.detr.backbone.0.backbone.res5.0.conv3.weight
  detr.detr.backbone.0.backbone.res5.0.conv3.norm.{bias, running_mean, running_var, weight}
  detr.detr.backbone.0.backbone.res5.1.conv1.weight
  detr.detr.backbone.0.backbone.res5.1.conv1.norm.{bias, running_mean, running_var, weight}
  detr.detr.backbone.0.backbone.res5.1.conv2.weight
  detr.detr.backbone.0.backbone.res5.1.conv2.norm.{bias, running_mean, running_var, weight}
  detr.detr.backbone.0.backbone.res5.1.conv3.weight
  detr.detr.backbone.0.backbone.res5.1.conv3.norm.{bias, running_mean, running_var, weight}
  detr.detr.backbone.0.backbone.res5.2.conv1.weight
  detr.detr.backbone.0.backbone.res5.2.conv1.norm.{bias, running_mean, running_var, weight}
  detr.detr.backbone.0.backbone.res5.2.conv2.weight
  detr.detr.backbone.0.backbone.res5.2.conv2.norm.{bias, running_mean, running_var, weight}
  detr.detr.backbone.0.backbone.res5.2.conv3.weight
  detr.detr.backbone.0.backbone.res5.2.conv3.norm.{bias, running_mean, running_var, weight}
  detr.controller.layers.0.{bias, weight}
  detr.controller.layers.1.{bias, weight}
  detr.controller.layers.2.{bias, weight}
  detr.mask_head.lay1.{bias, weight}
  detr.mask_head.lay2.{bias, weight}
  detr.mask_head.lay3.{bias, weight}
  detr.mask_head.lay4.{bias, weight}
  detr.mask_head.dcn.{bias, weight}
[05/26 01:40:59 d2.engine.train_loop]: Starting training from iteration 0
/home/kunal/anaconda3/envs/DINOIDOL/lib/python3.10/site-packages/torch/functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025831440/work/aten/src/ATen/native/TensorShape.cpp:3549.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
106
./datasets/EV18/train/JPEGImages/seq14/frame106.png
108
./datasets/EV18/train/JPEGImages/seq14/frame108.png
24
./datasets/EV18/train/JPEGImages/seq3/frame024.png
26
./datasets/EV18/train/JPEGImages/seq3/frame026.png
127
./datasets/EV18/train/JPEGImages/seq11/frame127.png
137
./datasets/EV18/train/JPEGImages/seq11/frame137.png
103
./datasets/EV18/train/JPEGImages/seq10/frame103.png
105
./datasets/EV18/train/JPEGImages/seq10/frame105.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(181.7564, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5246, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7742, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
29
./datasets/EV18/train/JPEGImages/seq6/frame029.png
37
./datasets/EV18/train/JPEGImages/seq6/frame037.png
26
./datasets/EV18/train/JPEGImages/seq12/frame026.png
33
./datasets/EV18/train/JPEGImages/seq12/frame033.png
8
./datasets/EV18/train/JPEGImages/seq4/frame008.png
12
./datasets/EV18/train/JPEGImages/seq4/frame012.png
134
./datasets/EV18/train/JPEGImages/seq7/frame134.png
144
./datasets/EV18/train/JPEGImages/seq7/frame144.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(175.0129, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.6211, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8156, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
94
./datasets/EV18/train/JPEGImages/seq13/frame094.png
97
./datasets/EV18/train/JPEGImages/seq13/frame097.png
126
./datasets/EV18/train/JPEGImages/seq6/frame126.png
127
./datasets/EV18/train/JPEGImages/seq6/frame127.png
137
./datasets/EV18/train/JPEGImages/seq4/frame137.png
141
./datasets/EV18/train/JPEGImages/seq4/frame141.png
65
./datasets/EV18/train/JPEGImages/seq14/frame065.png
67
./datasets/EV18/train/JPEGImages/seq14/frame067.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(149.3422, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.1243, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.6375, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
60
./datasets/EV18/train/JPEGImages/seq7/frame060.png
66
./datasets/EV18/train/JPEGImages/seq7/frame066.png
16
./datasets/EV18/train/JPEGImages/seq1/frame016.png
22
./datasets/EV18/train/JPEGImages/seq1/frame022.png
61
./datasets/EV18/train/JPEGImages/seq11/frame061.png
66
./datasets/EV18/train/JPEGImages/seq11/frame066.png
54
./datasets/EV18/train/JPEGImages/seq13/frame054.png
63
./datasets/EV18/train/JPEGImages/seq13/frame063.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(163.1691, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5550, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7931, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
51
./datasets/EV18/train/JPEGImages/seq1/frame051.png
59
./datasets/EV18/train/JPEGImages/seq1/frame059.png
10
./datasets/EV18/train/JPEGImages/seq10/frame010.png
17
./datasets/EV18/train/JPEGImages/seq10/frame017.png
84
./datasets/EV18/train/JPEGImages/seq7/frame084.png
85
./datasets/EV18/train/JPEGImages/seq7/frame085.png
0
./datasets/EV18/train/JPEGImages/seq16/frame000.png
7
./datasets/EV18/train/JPEGImages/seq16/frame007.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(163.4668, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.7541, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8533, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
92
./datasets/EV18/train/JPEGImages/seq11/frame092.png
95
./datasets/EV18/train/JPEGImages/seq11/frame095.png
135
./datasets/EV18/train/JPEGImages/seq6/frame135.png
141
./datasets/EV18/train/JPEGImages/seq6/frame141.png
69
./datasets/EV18/train/JPEGImages/seq16/frame069.png
74
./datasets/EV18/train/JPEGImages/seq16/frame074.png
105
./datasets/EV18/train/JPEGImages/seq14/frame105.png
107
./datasets/EV18/train/JPEGImages/seq14/frame107.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(117.4005, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.3252, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7252, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
124
./datasets/EV18/train/JPEGImages/seq12/frame124.png
130
./datasets/EV18/train/JPEGImages/seq12/frame130.png
17
./datasets/EV18/train/JPEGImages/seq16/frame017.png
22
./datasets/EV18/train/JPEGImages/seq16/frame022.png
122
./datasets/EV18/train/JPEGImages/seq4/frame122.png
123
./datasets/EV18/train/JPEGImages/seq4/frame123.png
100
./datasets/EV18/train/JPEGImages/seq13/frame100.png
107
./datasets/EV18/train/JPEGImages/seq13/frame107.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(209.4834, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.7896, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8751, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
72
./datasets/EV18/train/JPEGImages/seq3/frame072.png
76
./datasets/EV18/train/JPEGImages/seq3/frame076.png
119
./datasets/EV18/train/JPEGImages/seq12/frame119.png
123
./datasets/EV18/train/JPEGImages/seq12/frame123.png
91
./datasets/EV18/train/JPEGImages/seq10/frame091.png
98
./datasets/EV18/train/JPEGImages/seq10/frame098.png
98
./datasets/EV18/train/JPEGImages/seq1/frame098.png
106
./datasets/EV18/train/JPEGImages/seq1/frame106.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(156.8782, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.6737, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8038, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
32
./datasets/EV18/train/JPEGImages/seq3/frame032.png
41
./datasets/EV18/train/JPEGImages/seq3/frame041.png
41
./datasets/EV18/train/JPEGImages/seq7/frame041.png
42
./datasets/EV18/train/JPEGImages/seq7/frame042.png
60
./datasets/EV18/train/JPEGImages/seq11/frame060.png
66
./datasets/EV18/train/JPEGImages/seq11/frame066.png
40
./datasets/EV18/train/JPEGImages/seq12/frame040.png
46
./datasets/EV18/train/JPEGImages/seq12/frame046.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(182.0179, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.2988, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.6973, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
2
./datasets/EV18/train/JPEGImages/seq1/frame002.png
6
./datasets/EV18/train/JPEGImages/seq1/frame006.png
72
./datasets/EV18/train/JPEGImages/seq11/frame072.png
76
./datasets/EV18/train/JPEGImages/seq11/frame076.png
24
./datasets/EV18/train/JPEGImages/seq14/frame024.png
29
./datasets/EV18/train/JPEGImages/seq14/frame029.png
83
./datasets/EV18/train/JPEGImages/seq10/frame083.png
85
./datasets/EV18/train/JPEGImages/seq10/frame085.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(186.4205, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.7790, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8741, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
109
./datasets/EV18/train/JPEGImages/seq10/frame109.png
113
./datasets/EV18/train/JPEGImages/seq10/frame113.png
108
./datasets/EV18/train/JPEGImages/seq13/frame108.png
114
./datasets/EV18/train/JPEGImages/seq13/frame114.png
71
./datasets/EV18/train/JPEGImages/seq14/frame071.png
78
./datasets/EV18/train/JPEGImages/seq14/frame078.png
63
./datasets/EV18/train/JPEGImages/seq16/frame063.png
68
./datasets/EV18/train/JPEGImages/seq16/frame068.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(200.3967, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.6180, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8370, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
84
./datasets/EV18/train/JPEGImages/seq10/frame084.png
85
./datasets/EV18/train/JPEGImages/seq10/frame085.png
123
./datasets/EV18/train/JPEGImages/seq13/frame123.png
131
./datasets/EV18/train/JPEGImages/seq13/frame131.png
8
./datasets/EV18/train/JPEGImages/seq12/frame008.png
17
./datasets/EV18/train/JPEGImages/seq12/frame017.png
65
./datasets/EV18/train/JPEGImages/seq7/frame065.png
67
./datasets/EV18/train/JPEGImages/seq7/frame067.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(155.7805, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.4120, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7368, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
75
./datasets/EV18/train/JPEGImages/seq6/frame075.png
77
./datasets/EV18/train/JPEGImages/seq6/frame077.png
33
./datasets/EV18/train/JPEGImages/seq1/frame033.png
43
./datasets/EV18/train/JPEGImages/seq1/frame043.png
17
./datasets/EV18/train/JPEGImages/seq12/frame017.png
22
./datasets/EV18/train/JPEGImages/seq12/frame022.png
20
./datasets/EV18/train/JPEGImages/seq4/frame020.png
29
./datasets/EV18/train/JPEGImages/seq4/frame029.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(109.8560, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.3459, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7227, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
28
./datasets/EV18/train/JPEGImages/seq14/frame028.png
33
./datasets/EV18/train/JPEGImages/seq14/frame033.png
14
./datasets/EV18/train/JPEGImages/seq3/frame014.png
23
./datasets/EV18/train/JPEGImages/seq3/frame023.png
96
./datasets/EV18/train/JPEGImages/seq6/frame096.png
106
./datasets/EV18/train/JPEGImages/seq6/frame106.png
84
./datasets/EV18/train/JPEGImages/seq1/frame084.png
93
./datasets/EV18/train/JPEGImages/seq1/frame093.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(146.6551, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.8005, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8652, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
70
./datasets/EV18/train/JPEGImages/seq4/frame070.png
71
./datasets/EV18/train/JPEGImages/seq4/frame071.png
51
./datasets/EV18/train/JPEGImages/seq3/frame051.png
54
./datasets/EV18/train/JPEGImages/seq3/frame054.png
13
./datasets/EV18/train/JPEGImages/seq16/frame013.png
16
./datasets/EV18/train/JPEGImages/seq16/frame016.png
114
./datasets/EV18/train/JPEGImages/seq6/frame114.png
121
./datasets/EV18/train/JPEGImages/seq6/frame121.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(125.4836, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.6432, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8241, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
57
./datasets/EV18/train/JPEGImages/seq7/frame057.png
65
./datasets/EV18/train/JPEGImages/seq7/frame065.png
62
./datasets/EV18/train/JPEGImages/seq16/frame062.png
70
./datasets/EV18/train/JPEGImages/seq16/frame070.png
56
./datasets/EV18/train/JPEGImages/seq11/frame056.png
58
./datasets/EV18/train/JPEGImages/seq11/frame058.png
85
./datasets/EV18/train/JPEGImages/seq3/frame085.png
87
./datasets/EV18/train/JPEGImages/seq3/frame087.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(207.2991, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5529, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7809, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
22
./datasets/EV18/train/JPEGImages/seq13/frame022.png
29
./datasets/EV18/train/JPEGImages/seq13/frame029.png
9
./datasets/EV18/train/JPEGImages/seq4/frame009.png
15
./datasets/EV18/train/JPEGImages/seq4/frame015.png
107
./datasets/EV18/train/JPEGImages/seq13/frame107.png
109
./datasets/EV18/train/JPEGImages/seq13/frame109.png
4
./datasets/EV18/train/JPEGImages/seq14/frame004.png
12
./datasets/EV18/train/JPEGImages/seq14/frame012.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(117.7496, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.4341, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7709, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
70
./datasets/EV18/train/JPEGImages/seq7/frame070.png
71
./datasets/EV18/train/JPEGImages/seq7/frame071.png
144
./datasets/EV18/train/JPEGImages/seq10/frame144.png
146
./datasets/EV18/train/JPEGImages/seq10/frame146.png
61
./datasets/EV18/train/JPEGImages/seq3/frame061.png
68
./datasets/EV18/train/JPEGImages/seq3/frame068.png
81
./datasets/EV18/train/JPEGImages/seq4/frame081.png
88
./datasets/EV18/train/JPEGImages/seq4/frame088.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(143.1306, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.4656, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7535, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
13
./datasets/EV18/train/JPEGImages/seq4/frame013.png
22
./datasets/EV18/train/JPEGImages/seq4/frame022.png
59
./datasets/EV18/train/JPEGImages/seq1/frame059.png
62
./datasets/EV18/train/JPEGImages/seq1/frame062.png
97
./datasets/EV18/train/JPEGImages/seq3/frame097.png
100
./datasets/EV18/train/JPEGImages/seq3/frame100.png
127
./datasets/EV18/train/JPEGImages/seq6/frame127.png
136
./datasets/EV18/train/JPEGImages/seq6/frame136.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(118.9407, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5169, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7475, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
10
./datasets/EV18/train/JPEGImages/seq12/frame010.png
15
./datasets/EV18/train/JPEGImages/seq12/frame015.png
131
./datasets/EV18/train/JPEGImages/seq14/frame131.png
134
./datasets/EV18/train/JPEGImages/seq14/frame134.png
141
./datasets/EV18/train/JPEGImages/seq1/frame141.png
144
./datasets/EV18/train/JPEGImages/seq1/frame144.png
11
./datasets/EV18/train/JPEGImages/seq7/frame011.png
19
./datasets/EV18/train/JPEGImages/seq7/frame019.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(170.1549, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.6420, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8329, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
[05/26 01:41:29 d2.utils.events]:  eta: 3:57:47  iter: 19  total_loss: 2292  loss_ce: 226.9  loss_bbox: 1.688  loss_giou: 0.8516  loss_mask: 1.445  loss_dice: 0.9503  loss_ce_dn: 1.831  loss_mask_dn: 1.434  loss_dice_dn: 0.9504  loss_bbox_dn: 0.221  loss_giou_dn: 0.4241  loss_ce_0: 210.7  loss_mask_0: 0.8157  loss_dice_0: 0.9168  loss_bbox_0: 1.686  loss_giou_0: 0.8519  loss_ce_dn_0: 1.111  loss_mask_dn_0: 1.133  loss_dice_dn_0: 0.9349  loss_bbox_dn_0: 0.221  loss_giou_dn_0: 0.4241  loss_ce_1: 187  loss_mask_1: 0.7542  loss_dice_1: 0.9337  loss_bbox_1: 1.725  loss_giou_1: 0.8448  loss_ce_dn_1: 1.137  loss_mask_dn_1: 1.049  loss_dice_dn_1: 0.9366  loss_bbox_dn_1: 0.221  loss_giou_dn_1: 0.4241  loss_ce_2: 144.6  loss_mask_2: 0.8003  loss_dice_2: 0.9237  loss_bbox_2: 1.704  loss_giou_2: 0.845  loss_ce_dn_2: 1.085  loss_mask_dn_2: 0.9958  loss_dice_dn_2: 0.9203  loss_bbox_dn_2: 0.221  loss_giou_dn_2: 0.4241  loss_ce_3: 228.4  loss_mask_3: 0.7509  loss_dice_3: 0.913  loss_bbox_3: 1.7  loss_giou_3: 0.8521  loss_ce_dn_3: 1.801  loss_mask_dn_3: 0.9082  loss_dice_dn_3: 0.9161  loss_bbox_dn_3: 0.221  loss_giou_dn_3: 0.4241  loss_ce_4: 143.1  loss_mask_4: 0.9009  loss_dice_4: 0.9216  loss_bbox_4: 1.697  loss_giou_4: 0.8522  loss_ce_dn_4: 1.206  loss_mask_dn_4: 1.077  loss_dice_dn_4: 0.9237  loss_bbox_dn_4: 0.221  loss_giou_dn_4: 0.4241  loss_ce_5: 217.1  loss_mask_5: 0.7197  loss_dice_5: 0.9191  loss_bbox_5: 1.679  loss_giou_5: 0.852  loss_ce_dn_5: 2.002  loss_mask_dn_5: 0.7691  loss_dice_dn_5: 0.9386  loss_bbox_dn_5: 0.221  loss_giou_dn_5: 0.4241  loss_ce_6: 142.4  loss_mask_6: 0.821  loss_dice_6: 0.9355  loss_bbox_6: 1.679  loss_giou_6: 0.8521  loss_ce_dn_6: 1.338  loss_mask_dn_6: 0.8833  loss_dice_dn_6: 0.9348  loss_bbox_dn_6: 0.221  loss_giou_dn_6: 0.4241  loss_ce_7: 234.1  loss_mask_7: 0.8841  loss_dice_7: 0.9352  loss_bbox_7: 1.697  loss_giou_7: 0.8448  loss_ce_dn_7: 1.947  loss_mask_dn_7: 0.9124  loss_dice_dn_7: 0.9293  loss_bbox_dn_7: 0.221  loss_giou_dn_7: 0.4241  loss_ce_8: 232.3  loss_mask_8: 1.178  loss_dice_8: 0.9349  loss_bbox_8: 1.682  loss_giou_8: 0.8522  loss_ce_dn_8: 2.017  loss_mask_dn_8: 1.206  loss_dice_dn_8: 0.9298  loss_bbox_dn_8: 0.221  loss_giou_dn_8: 0.4241  loss_ce_interm: 210.8  loss_mask_interm: 0.9489  loss_dice_interm: 0.9267  loss_bbox_interm: 0.7004  loss_giou_interm: 1.076    time: 1.1891  last_time: 1.1885  data_time: 0.0966  last_data_time: 0.0114   lr: 0.0001  max_mem: 18701M
113
./datasets/EV18/train/JPEGImages/seq10/frame113.png
117
./datasets/EV18/train/JPEGImages/seq10/frame117.png
137
./datasets/EV18/train/JPEGImages/seq6/frame137.png
145
./datasets/EV18/train/JPEGImages/seq6/frame145.png
105
./datasets/EV18/train/JPEGImages/seq16/frame105.png
106
./datasets/EV18/train/JPEGImages/seq16/frame106.png
93
./datasets/EV18/train/JPEGImages/seq13/frame093.png
97
./datasets/EV18/train/JPEGImages/seq13/frame097.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(161.0827, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5784, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7983, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
35
./datasets/EV18/train/JPEGImages/seq16/frame035.png
41
./datasets/EV18/train/JPEGImages/seq16/frame041.png
25
./datasets/EV18/train/JPEGImages/seq11/frame025.png
27
./datasets/EV18/train/JPEGImages/seq11/frame027.png
20
./datasets/EV18/train/JPEGImages/seq10/frame020.png
21
./datasets/EV18/train/JPEGImages/seq10/frame021.png
36
./datasets/EV18/train/JPEGImages/seq16/frame036.png
46
./datasets/EV18/train/JPEGImages/seq16/frame046.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(219.0611, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.7323, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8562, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
4
./datasets/EV18/train/JPEGImages/seq7/frame004.png
5
./datasets/EV18/train/JPEGImages/seq7/frame005.png
50
./datasets/EV18/train/JPEGImages/seq11/frame050.png
60
./datasets/EV18/train/JPEGImages/seq11/frame060.png
34
./datasets/EV18/train/JPEGImages/seq12/frame034.png
43
./datasets/EV18/train/JPEGImages/seq12/frame043.png
116
./datasets/EV18/train/JPEGImages/seq1/frame116.png
122
./datasets/EV18/train/JPEGImages/seq1/frame122.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(117.6883, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.1900, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.6568, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
108
./datasets/EV18/train/JPEGImages/seq4/frame108.png
116
./datasets/EV18/train/JPEGImages/seq4/frame116.png
133
./datasets/EV18/train/JPEGImages/seq3/frame133.png
134
./datasets/EV18/train/JPEGImages/seq3/frame134.png
142
./datasets/EV18/train/JPEGImages/seq6/frame142.png
144
./datasets/EV18/train/JPEGImages/seq6/frame144.png
10
./datasets/EV18/train/JPEGImages/seq12/frame010.png
18
./datasets/EV18/train/JPEGImages/seq12/frame018.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(125.1198, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.2403, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.6841, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
6
./datasets/EV18/train/JPEGImages/seq14/frame006.png
8
./datasets/EV18/train/JPEGImages/seq14/frame008.png
140
./datasets/EV18/train/JPEGImages/seq12/frame140.png
143
./datasets/EV18/train/JPEGImages/seq12/frame143.png
33
./datasets/EV18/train/JPEGImages/seq7/frame033.png
43
./datasets/EV18/train/JPEGImages/seq7/frame043.png
90
./datasets/EV18/train/JPEGImages/seq14/frame090.png
93
./datasets/EV18/train/JPEGImages/seq14/frame093.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(157.0073, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.4905, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7852, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
13
./datasets/EV18/train/JPEGImages/seq6/frame013.png
20
./datasets/EV18/train/JPEGImages/seq6/frame020.png
89
./datasets/EV18/train/JPEGImages/seq1/frame089.png
91
./datasets/EV18/train/JPEGImages/seq1/frame091.png
107
./datasets/EV18/train/JPEGImages/seq4/frame107.png
108
./datasets/EV18/train/JPEGImages/seq4/frame108.png
117
./datasets/EV18/train/JPEGImages/seq11/frame117.png
119
./datasets/EV18/train/JPEGImages/seq11/frame119.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(99.4394, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5779, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7784, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
100
./datasets/EV18/train/JPEGImages/seq11/frame100.png
104
./datasets/EV18/train/JPEGImages/seq11/frame104.png
28
./datasets/EV18/train/JPEGImages/seq1/frame028.png
32
./datasets/EV18/train/JPEGImages/seq1/frame032.png
80
./datasets/EV18/train/JPEGImages/seq3/frame080.png
83
./datasets/EV18/train/JPEGImages/seq3/frame083.png
56
./datasets/EV18/train/JPEGImages/seq16/frame056.png
60
./datasets/EV18/train/JPEGImages/seq16/frame060.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(188.0844, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.6792, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8583, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
15
./datasets/EV18/train/JPEGImages/seq16/frame015.png
18
./datasets/EV18/train/JPEGImages/seq16/frame018.png
17
./datasets/EV18/train/JPEGImages/seq11/frame017.png
20
./datasets/EV18/train/JPEGImages/seq11/frame020.png
22
./datasets/EV18/train/JPEGImages/seq10/frame022.png
27
./datasets/EV18/train/JPEGImages/seq10/frame027.png
145
./datasets/EV18/train/JPEGImages/seq16/frame145.png
147
./datasets/EV18/train/JPEGImages/seq16/frame147.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(163.0474, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5499, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7866, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
37
./datasets/EV18/train/JPEGImages/seq13/frame037.png
44
./datasets/EV18/train/JPEGImages/seq13/frame044.png
70
./datasets/EV18/train/JPEGImages/seq13/frame070.png
78
./datasets/EV18/train/JPEGImages/seq13/frame078.png
89
./datasets/EV18/train/JPEGImages/seq4/frame089.png
97
./datasets/EV18/train/JPEGImages/seq4/frame097.png
94
./datasets/EV18/train/JPEGImages/seq14/frame094.png
102
./datasets/EV18/train/JPEGImages/seq14/frame102.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(138.0603, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.4355, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7726, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
49
./datasets/EV18/train/JPEGImages/seq7/frame049.png
59
./datasets/EV18/train/JPEGImages/seq7/frame059.png
44
./datasets/EV18/train/JPEGImages/seq12/frame044.png
45
./datasets/EV18/train/JPEGImages/seq12/frame045.png
14
./datasets/EV18/train/JPEGImages/seq7/frame014.png
16
./datasets/EV18/train/JPEGImages/seq7/frame016.png
81
./datasets/EV18/train/JPEGImages/seq13/frame081.png
84
./datasets/EV18/train/JPEGImages/seq13/frame084.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(181.7257, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.2441, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.6740, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
42
./datasets/EV18/train/JPEGImages/seq11/frame042.png
45
./datasets/EV18/train/JPEGImages/seq11/frame045.png
99
./datasets/EV18/train/JPEGImages/seq10/frame099.png
101
./datasets/EV18/train/JPEGImages/seq10/frame101.png
93
./datasets/EV18/train/JPEGImages/seq6/frame093.png
103
./datasets/EV18/train/JPEGImages/seq6/frame103.png
117
./datasets/EV18/train/JPEGImages/seq13/frame117.png
119
./datasets/EV18/train/JPEGImages/seq13/frame119.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(160.1142, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.4009, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7570, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
73
./datasets/EV18/train/JPEGImages/seq3/frame073.png
83
./datasets/EV18/train/JPEGImages/seq3/frame083.png
74
./datasets/EV18/train/JPEGImages/seq10/frame074.png
80
./datasets/EV18/train/JPEGImages/seq10/frame080.png
51
./datasets/EV18/train/JPEGImages/seq6/frame051.png
60
./datasets/EV18/train/JPEGImages/seq6/frame060.png
17
./datasets/EV18/train/JPEGImages/seq12/frame017.png
24
./datasets/EV18/train/JPEGImages/seq12/frame024.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(202.8776, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5667, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8294, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
15
./datasets/EV18/train/JPEGImages/seq1/frame015.png
16
./datasets/EV18/train/JPEGImages/seq1/frame016.png
42
./datasets/EV18/train/JPEGImages/seq12/frame042.png
48
./datasets/EV18/train/JPEGImages/seq12/frame048.png
110
./datasets/EV18/train/JPEGImages/seq10/frame110.png
111
./datasets/EV18/train/JPEGImages/seq10/frame111.png
79
./datasets/EV18/train/JPEGImages/seq13/frame079.png
89
./datasets/EV18/train/JPEGImages/seq13/frame089.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(142.3194, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.4077, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7116, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
15
./datasets/EV18/train/JPEGImages/seq7/frame015.png
17
./datasets/EV18/train/JPEGImages/seq7/frame017.png
60
./datasets/EV18/train/JPEGImages/seq4/frame060.png
67
./datasets/EV18/train/JPEGImages/seq4/frame067.png
39
./datasets/EV18/train/JPEGImages/seq1/frame039.png
44
./datasets/EV18/train/JPEGImages/seq1/frame044.png
106
./datasets/EV18/train/JPEGImages/seq16/frame106.png
115
./datasets/EV18/train/JPEGImages/seq16/frame115.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(137.8599, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.3104, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7139, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
28
./datasets/EV18/train/JPEGImages/seq3/frame028.png
38
./datasets/EV18/train/JPEGImages/seq3/frame038.png
114
./datasets/EV18/train/JPEGImages/seq11/frame114.png
118
./datasets/EV18/train/JPEGImages/seq11/frame118.png
68
./datasets/EV18/train/JPEGImages/seq16/frame068.png
71
./datasets/EV18/train/JPEGImages/seq16/frame071.png
12
./datasets/EV18/train/JPEGImages/seq7/frame012.png
14
./datasets/EV18/train/JPEGImages/seq7/frame014.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(146.7873, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.2690, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.6976, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
33
./datasets/EV18/train/JPEGImages/seq14/frame033.png
37
./datasets/EV18/train/JPEGImages/seq14/frame037.png
71
./datasets/EV18/train/JPEGImages/seq3/frame071.png
76
./datasets/EV18/train/JPEGImages/seq3/frame076.png
14
./datasets/EV18/train/JPEGImages/seq12/frame014.png
15
./datasets/EV18/train/JPEGImages/seq12/frame015.png
12
./datasets/EV18/train/JPEGImages/seq7/frame012.png
17
./datasets/EV18/train/JPEGImages/seq7/frame017.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(156.8279, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5316, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7930, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
25
./datasets/EV18/train/JPEGImages/seq14/frame025.png
29
./datasets/EV18/train/JPEGImages/seq14/frame029.png
30
./datasets/EV18/train/JPEGImages/seq1/frame030.png
32
./datasets/EV18/train/JPEGImages/seq1/frame032.png
20
./datasets/EV18/train/JPEGImages/seq14/frame020.png
26
./datasets/EV18/train/JPEGImages/seq14/frame026.png
55
./datasets/EV18/train/JPEGImages/seq4/frame055.png
62
./datasets/EV18/train/JPEGImages/seq4/frame062.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(75.5144, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.2579, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.6943, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
116
./datasets/EV18/train/JPEGImages/seq11/frame116.png
121
./datasets/EV18/train/JPEGImages/seq11/frame121.png
24
./datasets/EV18/train/JPEGImages/seq6/frame024.png
26
./datasets/EV18/train/JPEGImages/seq6/frame026.png
101
./datasets/EV18/train/JPEGImages/seq4/frame101.png
103
./datasets/EV18/train/JPEGImages/seq4/frame103.png
0
./datasets/EV18/train/JPEGImages/seq12/frame000.png
9
./datasets/EV18/train/JPEGImages/seq12/frame009.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(125.3558, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5305, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7634, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
1
./datasets/EV18/train/JPEGImages/seq4/frame001.png
2
./datasets/EV18/train/JPEGImages/seq4/frame002.png
99
./datasets/EV18/train/JPEGImages/seq6/frame099.png
100
./datasets/EV18/train/JPEGImages/seq6/frame100.png
77
./datasets/EV18/train/JPEGImages/seq3/frame077.png
81
./datasets/EV18/train/JPEGImages/seq3/frame081.png
14
./datasets/EV18/train/JPEGImages/seq10/frame014.png
19
./datasets/EV18/train/JPEGImages/seq10/frame019.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(125.6039, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.4836, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7650, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
89
./datasets/EV18/train/JPEGImages/seq16/frame089.png
90
./datasets/EV18/train/JPEGImages/seq16/frame090.png
43
./datasets/EV18/train/JPEGImages/seq13/frame043.png
47
./datasets/EV18/train/JPEGImages/seq13/frame047.png
136
./datasets/EV18/train/JPEGImages/seq11/frame136.png
141
./datasets/EV18/train/JPEGImages/seq11/frame141.png
28
./datasets/EV18/train/JPEGImages/seq6/frame028.png
30
./datasets/EV18/train/JPEGImages/seq6/frame030.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(138.9726, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.4093, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7388, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
[05/26 01:41:52 d2.utils.events]:  eta: 3:57:10  iter: 39  total_loss: 2345  loss_ce: 235.9  loss_bbox: 1.597  loss_giou: 0.8198  loss_mask: 1.456  loss_dice: 0.9528  loss_ce_dn: 1.631  loss_mask_dn: 1.472  loss_dice_dn: 0.9535  loss_bbox_dn: 0.2431  loss_giou_dn: 0.4259  loss_ce_0: 218.2  loss_mask_0: 0.8238  loss_dice_0: 0.928  loss_bbox_0: 1.603  loss_giou_0: 0.8216  loss_ce_dn_0: 1.015  loss_mask_dn_0: 1.142  loss_dice_dn_0: 0.933  loss_bbox_dn_0: 0.2431  loss_giou_dn_0: 0.4259  loss_ce_1: 191.1  loss_mask_1: 0.7629  loss_dice_1: 0.9321  loss_bbox_1: 1.62  loss_giou_1: 0.8177  loss_ce_dn_1: 1.029  loss_mask_dn_1: 1.051  loss_dice_dn_1: 0.9377  loss_bbox_dn_1: 0.2431  loss_giou_dn_1: 0.4259  loss_ce_2: 149.9  loss_mask_2: 0.8091  loss_dice_2: 0.9155  loss_bbox_2: 1.62  loss_giou_2: 0.8181  loss_ce_dn_2: 0.9821  loss_mask_dn_2: 0.9924  loss_dice_dn_2: 0.9231  loss_bbox_dn_2: 0.2431  loss_giou_dn_2: 0.4259  loss_ce_3: 228  loss_mask_3: 0.7539  loss_dice_3: 0.9016  loss_bbox_3: 1.605  loss_giou_3: 0.8174  loss_ce_dn_3: 1.534  loss_mask_dn_3: 0.8743  loss_dice_dn_3: 0.9028  loss_bbox_dn_3: 0.2431  loss_giou_dn_3: 0.4259  loss_ce_4: 142.5  loss_mask_4: 0.8916  loss_dice_4: 0.9093  loss_bbox_4: 1.604  loss_giou_4: 0.8178  loss_ce_dn_4: 1.075  loss_mask_dn_4: 1.052  loss_dice_dn_4: 0.9164  loss_bbox_dn_4: 0.2431  loss_giou_dn_4: 0.4259  loss_ce_5: 225.8  loss_mask_5: 0.7259  loss_dice_5: 0.9102  loss_bbox_5: 1.595  loss_giou_5: 0.8166  loss_ce_dn_5: 1.75  loss_mask_dn_5: 0.7643  loss_dice_dn_5: 0.9298  loss_bbox_dn_5: 0.2431  loss_giou_dn_5: 0.4259  loss_ce_6: 146.1  loss_mask_6: 0.8267  loss_dice_6: 0.9359  loss_bbox_6: 1.6  loss_giou_6: 0.8167  loss_ce_dn_6: 1.24  loss_mask_dn_6: 0.8921  loss_dice_dn_6: 0.9328  loss_bbox_dn_6: 0.2431  loss_giou_dn_6: 0.4259  loss_ce_7: 237.2  loss_mask_7: 0.8971  loss_dice_7: 0.9367  loss_bbox_7: 1.594  loss_giou_7: 0.8179  loss_ce_dn_7: 1.746  loss_mask_dn_7: 0.9085  loss_dice_dn_7: 0.9308  loss_bbox_dn_7: 0.2431  loss_giou_dn_7: 0.4259  loss_ce_8: 244.1  loss_mask_8: 1.19  loss_dice_8: 0.9308  loss_bbox_8: 1.601  loss_giou_8: 0.8196  loss_ce_dn_8: 1.848  loss_mask_dn_8: 1.198  loss_dice_dn_8: 0.9206  loss_bbox_dn_8: 0.2431  loss_giou_dn_8: 0.4259  loss_ce_interm: 218.3  loss_mask_interm: 0.9127  loss_dice_interm: 0.9425  loss_bbox_interm: 0.7182  loss_giou_interm: 1.02    time: 1.1747  last_time: 1.2182  data_time: 0.0129  last_data_time: 0.0118   lr: 0.0001  max_mem: 18844M
2
./datasets/EV18/train/JPEGImages/seq13/frame002.png
11
./datasets/EV18/train/JPEGImages/seq13/frame011.png
103
./datasets/EV18/train/JPEGImages/seq10/frame103.png
108
./datasets/EV18/train/JPEGImages/seq10/frame108.png
89
./datasets/EV18/train/JPEGImages/seq11/frame089.png
95
./datasets/EV18/train/JPEGImages/seq11/frame095.png
103
./datasets/EV18/train/JPEGImages/seq13/frame103.png
106
./datasets/EV18/train/JPEGImages/seq13/frame106.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(191.8187, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.4248, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7886, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
19
./datasets/EV18/train/JPEGImages/seq16/frame019.png
28
./datasets/EV18/train/JPEGImages/seq16/frame028.png
1
./datasets/EV18/train/JPEGImages/seq3/frame001.png
9
./datasets/EV18/train/JPEGImages/seq3/frame009.png
75
./datasets/EV18/train/JPEGImages/seq4/frame075.png
80
./datasets/EV18/train/JPEGImages/seq4/frame080.png
50
./datasets/EV18/train/JPEGImages/seq3/frame050.png
59
./datasets/EV18/train/JPEGImages/seq3/frame059.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(137.9274, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.4472, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7482, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
86
./datasets/EV18/train/JPEGImages/seq3/frame086.png
88
./datasets/EV18/train/JPEGImages/seq3/frame088.png
82
./datasets/EV18/train/JPEGImages/seq14/frame082.png
86
./datasets/EV18/train/JPEGImages/seq14/frame086.png
138
./datasets/EV18/train/JPEGImages/seq6/frame138.png
140
./datasets/EV18/train/JPEGImages/seq6/frame140.png
25
./datasets/EV18/train/JPEGImages/seq4/frame025.png
26
./datasets/EV18/train/JPEGImages/seq4/frame026.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(145.5618, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5443, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7924, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
144
./datasets/EV18/train/JPEGImages/seq10/frame144.png
147
./datasets/EV18/train/JPEGImages/seq10/frame147.png
32
./datasets/EV18/train/JPEGImages/seq11/frame032.png
38
./datasets/EV18/train/JPEGImages/seq11/frame038.png
111
./datasets/EV18/train/JPEGImages/seq7/frame111.png
119
./datasets/EV18/train/JPEGImages/seq7/frame119.png
32
./datasets/EV18/train/JPEGImages/seq6/frame032.png
34
./datasets/EV18/train/JPEGImages/seq6/frame034.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(187.4943, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.6569, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8024, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
29
./datasets/EV18/train/JPEGImages/seq14/frame029.png
35
./datasets/EV18/train/JPEGImages/seq14/frame035.png
118
./datasets/EV18/train/JPEGImages/seq10/frame118.png
123
./datasets/EV18/train/JPEGImages/seq10/frame123.png
130
./datasets/EV18/train/JPEGImages/seq7/frame130.png
133
./datasets/EV18/train/JPEGImages/seq7/frame133.png
64
./datasets/EV18/train/JPEGImages/seq12/frame064.png
69
./datasets/EV18/train/JPEGImages/seq12/frame069.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(174.0817, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5197, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7971, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
9
./datasets/EV18/train/JPEGImages/seq1/frame009.png
18
./datasets/EV18/train/JPEGImages/seq1/frame018.png
108
./datasets/EV18/train/JPEGImages/seq12/frame108.png
116
./datasets/EV18/train/JPEGImages/seq12/frame116.png
74
./datasets/EV18/train/JPEGImages/seq14/frame074.png
81
./datasets/EV18/train/JPEGImages/seq14/frame081.png
13
./datasets/EV18/train/JPEGImages/seq13/frame013.png
18
./datasets/EV18/train/JPEGImages/seq13/frame018.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(193.6654, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.8304, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8809, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
58
./datasets/EV18/train/JPEGImages/seq1/frame058.png
60
./datasets/EV18/train/JPEGImages/seq1/frame060.png
8
./datasets/EV18/train/JPEGImages/seq16/frame008.png
16
./datasets/EV18/train/JPEGImages/seq16/frame016.png
35
./datasets/EV18/train/JPEGImages/seq1/frame035.png
36
./datasets/EV18/train/JPEGImages/seq1/frame036.png
0
./datasets/EV18/train/JPEGImages/seq3/frame000.png
2
./datasets/EV18/train/JPEGImages/seq3/frame002.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(213.5953, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.9839, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.9251, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
118
./datasets/EV18/train/JPEGImages/seq6/frame118.png
125
./datasets/EV18/train/JPEGImages/seq6/frame125.png
38
./datasets/EV18/train/JPEGImages/seq13/frame038.png
39
./datasets/EV18/train/JPEGImages/seq13/frame039.png
17
./datasets/EV18/train/JPEGImages/seq11/frame017.png
21
./datasets/EV18/train/JPEGImages/seq11/frame021.png
91
./datasets/EV18/train/JPEGImages/seq4/frame091.png
101
./datasets/EV18/train/JPEGImages/seq4/frame101.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(143.8115, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5757, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7877, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
142
./datasets/EV18/train/JPEGImages/seq16/frame142.png
143
./datasets/EV18/train/JPEGImages/seq16/frame143.png
111
./datasets/EV18/train/JPEGImages/seq7/frame111.png
116
./datasets/EV18/train/JPEGImages/seq7/frame116.png
3
./datasets/EV18/train/JPEGImages/seq12/frame003.png
7
./datasets/EV18/train/JPEGImages/seq12/frame007.png
4
./datasets/EV18/train/JPEGImages/seq13/frame004.png
6
./datasets/EV18/train/JPEGImages/seq13/frame006.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(177.1975, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.4473, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7853, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
132
./datasets/EV18/train/JPEGImages/seq3/frame132.png
134
./datasets/EV18/train/JPEGImages/seq3/frame134.png
7
./datasets/EV18/train/JPEGImages/seq16/frame007.png
11
./datasets/EV18/train/JPEGImages/seq16/frame011.png
140
./datasets/EV18/train/JPEGImages/seq7/frame140.png
147
./datasets/EV18/train/JPEGImages/seq7/frame147.png
89
./datasets/EV18/train/JPEGImages/seq12/frame089.png
98
./datasets/EV18/train/JPEGImages/seq12/frame098.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(154.0936, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.4312, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7242, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
75
./datasets/EV18/train/JPEGImages/seq1/frame075.png
76
./datasets/EV18/train/JPEGImages/seq1/frame076.png
90
./datasets/EV18/train/JPEGImages/seq14/frame090.png
95
./datasets/EV18/train/JPEGImages/seq14/frame095.png
141
./datasets/EV18/train/JPEGImages/seq14/frame141.png
145
./datasets/EV18/train/JPEGImages/seq14/frame145.png
4
./datasets/EV18/train/JPEGImages/seq7/frame004.png
11
./datasets/EV18/train/JPEGImages/seq7/frame011.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(107.6986, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.2012, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7072, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
42
./datasets/EV18/train/JPEGImages/seq14/frame042.png
47
./datasets/EV18/train/JPEGImages/seq14/frame047.png
89
./datasets/EV18/train/JPEGImages/seq11/frame089.png
94
./datasets/EV18/train/JPEGImages/seq11/frame094.png
125
./datasets/EV18/train/JPEGImages/seq6/frame125.png
127
./datasets/EV18/train/JPEGImages/seq6/frame127.png
33
./datasets/EV18/train/JPEGImages/seq16/frame033.png
39
./datasets/EV18/train/JPEGImages/seq16/frame039.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(131.0537, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.2303, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7350, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
129
./datasets/EV18/train/JPEGImages/seq12/frame129.png
130
./datasets/EV18/train/JPEGImages/seq12/frame130.png
2
./datasets/EV18/train/JPEGImages/seq4/frame002.png
3
./datasets/EV18/train/JPEGImages/seq4/frame003.png
28
./datasets/EV18/train/JPEGImages/seq10/frame028.png
36
./datasets/EV18/train/JPEGImages/seq10/frame036.png
18
./datasets/EV18/train/JPEGImages/seq16/frame018.png
24
./datasets/EV18/train/JPEGImages/seq16/frame024.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(198.6396, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5696, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7973, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
84
./datasets/EV18/train/JPEGImages/seq10/frame084.png
85
./datasets/EV18/train/JPEGImages/seq10/frame085.png
17
./datasets/EV18/train/JPEGImages/seq13/frame017.png
20
./datasets/EV18/train/JPEGImages/seq13/frame020.png
111
./datasets/EV18/train/JPEGImages/seq1/frame111.png
121
./datasets/EV18/train/JPEGImages/seq1/frame121.png
56
./datasets/EV18/train/JPEGImages/seq10/frame056.png
57
./datasets/EV18/train/JPEGImages/seq10/frame057.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(171.8233, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.6725, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8280, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
61
./datasets/EV18/train/JPEGImages/seq10/frame061.png
65
./datasets/EV18/train/JPEGImages/seq10/frame065.png
106
./datasets/EV18/train/JPEGImages/seq11/frame106.png
108
./datasets/EV18/train/JPEGImages/seq11/frame108.png
50
./datasets/EV18/train/JPEGImages/seq6/frame050.png
51
./datasets/EV18/train/JPEGImages/seq6/frame051.png
29
./datasets/EV18/train/JPEGImages/seq1/frame029.png
34
./datasets/EV18/train/JPEGImages/seq1/frame034.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(174.6264, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5929, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8001, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
122
./datasets/EV18/train/JPEGImages/seq3/frame122.png
129
./datasets/EV18/train/JPEGImages/seq3/frame129.png
136
./datasets/EV18/train/JPEGImages/seq12/frame136.png
145
./datasets/EV18/train/JPEGImages/seq12/frame145.png
87
./datasets/EV18/train/JPEGImages/seq4/frame087.png
91
./datasets/EV18/train/JPEGImages/seq4/frame091.png
29
./datasets/EV18/train/JPEGImages/seq6/frame029.png
32
./datasets/EV18/train/JPEGImages/seq6/frame032.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(171.7905, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5211, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7881, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
121
./datasets/EV18/train/JPEGImages/seq4/frame121.png
131
./datasets/EV18/train/JPEGImages/seq4/frame131.png
95
./datasets/EV18/train/JPEGImages/seq3/frame095.png
99
./datasets/EV18/train/JPEGImages/seq3/frame099.png
126
./datasets/EV18/train/JPEGImages/seq13/frame126.png
129
./datasets/EV18/train/JPEGImages/seq13/frame129.png
121
./datasets/EV18/train/JPEGImages/seq16/frame121.png
126
./datasets/EV18/train/JPEGImages/seq16/frame126.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(156.5459, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.6380, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8467, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
140
./datasets/EV18/train/JPEGImages/seq6/frame140.png
146
./datasets/EV18/train/JPEGImages/seq6/frame146.png
16
./datasets/EV18/train/JPEGImages/seq11/frame016.png
17
./datasets/EV18/train/JPEGImages/seq11/frame017.png
140
./datasets/EV18/train/JPEGImages/seq1/frame140.png
141
./datasets/EV18/train/JPEGImages/seq1/frame141.png
10
./datasets/EV18/train/JPEGImages/seq13/frame010.png
20
./datasets/EV18/train/JPEGImages/seq13/frame020.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(165.1299, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.4885, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8101, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
3
./datasets/EV18/train/JPEGImages/seq1/frame003.png
12
./datasets/EV18/train/JPEGImages/seq1/frame012.png
23
./datasets/EV18/train/JPEGImages/seq13/frame023.png
27
./datasets/EV18/train/JPEGImages/seq13/frame027.png
117
./datasets/EV18/train/JPEGImages/seq3/frame117.png
120
./datasets/EV18/train/JPEGImages/seq3/frame120.png
68
./datasets/EV18/train/JPEGImages/seq10/frame068.png
71
./datasets/EV18/train/JPEGImages/seq10/frame071.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(137.9978, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.4687, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7835, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
33
./datasets/EV18/train/JPEGImages/seq4/frame033.png
42
./datasets/EV18/train/JPEGImages/seq4/frame042.png
121
./datasets/EV18/train/JPEGImages/seq4/frame121.png
127
./datasets/EV18/train/JPEGImages/seq4/frame127.png
71
./datasets/EV18/train/JPEGImages/seq16/frame071.png
77
./datasets/EV18/train/JPEGImages/seq16/frame077.png
106
./datasets/EV18/train/JPEGImages/seq6/frame106.png
109
./datasets/EV18/train/JPEGImages/seq6/frame109.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(124.6036, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5721, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7933, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
[05/26 01:42:16 d2.utils.events]:  eta: 3:55:58  iter: 59  total_loss: 2236  loss_ce: 231.7  loss_bbox: 1.71  loss_giou: 0.8512  loss_mask: 1.421  loss_dice: 0.9579  loss_ce_dn: 1.799  loss_mask_dn: 1.412  loss_dice_dn: 0.9575  loss_bbox_dn: 0.2167  loss_giou_dn: 0.4254  loss_ce_0: 207.3  loss_mask_0: 0.811  loss_dice_0: 0.9396  loss_bbox_0: 1.714  loss_giou_0: 0.8503  loss_ce_dn_0: 1.129  loss_mask_dn_0: 1.114  loss_dice_dn_0: 0.9396  loss_bbox_dn_0: 0.2167  loss_giou_dn_0: 0.4254  loss_ce_1: 183.5  loss_mask_1: 0.743  loss_dice_1: 0.9394  loss_bbox_1: 1.719  loss_giou_1: 0.844  loss_ce_dn_1: 1.171  loss_mask_dn_1: 1.062  loss_dice_dn_1: 0.9455  loss_bbox_dn_1: 0.2167  loss_giou_dn_1: 0.4254  loss_ce_2: 143.8  loss_mask_2: 0.8007  loss_dice_2: 0.9319  loss_bbox_2: 1.721  loss_giou_2: 0.8485  loss_ce_dn_2: 1.088  loss_mask_dn_2: 1.011  loss_dice_dn_2: 0.9275  loss_bbox_dn_2: 0.2167  loss_giou_dn_2: 0.4254  loss_ce_3: 219.2  loss_mask_3: 0.7515  loss_dice_3: 0.9152  loss_bbox_3: 1.721  loss_giou_3: 0.8485  loss_ce_dn_3: 1.78  loss_mask_dn_3: 0.9121  loss_dice_dn_3: 0.9198  loss_bbox_dn_3: 0.2167  loss_giou_dn_3: 0.4254  loss_ce_4: 140.9  loss_mask_4: 0.8868  loss_dice_4: 0.9266  loss_bbox_4: 1.712  loss_giou_4: 0.8487  loss_ce_dn_4: 1.231  loss_mask_dn_4: 1.081  loss_dice_dn_4: 0.9312  loss_bbox_dn_4: 0.2167  loss_giou_dn_4: 0.4254  loss_ce_5: 214  loss_mask_5: 0.7206  loss_dice_5: 0.9256  loss_bbox_5: 1.708  loss_giou_5: 0.8485  loss_ce_dn_5: 2.035  loss_mask_dn_5: 0.7694  loss_dice_dn_5: 0.9389  loss_bbox_dn_5: 0.2167  loss_giou_dn_5: 0.4254  loss_ce_6: 141.3  loss_mask_6: 0.8253  loss_dice_6: 0.9399  loss_bbox_6: 1.711  loss_giou_6: 0.8497  loss_ce_dn_6: 1.361  loss_mask_dn_6: 0.8757  loss_dice_dn_6: 0.9455  loss_bbox_dn_6: 0.2167  loss_giou_dn_6: 0.4254  loss_ce_7: 229.8  loss_mask_7: 0.8947  loss_dice_7: 0.9427  loss_bbox_7: 1.715  loss_giou_7: 0.8515  loss_ce_dn_7: 1.985  loss_mask_dn_7: 0.9003  loss_dice_dn_7: 0.939  loss_bbox_dn_7: 0.2167  loss_giou_dn_7: 0.4254  loss_ce_8: 238.9  loss_mask_8: 1.17  loss_dice_8: 0.9364  loss_bbox_8: 1.71  loss_giou_8: 0.8513  loss_ce_dn_8: 2.077  loss_mask_dn_8: 1.17  loss_dice_dn_8: 0.9309  loss_bbox_dn_8: 0.2167  loss_giou_dn_8: 0.4254  loss_ce_interm: 207.4  loss_mask_interm: 0.9016  loss_dice_interm: 0.9453  loss_bbox_interm: 0.6907  loss_giou_interm: 1.08    time: 1.1706  last_time: 1.1652  data_time: 0.0125  last_data_time: 0.0108   lr: 0.0001  max_mem: 18844M
65
./datasets/EV18/train/JPEGImages/seq11/frame065.png
74
./datasets/EV18/train/JPEGImages/seq11/frame074.png
5
./datasets/EV18/train/JPEGImages/seq14/frame005.png
15
./datasets/EV18/train/JPEGImages/seq14/frame015.png
112
./datasets/EV18/train/JPEGImages/seq1/frame112.png
115
./datasets/EV18/train/JPEGImages/seq1/frame115.png
59
./datasets/EV18/train/JPEGImages/seq11/frame059.png
65
./datasets/EV18/train/JPEGImages/seq11/frame065.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(130.2880, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5845, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7553, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
144
./datasets/EV18/train/JPEGImages/seq7/frame144.png
147
./datasets/EV18/train/JPEGImages/seq7/frame147.png
80
./datasets/EV18/train/JPEGImages/seq12/frame080.png
81
./datasets/EV18/train/JPEGImages/seq12/frame081.png
28
./datasets/EV18/train/JPEGImages/seq6/frame028.png
35
./datasets/EV18/train/JPEGImages/seq6/frame035.png
51
./datasets/EV18/train/JPEGImages/seq11/frame051.png
61
./datasets/EV18/train/JPEGImages/seq11/frame061.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(117.1349, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.2908, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.6653, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
106
./datasets/EV18/train/JPEGImages/seq7/frame106.png
108
./datasets/EV18/train/JPEGImages/seq7/frame108.png
94
./datasets/EV18/train/JPEGImages/seq12/frame094.png
96
./datasets/EV18/train/JPEGImages/seq12/frame096.png
110
./datasets/EV18/train/JPEGImages/seq14/frame110.png
113
./datasets/EV18/train/JPEGImages/seq14/frame113.png
6
./datasets/EV18/train/JPEGImages/seq7/frame006.png
8
./datasets/EV18/train/JPEGImages/seq7/frame008.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(160.9495, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.4133, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7622, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
134
./datasets/EV18/train/JPEGImages/seq3/frame134.png
141
./datasets/EV18/train/JPEGImages/seq3/frame141.png
104
./datasets/EV18/train/JPEGImages/seq10/frame104.png
113
./datasets/EV18/train/JPEGImages/seq10/frame113.png
19
./datasets/EV18/train/JPEGImages/seq14/frame019.png
23
./datasets/EV18/train/JPEGImages/seq14/frame023.png
22
./datasets/EV18/train/JPEGImages/seq14/frame022.png
24
./datasets/EV18/train/JPEGImages/seq14/frame024.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(166.5522, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.6842, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8374, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
110
./datasets/EV18/train/JPEGImages/seq4/frame110.png
115
./datasets/EV18/train/JPEGImages/seq4/frame115.png
117
./datasets/EV18/train/JPEGImages/seq12/frame117.png
118
./datasets/EV18/train/JPEGImages/seq12/frame118.png
39
./datasets/EV18/train/JPEGImages/seq6/frame039.png
48
./datasets/EV18/train/JPEGImages/seq6/frame048.png
79
./datasets/EV18/train/JPEGImages/seq16/frame079.png
87
./datasets/EV18/train/JPEGImages/seq16/frame087.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(138.1818, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5767, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7908, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
94
./datasets/EV18/train/JPEGImages/seq12/frame094.png
100
./datasets/EV18/train/JPEGImages/seq12/frame100.png
130
./datasets/EV18/train/JPEGImages/seq3/frame130.png
139
./datasets/EV18/train/JPEGImages/seq3/frame139.png
74
./datasets/EV18/train/JPEGImages/seq13/frame074.png
81
./datasets/EV18/train/JPEGImages/seq13/frame081.png
66
./datasets/EV18/train/JPEGImages/seq4/frame066.png
75
./datasets/EV18/train/JPEGImages/seq4/frame075.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(124.7507, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.2665, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7148, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
100
./datasets/EV18/train/JPEGImages/seq7/frame100.png
107
./datasets/EV18/train/JPEGImages/seq7/frame107.png
89
./datasets/EV18/train/JPEGImages/seq13/frame089.png
91
./datasets/EV18/train/JPEGImages/seq13/frame091.png
75
./datasets/EV18/train/JPEGImages/seq1/frame075.png
85
./datasets/EV18/train/JPEGImages/seq1/frame085.png
1
./datasets/EV18/train/JPEGImages/seq3/frame001.png
6
./datasets/EV18/train/JPEGImages/seq3/frame006.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(182.3031, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5394, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8225, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
47
./datasets/EV18/train/JPEGImages/seq7/frame047.png
53
./datasets/EV18/train/JPEGImages/seq7/frame053.png
141
./datasets/EV18/train/JPEGImages/seq16/frame141.png
145
./datasets/EV18/train/JPEGImages/seq16/frame145.png
55
./datasets/EV18/train/JPEGImages/seq12/frame055.png
60
./datasets/EV18/train/JPEGImages/seq12/frame060.png
63
./datasets/EV18/train/JPEGImages/seq1/frame063.png
72
./datasets/EV18/train/JPEGImages/seq1/frame072.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(165.8689, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.7096, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8219, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
111
./datasets/EV18/train/JPEGImages/seq3/frame111.png
117
./datasets/EV18/train/JPEGImages/seq3/frame117.png
25
./datasets/EV18/train/JPEGImages/seq1/frame025.png
33
./datasets/EV18/train/JPEGImages/seq1/frame033.png
48
./datasets/EV18/train/JPEGImages/seq14/frame048.png
55
./datasets/EV18/train/JPEGImages/seq14/frame055.png
6
./datasets/EV18/train/JPEGImages/seq4/frame006.png
15
./datasets/EV18/train/JPEGImages/seq4/frame015.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(118.2143, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5012, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7763, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
72
./datasets/EV18/train/JPEGImages/seq13/frame072.png
82
./datasets/EV18/train/JPEGImages/seq13/frame082.png
135
./datasets/EV18/train/JPEGImages/seq14/frame135.png
145
./datasets/EV18/train/JPEGImages/seq14/frame145.png
89
./datasets/EV18/train/JPEGImages/seq7/frame089.png
90
./datasets/EV18/train/JPEGImages/seq7/frame090.png
42
./datasets/EV18/train/JPEGImages/seq11/frame042.png
51
./datasets/EV18/train/JPEGImages/seq11/frame051.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(153.2524, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5427, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8316, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
142
./datasets/EV18/train/JPEGImages/seq10/frame142.png
145
./datasets/EV18/train/JPEGImages/seq10/frame145.png
40
./datasets/EV18/train/JPEGImages/seq16/frame040.png
46
./datasets/EV18/train/JPEGImages/seq16/frame046.png
125
./datasets/EV18/train/JPEGImages/seq11/frame125.png
131
./datasets/EV18/train/JPEGImages/seq11/frame131.png
120
./datasets/EV18/train/JPEGImages/seq10/frame120.png
130
./datasets/EV18/train/JPEGImages/seq10/frame130.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(129.1142, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.2934, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.6761, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
6
./datasets/EV18/train/JPEGImages/seq11/frame006.png
9
./datasets/EV18/train/JPEGImages/seq11/frame009.png
140
./datasets/EV18/train/JPEGImages/seq6/frame140.png
142
./datasets/EV18/train/JPEGImages/seq6/frame142.png
39
./datasets/EV18/train/JPEGImages/seq10/frame039.png
46
./datasets/EV18/train/JPEGImages/seq10/frame046.png
8
./datasets/EV18/train/JPEGImages/seq4/frame008.png
11
./datasets/EV18/train/JPEGImages/seq4/frame011.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(133.9534, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.4598, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7620, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
79
./datasets/EV18/train/JPEGImages/seq7/frame079.png
88
./datasets/EV18/train/JPEGImages/seq7/frame088.png
128
./datasets/EV18/train/JPEGImages/seq14/frame128.png
137
./datasets/EV18/train/JPEGImages/seq14/frame137.png
40
./datasets/EV18/train/JPEGImages/seq13/frame040.png
50
./datasets/EV18/train/JPEGImages/seq13/frame050.png
111
./datasets/EV18/train/JPEGImages/seq12/frame111.png
119
./datasets/EV18/train/JPEGImages/seq12/frame119.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(134.5938, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.2060, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7036, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
103
./datasets/EV18/train/JPEGImages/seq4/frame103.png
113
./datasets/EV18/train/JPEGImages/seq4/frame113.png
106
./datasets/EV18/train/JPEGImages/seq3/frame106.png
114
./datasets/EV18/train/JPEGImages/seq3/frame114.png
94
./datasets/EV18/train/JPEGImages/seq13/frame094.png
98
./datasets/EV18/train/JPEGImages/seq13/frame098.png
109
./datasets/EV18/train/JPEGImages/seq6/frame109.png
114
./datasets/EV18/train/JPEGImages/seq6/frame114.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(146.5246, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.6806, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8310, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
141
./datasets/EV18/train/JPEGImages/seq12/frame141.png
142
./datasets/EV18/train/JPEGImages/seq12/frame142.png
69
./datasets/EV18/train/JPEGImages/seq16/frame069.png
71
./datasets/EV18/train/JPEGImages/seq16/frame071.png
121
./datasets/EV18/train/JPEGImages/seq13/frame121.png
127
./datasets/EV18/train/JPEGImages/seq13/frame127.png
65
./datasets/EV18/train/JPEGImages/seq10/frame065.png
69
./datasets/EV18/train/JPEGImages/seq10/frame069.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(154.2533, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5042, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8003, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
44
./datasets/EV18/train/JPEGImages/seq6/frame044.png
48
./datasets/EV18/train/JPEGImages/seq6/frame048.png
38
./datasets/EV18/train/JPEGImages/seq1/frame038.png
47
./datasets/EV18/train/JPEGImages/seq1/frame047.png
129
./datasets/EV18/train/JPEGImages/seq16/frame129.png
133
./datasets/EV18/train/JPEGImages/seq16/frame133.png
48
./datasets/EV18/train/JPEGImages/seq4/frame048.png
54
./datasets/EV18/train/JPEGImages/seq4/frame054.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(115.7211, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.4237, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7541, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
75
./datasets/EV18/train/JPEGImages/seq3/frame075.png
83
./datasets/EV18/train/JPEGImages/seq3/frame083.png
113
./datasets/EV18/train/JPEGImages/seq6/frame113.png
122
./datasets/EV18/train/JPEGImages/seq6/frame122.png
47
./datasets/EV18/train/JPEGImages/seq3/frame047.png
54
./datasets/EV18/train/JPEGImages/seq3/frame054.png
128
./datasets/EV18/train/JPEGImages/seq14/frame128.png
129
./datasets/EV18/train/JPEGImages/seq14/frame129.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(134.8714, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.2537, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.6909, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
94
./datasets/EV18/train/JPEGImages/seq11/frame094.png
97
./datasets/EV18/train/JPEGImages/seq11/frame097.png
23
./datasets/EV18/train/JPEGImages/seq7/frame023.png
27
./datasets/EV18/train/JPEGImages/seq7/frame027.png
117
./datasets/EV18/train/JPEGImages/seq11/frame117.png
125
./datasets/EV18/train/JPEGImages/seq11/frame125.png
65
./datasets/EV18/train/JPEGImages/seq12/frame065.png
72
./datasets/EV18/train/JPEGImages/seq12/frame072.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(114.6218, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.2247, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.6672, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
74
./datasets/EV18/train/JPEGImages/seq10/frame074.png
76
./datasets/EV18/train/JPEGImages/seq10/frame076.png
38
./datasets/EV18/train/JPEGImages/seq1/frame038.png
41
./datasets/EV18/train/JPEGImages/seq1/frame041.png
130
./datasets/EV18/train/JPEGImages/seq1/frame130.png
134
./datasets/EV18/train/JPEGImages/seq1/frame134.png
39
./datasets/EV18/train/JPEGImages/seq16/frame039.png
45
./datasets/EV18/train/JPEGImages/seq16/frame045.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(128.7900, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.8341, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8762, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
0
./datasets/EV18/train/JPEGImages/seq7/frame000.png
10
./datasets/EV18/train/JPEGImages/seq7/frame010.png
87
./datasets/EV18/train/JPEGImages/seq14/frame087.png
95
./datasets/EV18/train/JPEGImages/seq14/frame095.png
7
./datasets/EV18/train/JPEGImages/seq10/frame007.png
12
./datasets/EV18/train/JPEGImages/seq10/frame012.png
100
./datasets/EV18/train/JPEGImages/seq12/frame100.png
109
./datasets/EV18/train/JPEGImages/seq12/frame109.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(168.3344, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.4293, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7684, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
[05/26 01:42:39 d2.utils.events]:  eta: 3:54:18  iter: 79  total_loss: 2192  loss_ce: 224  loss_bbox: 1.63  loss_giou: 0.8351  loss_mask: 1.428  loss_dice: 0.9555  loss_ce_dn: 1.781  loss_mask_dn: 1.491  loss_dice_dn: 0.9563  loss_bbox_dn: 0.235  loss_giou_dn: 0.4256  loss_ce_0: 202.7  loss_mask_0: 0.8461  loss_dice_0: 0.9286  loss_bbox_0: 1.642  loss_giou_0: 0.837  loss_ce_dn_0: 1.082  loss_mask_dn_0: 1.119  loss_dice_dn_0: 0.9297  loss_bbox_dn_0: 0.235  loss_giou_dn_0: 0.4256  loss_ce_1: 178.6  loss_mask_1: 0.7519  loss_dice_1: 0.9313  loss_bbox_1: 1.643  loss_giou_1: 0.8314  loss_ce_dn_1: 1.104  loss_mask_dn_1: 1.062  loss_dice_dn_1: 0.9381  loss_bbox_dn_1: 0.235  loss_giou_dn_1: 0.4256  loss_ce_2: 138  loss_mask_2: 0.8025  loss_dice_2: 0.9191  loss_bbox_2: 1.643  loss_giou_2: 0.8316  loss_ce_dn_2: 1.027  loss_mask_dn_2: 1.014  loss_dice_dn_2: 0.9131  loss_bbox_dn_2: 0.235  loss_giou_dn_2: 0.4256  loss_ce_3: 217  loss_mask_3: 0.754  loss_dice_3: 0.8977  loss_bbox_3: 1.645  loss_giou_3: 0.8323  loss_ce_dn_3: 1.67  loss_mask_dn_3: 0.9017  loss_dice_dn_3: 0.9123  loss_bbox_dn_3: 0.235  loss_giou_dn_3: 0.4256  loss_ce_4: 136.9  loss_mask_4: 0.8945  loss_dice_4: 0.9271  loss_bbox_4: 1.638  loss_giou_4: 0.8323  loss_ce_dn_4: 1.141  loss_mask_dn_4: 1.052  loss_dice_dn_4: 0.9274  loss_bbox_dn_4: 0.235  loss_giou_dn_4: 0.4256  loss_ce_5: 208.7  loss_mask_5: 0.7195  loss_dice_5: 0.9162  loss_bbox_5: 1.629  loss_giou_5: 0.8315  loss_ce_dn_5: 1.927  loss_mask_dn_5: 0.7597  loss_dice_dn_5: 0.9271  loss_bbox_dn_5: 0.235  loss_giou_dn_5: 0.4256  loss_ce_6: 138.5  loss_mask_6: 0.8154  loss_dice_6: 0.9385  loss_bbox_6: 1.629  loss_giou_6: 0.8343  loss_ce_dn_6: 1.304  loss_mask_dn_6: 0.8853  loss_dice_dn_6: 0.9435  loss_bbox_dn_6: 0.235  loss_giou_dn_6: 0.4256  loss_ce_7: 229.4  loss_mask_7: 0.8999  loss_dice_7: 0.9345  loss_bbox_7: 1.641  loss_giou_7: 0.8344  loss_ce_dn_7: 1.95  loss_mask_dn_7: 0.8985  loss_dice_dn_7: 0.9289  loss_bbox_dn_7: 0.235  loss_giou_dn_7: 0.4256  loss_ce_8: 236  loss_mask_8: 1.199  loss_dice_8: 0.9348  loss_bbox_8: 1.629  loss_giou_8: 0.8372  loss_ce_dn_8: 1.983  loss_mask_dn_8: 1.198  loss_dice_dn_8: 0.9276  loss_bbox_dn_8: 0.235  loss_giou_dn_8: 0.4256  loss_ce_interm: 202.8  loss_mask_interm: 0.9293  loss_dice_interm: 0.9325  loss_bbox_interm: 0.7619  loss_giou_interm: 1.023    time: 1.1655  last_time: 1.1953  data_time: 0.0125  last_data_time: 0.0137   lr: 0.0001  max_mem: 18844M
37
./datasets/EV18/train/JPEGImages/seq14/frame037.png
38
./datasets/EV18/train/JPEGImages/seq14/frame038.png
101
./datasets/EV18/train/JPEGImages/seq4/frame101.png
108
./datasets/EV18/train/JPEGImages/seq4/frame108.png
115
./datasets/EV18/train/JPEGImages/seq6/frame115.png
116
./datasets/EV18/train/JPEGImages/seq6/frame116.png
82
./datasets/EV18/train/JPEGImages/seq14/frame082.png
85
./datasets/EV18/train/JPEGImages/seq14/frame085.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(94.7991, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5131, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7793, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
28
./datasets/EV18/train/JPEGImages/seq7/frame028.png
34
./datasets/EV18/train/JPEGImages/seq7/frame034.png
109
./datasets/EV18/train/JPEGImages/seq4/frame109.png
113
./datasets/EV18/train/JPEGImages/seq4/frame113.png
10
./datasets/EV18/train/JPEGImages/seq12/frame010.png
12
./datasets/EV18/train/JPEGImages/seq12/frame012.png
144
./datasets/EV18/train/JPEGImages/seq4/frame144.png
148
./datasets/EV18/train/JPEGImages/seq4/frame148.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(137.2909, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.4736, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7836, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
41
./datasets/EV18/train/JPEGImages/seq7/frame041.png
45
./datasets/EV18/train/JPEGImages/seq7/frame045.png
21
./datasets/EV18/train/JPEGImages/seq11/frame021.png
31
./datasets/EV18/train/JPEGImages/seq11/frame031.png
136
./datasets/EV18/train/JPEGImages/seq1/frame136.png
145
./datasets/EV18/train/JPEGImages/seq1/frame145.png
7
./datasets/EV18/train/JPEGImages/seq6/frame007.png
16
./datasets/EV18/train/JPEGImages/seq6/frame016.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(157.5351, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.7038, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8560, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
78
./datasets/EV18/train/JPEGImages/seq11/frame078.png
85
./datasets/EV18/train/JPEGImages/seq11/frame085.png
43
./datasets/EV18/train/JPEGImages/seq1/frame043.png
48
./datasets/EV18/train/JPEGImages/seq1/frame048.png
80
./datasets/EV18/train/JPEGImages/seq11/frame080.png
84
./datasets/EV18/train/JPEGImages/seq11/frame084.png
39
./datasets/EV18/train/JPEGImages/seq6/frame039.png
42
./datasets/EV18/train/JPEGImages/seq6/frame042.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(213.1662, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.7830, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8609, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
58
./datasets/EV18/train/JPEGImages/seq3/frame058.png
61
./datasets/EV18/train/JPEGImages/seq3/frame061.png
51
./datasets/EV18/train/JPEGImages/seq13/frame051.png
60
./datasets/EV18/train/JPEGImages/seq13/frame060.png
104
./datasets/EV18/train/JPEGImages/seq12/frame104.png
113
./datasets/EV18/train/JPEGImages/seq12/frame113.png
79
./datasets/EV18/train/JPEGImages/seq3/frame079.png
86
./datasets/EV18/train/JPEGImages/seq3/frame086.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(227.6400, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.6174, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8457, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
0
./datasets/EV18/train/JPEGImages/seq1/frame000.png
4
./datasets/EV18/train/JPEGImages/seq1/frame004.png
82
./datasets/EV18/train/JPEGImages/seq13/frame082.png
86
./datasets/EV18/train/JPEGImages/seq13/frame086.png
121
./datasets/EV18/train/JPEGImages/seq3/frame121.png
127
./datasets/EV18/train/JPEGImages/seq3/frame127.png
58
./datasets/EV18/train/JPEGImages/seq14/frame058.png
61
./datasets/EV18/train/JPEGImages/seq14/frame061.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(188.3801, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.7238, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8653, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
116
./datasets/EV18/train/JPEGImages/seq16/frame116.png
125
./datasets/EV18/train/JPEGImages/seq16/frame125.png
95
./datasets/EV18/train/JPEGImages/seq10/frame095.png
101
./datasets/EV18/train/JPEGImages/seq10/frame101.png
41
./datasets/EV18/train/JPEGImages/seq13/frame041.png
44
./datasets/EV18/train/JPEGImages/seq13/frame044.png
22
./datasets/EV18/train/JPEGImages/seq16/frame022.png
28
./datasets/EV18/train/JPEGImages/seq16/frame028.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(136.2912, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.3182, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7077, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
0
./datasets/EV18/train/JPEGImages/seq10/frame000.png
9
./datasets/EV18/train/JPEGImages/seq10/frame009.png
43
./datasets/EV18/train/JPEGImages/seq16/frame043.png
44
./datasets/EV18/train/JPEGImages/seq16/frame044.png
132
./datasets/EV18/train/JPEGImages/seq10/frame132.png
139
./datasets/EV18/train/JPEGImages/seq10/frame139.png
125
./datasets/EV18/train/JPEGImages/seq7/frame125.png
134
./datasets/EV18/train/JPEGImages/seq7/frame134.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(241.4144, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.7277, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8333, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
120
./datasets/EV18/train/JPEGImages/seq6/frame120.png
124
./datasets/EV18/train/JPEGImages/seq6/frame124.png
130
./datasets/EV18/train/JPEGImages/seq7/frame130.png
132
./datasets/EV18/train/JPEGImages/seq7/frame132.png
137
./datasets/EV18/train/JPEGImages/seq1/frame137.png
144
./datasets/EV18/train/JPEGImages/seq1/frame144.png
107
./datasets/EV18/train/JPEGImages/seq4/frame107.png
113
./datasets/EV18/train/JPEGImages/seq4/frame113.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(104.1925, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.4571, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7628, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
61
./datasets/EV18/train/JPEGImages/seq13/frame061.png
65
./datasets/EV18/train/JPEGImages/seq13/frame065.png
104
./datasets/EV18/train/JPEGImages/seq3/frame104.png
108
./datasets/EV18/train/JPEGImages/seq3/frame108.png
121
./datasets/EV18/train/JPEGImages/seq11/frame121.png
128
./datasets/EV18/train/JPEGImages/seq11/frame128.png
48
./datasets/EV18/train/JPEGImages/seq3/frame048.png
51
./datasets/EV18/train/JPEGImages/seq3/frame051.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(185.6292, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.4962, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7787, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
33
./datasets/EV18/train/JPEGImages/seq3/frame033.png
42
./datasets/EV18/train/JPEGImages/seq3/frame042.png
26
./datasets/EV18/train/JPEGImages/seq16/frame026.png
32
./datasets/EV18/train/JPEGImages/seq16/frame032.png
133
./datasets/EV18/train/JPEGImages/seq4/frame133.png
139
./datasets/EV18/train/JPEGImages/seq4/frame139.png
60
./datasets/EV18/train/JPEGImages/seq11/frame060.png
68
./datasets/EV18/train/JPEGImages/seq11/frame068.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(146.7191, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.3865, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7321, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
50
./datasets/EV18/train/JPEGImages/seq14/frame050.png
53
./datasets/EV18/train/JPEGImages/seq14/frame053.png
104
./datasets/EV18/train/JPEGImages/seq12/frame104.png
114
./datasets/EV18/train/JPEGImages/seq12/frame114.png
49
./datasets/EV18/train/JPEGImages/seq7/frame049.png
50
./datasets/EV18/train/JPEGImages/seq7/frame050.png
72
./datasets/EV18/train/JPEGImages/seq14/frame072.png
82
./datasets/EV18/train/JPEGImages/seq14/frame082.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(183.2131, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5856, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8290, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
111
./datasets/EV18/train/JPEGImages/seq10/frame111.png
117
./datasets/EV18/train/JPEGImages/seq10/frame117.png
4
./datasets/EV18/train/JPEGImages/seq11/frame004.png
8
./datasets/EV18/train/JPEGImages/seq11/frame008.png
109
./datasets/EV18/train/JPEGImages/seq14/frame109.png
119
./datasets/EV18/train/JPEGImages/seq14/frame119.png
28
./datasets/EV18/train/JPEGImages/seq6/frame028.png
32
./datasets/EV18/train/JPEGImages/seq6/frame032.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(171.6494, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.4758, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7854, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
87
./datasets/EV18/train/JPEGImages/seq10/frame087.png
89
./datasets/EV18/train/JPEGImages/seq10/frame089.png
147
./datasets/EV18/train/JPEGImages/seq13/frame147.png
148
./datasets/EV18/train/JPEGImages/seq13/frame148.png
54
./datasets/EV18/train/JPEGImages/seq6/frame054.png
58
./datasets/EV18/train/JPEGImages/seq6/frame058.png
135
./datasets/EV18/train/JPEGImages/seq10/frame135.png
138
./datasets/EV18/train/JPEGImages/seq10/frame138.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(149.7604, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.4996, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7905, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
13
./datasets/EV18/train/JPEGImages/seq13/frame013.png
20
./datasets/EV18/train/JPEGImages/seq13/frame020.png
68
./datasets/EV18/train/JPEGImages/seq12/frame068.png
69
./datasets/EV18/train/JPEGImages/seq12/frame069.png
41
./datasets/EV18/train/JPEGImages/seq1/frame041.png
51
./datasets/EV18/train/JPEGImages/seq1/frame051.png
92
./datasets/EV18/train/JPEGImages/seq7/frame092.png
95
./datasets/EV18/train/JPEGImages/seq7/frame095.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(206.3578, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.7897, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8912, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
77
./datasets/EV18/train/JPEGImages/seq16/frame077.png
84
./datasets/EV18/train/JPEGImages/seq16/frame084.png
83
./datasets/EV18/train/JPEGImages/seq1/frame083.png
86
./datasets/EV18/train/JPEGImages/seq1/frame086.png
137
./datasets/EV18/train/JPEGImages/seq16/frame137.png
146
./datasets/EV18/train/JPEGImages/seq16/frame146.png
133
./datasets/EV18/train/JPEGImages/seq12/frame133.png
135
./datasets/EV18/train/JPEGImages/seq12/frame135.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(141.7564, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.4896, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7839, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
0
./datasets/EV18/train/JPEGImages/seq4/frame000.png
3
./datasets/EV18/train/JPEGImages/seq4/frame003.png
0
./datasets/EV18/train/JPEGImages/seq12/frame000.png
1
./datasets/EV18/train/JPEGImages/seq12/frame001.png
35
./datasets/EV18/train/JPEGImages/seq10/frame035.png
44
./datasets/EV18/train/JPEGImages/seq10/frame044.png
76
./datasets/EV18/train/JPEGImages/seq14/frame076.png
81
./datasets/EV18/train/JPEGImages/seq14/frame081.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(191.8530, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.7083, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8597, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
24
./datasets/EV18/train/JPEGImages/seq6/frame024.png
26
./datasets/EV18/train/JPEGImages/seq6/frame026.png
93
./datasets/EV18/train/JPEGImages/seq7/frame093.png
103
./datasets/EV18/train/JPEGImages/seq7/frame103.png
124
./datasets/EV18/train/JPEGImages/seq11/frame124.png
125
./datasets/EV18/train/JPEGImages/seq11/frame125.png
127
./datasets/EV18/train/JPEGImages/seq1/frame127.png
133
./datasets/EV18/train/JPEGImages/seq1/frame133.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(126.3580, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.3962, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7257, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
115
./datasets/EV18/train/JPEGImages/seq3/frame115.png
117
./datasets/EV18/train/JPEGImages/seq3/frame117.png
97
./datasets/EV18/train/JPEGImages/seq7/frame097.png
106
./datasets/EV18/train/JPEGImages/seq7/frame106.png
115
./datasets/EV18/train/JPEGImages/seq16/frame115.png
116
./datasets/EV18/train/JPEGImages/seq16/frame116.png
93
./datasets/EV18/train/JPEGImages/seq13/frame093.png
99
./datasets/EV18/train/JPEGImages/seq13/frame099.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(179.6442, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.6100, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8303, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
41
./datasets/EV18/train/JPEGImages/seq11/frame041.png
49
./datasets/EV18/train/JPEGImages/seq11/frame049.png
91
./datasets/EV18/train/JPEGImages/seq12/frame091.png
96
./datasets/EV18/train/JPEGImages/seq12/frame096.png
103
./datasets/EV18/train/JPEGImages/seq14/frame103.png
105
./datasets/EV18/train/JPEGImages/seq14/frame105.png
78
./datasets/EV18/train/JPEGImages/seq7/frame078.png
81
./datasets/EV18/train/JPEGImages/seq7/frame081.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(96.5450, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.1702, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.6611, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
[05/26 01:43:02 d2.utils.events]:  eta: 3:53:54  iter: 99  total_loss: 2270  loss_ce: 229.4  loss_bbox: 1.651  loss_giou: 0.8496  loss_mask: 1.455  loss_dice: 0.9523  loss_ce_dn: 1.775  loss_mask_dn: 1.418  loss_dice_dn: 0.9538  loss_bbox_dn: 0.2245  loss_giou_dn: 0.4242  loss_ce_0: 204.3  loss_mask_0: 0.8046  loss_dice_0: 0.9372  loss_bbox_0: 1.657  loss_giou_0: 0.847  loss_ce_dn_0: 1.057  loss_mask_dn_0: 1.148  loss_dice_dn_0: 0.9363  loss_bbox_dn_0: 0.2245  loss_giou_dn_0: 0.4242  loss_ce_1: 183  loss_mask_1: 0.7535  loss_dice_1: 0.9435  loss_bbox_1: 1.666  loss_giou_1: 0.8425  loss_ce_dn_1: 1.101  loss_mask_dn_1: 1.063  loss_dice_dn_1: 0.9414  loss_bbox_dn_1: 0.2245  loss_giou_dn_1: 0.4242  loss_ce_2: 144  loss_mask_2: 0.8076  loss_dice_2: 0.9235  loss_bbox_2: 1.659  loss_giou_2: 0.8447  loss_ce_dn_2: 1.03  loss_mask_dn_2: 1.011  loss_dice_dn_2: 0.9223  loss_bbox_dn_2: 0.2245  loss_giou_dn_2: 0.4242  loss_ce_3: 228.8  loss_mask_3: 0.7555  loss_dice_3: 0.913  loss_bbox_3: 1.673  loss_giou_3: 0.8432  loss_ce_dn_3: 1.667  loss_mask_dn_3: 0.914  loss_dice_dn_3: 0.9146  loss_bbox_dn_3: 0.2245  loss_giou_dn_3: 0.4242  loss_ce_4: 140.7  loss_mask_4: 0.8972  loss_dice_4: 0.9192  loss_bbox_4: 1.672  loss_giou_4: 0.8431  loss_ce_dn_4: 1.151  loss_mask_dn_4: 1.062  loss_dice_dn_4: 0.9234  loss_bbox_dn_4: 0.2245  loss_giou_dn_4: 0.4242  loss_ce_5: 212.6  loss_mask_5: 0.7231  loss_dice_5: 0.9097  loss_bbox_5: 1.655  loss_giou_5: 0.8457  loss_ce_dn_5: 1.876  loss_mask_dn_5: 0.7656  loss_dice_dn_5: 0.9291  loss_bbox_dn_5: 0.2245  loss_giou_dn_5: 0.4242  loss_ce_6: 144.6  loss_mask_6: 0.823  loss_dice_6: 0.9399  loss_bbox_6: 1.653  loss_giou_6: 0.8472  loss_ce_dn_6: 1.343  loss_mask_dn_6: 0.8724  loss_dice_dn_6: 0.9442  loss_bbox_dn_6: 0.2245  loss_giou_dn_6: 0.4242  loss_ce_7: 236.6  loss_mask_7: 0.8808  loss_dice_7: 0.9349  loss_bbox_7: 1.666  loss_giou_7: 0.8424  loss_ce_dn_7: 1.947  loss_mask_dn_7: 0.9042  loss_dice_dn_7: 0.9357  loss_bbox_dn_7: 0.2245  loss_giou_dn_7: 0.4242  loss_ce_8: 235.8  loss_mask_8: 1.172  loss_dice_8: 0.9253  loss_bbox_8: 1.649  loss_giou_8: 0.8507  loss_ce_dn_8: 1.995  loss_mask_dn_8: 1.162  loss_dice_dn_8: 0.919  loss_bbox_dn_8: 0.2245  loss_giou_dn_8: 0.4242  loss_ce_interm: 204.4  loss_mask_interm: 0.8901  loss_dice_interm: 0.9453  loss_bbox_interm: 0.7062  loss_giou_interm: 1.059    time: 1.1657  last_time: 1.2038  data_time: 0.0137  last_data_time: 0.0131   lr: 0.0001  max_mem: 18844M
57
./datasets/EV18/train/JPEGImages/seq13/frame057.png
61
./datasets/EV18/train/JPEGImages/seq13/frame061.png
121
./datasets/EV18/train/JPEGImages/seq11/frame121.png
130
./datasets/EV18/train/JPEGImages/seq11/frame130.png
138
./datasets/EV18/train/JPEGImages/seq6/frame138.png
144
./datasets/EV18/train/JPEGImages/seq6/frame144.png
105
./datasets/EV18/train/JPEGImages/seq16/frame105.png
112
./datasets/EV18/train/JPEGImages/seq16/frame112.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(169.5337, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5225, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7938, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
2
./datasets/EV18/train/JPEGImages/seq4/frame002.png
8
./datasets/EV18/train/JPEGImages/seq4/frame008.png
81
./datasets/EV18/train/JPEGImages/seq1/frame081.png
85
./datasets/EV18/train/JPEGImages/seq1/frame085.png
3
./datasets/EV18/train/JPEGImages/seq13/frame003.png
6
./datasets/EV18/train/JPEGImages/seq13/frame006.png
89
./datasets/EV18/train/JPEGImages/seq10/frame089.png
92
./datasets/EV18/train/JPEGImages/seq10/frame092.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(160.7924, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.6762, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8495, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
81
./datasets/EV18/train/JPEGImages/seq1/frame081.png
88
./datasets/EV18/train/JPEGImages/seq1/frame088.png
76
./datasets/EV18/train/JPEGImages/seq14/frame076.png
86
./datasets/EV18/train/JPEGImages/seq14/frame086.png
68
./datasets/EV18/train/JPEGImages/seq4/frame068.png
75
./datasets/EV18/train/JPEGImages/seq4/frame075.png
40
./datasets/EV18/train/JPEGImages/seq10/frame040.png
49
./datasets/EV18/train/JPEGImages/seq10/frame049.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(162.3109, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5379, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8321, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
124
./datasets/EV18/train/JPEGImages/seq3/frame124.png
131
./datasets/EV18/train/JPEGImages/seq3/frame131.png
40
./datasets/EV18/train/JPEGImages/seq12/frame040.png
43
./datasets/EV18/train/JPEGImages/seq12/frame043.png
51
./datasets/EV18/train/JPEGImages/seq4/frame051.png
60
./datasets/EV18/train/JPEGImages/seq4/frame060.png
13
./datasets/EV18/train/JPEGImages/seq3/frame013.png
21
./datasets/EV18/train/JPEGImages/seq3/frame021.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(144.7959, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.2870, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.6964, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
108
./datasets/EV18/train/JPEGImages/seq6/frame108.png
115
./datasets/EV18/train/JPEGImages/seq6/frame115.png
47
./datasets/EV18/train/JPEGImages/seq11/frame047.png
48
./datasets/EV18/train/JPEGImages/seq11/frame048.png
64
./datasets/EV18/train/JPEGImages/seq6/frame064.png
71
./datasets/EV18/train/JPEGImages/seq6/frame071.png
76
./datasets/EV18/train/JPEGImages/seq16/frame076.png
85
./datasets/EV18/train/JPEGImages/seq16/frame085.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(158.4944, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5908, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8057, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
57
./datasets/EV18/train/JPEGImages/seq7/frame057.png
65
./datasets/EV18/train/JPEGImages/seq7/frame065.png
1
./datasets/EV18/train/JPEGImages/seq1/frame001.png
4
./datasets/EV18/train/JPEGImages/seq1/frame004.png
89
./datasets/EV18/train/JPEGImages/seq16/frame089.png
93
./datasets/EV18/train/JPEGImages/seq16/frame093.png
142
./datasets/EV18/train/JPEGImages/seq1/frame142.png
143
./datasets/EV18/train/JPEGImages/seq1/frame143.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(158.6870, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.6764, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8170, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
56
./datasets/EV18/train/JPEGImages/seq16/frame056.png
57
./datasets/EV18/train/JPEGImages/seq16/frame057.png
0
./datasets/EV18/train/JPEGImages/seq10/frame000.png
8
./datasets/EV18/train/JPEGImages/seq10/frame008.png
115
./datasets/EV18/train/JPEGImages/seq3/frame115.png
117
./datasets/EV18/train/JPEGImages/seq3/frame117.png
130
./datasets/EV18/train/JPEGImages/seq13/frame130.png
136
./datasets/EV18/train/JPEGImages/seq13/frame136.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(191.4019, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5707, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8040, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
107
./datasets/EV18/train/JPEGImages/seq3/frame107.png
115
./datasets/EV18/train/JPEGImages/seq3/frame115.png
107
./datasets/EV18/train/JPEGImages/seq14/frame107.png
109
./datasets/EV18/train/JPEGImages/seq14/frame109.png
38
./datasets/EV18/train/JPEGImages/seq10/frame038.png
40
./datasets/EV18/train/JPEGImages/seq10/frame040.png
5
./datasets/EV18/train/JPEGImages/seq3/frame005.png
8
./datasets/EV18/train/JPEGImages/seq3/frame008.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(161.8905, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.7347, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8629, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
51
./datasets/EV18/train/JPEGImages/seq12/frame051.png
56
./datasets/EV18/train/JPEGImages/seq12/frame056.png
97
./datasets/EV18/train/JPEGImages/seq1/frame097.png
99
./datasets/EV18/train/JPEGImages/seq1/frame099.png
87
./datasets/EV18/train/JPEGImages/seq13/frame087.png
89
./datasets/EV18/train/JPEGImages/seq13/frame089.png
144
./datasets/EV18/train/JPEGImages/seq16/frame144.png
148
./datasets/EV18/train/JPEGImages/seq16/frame148.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(122.1150, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.3970, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7128, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
66
./datasets/EV18/train/JPEGImages/seq11/frame066.png
76
./datasets/EV18/train/JPEGImages/seq11/frame076.png
3
./datasets/EV18/train/JPEGImages/seq4/frame003.png
6
./datasets/EV18/train/JPEGImages/seq4/frame006.png
6
./datasets/EV18/train/JPEGImages/seq7/frame006.png
7
./datasets/EV18/train/JPEGImages/seq7/frame007.png
136
./datasets/EV18/train/JPEGImages/seq13/frame136.png
140
./datasets/EV18/train/JPEGImages/seq13/frame140.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(207.6596, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5526, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7847, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
140
./datasets/EV18/train/JPEGImages/seq14/frame140.png
146
./datasets/EV18/train/JPEGImages/seq14/frame146.png
63
./datasets/EV18/train/JPEGImages/seq7/frame063.png
69
./datasets/EV18/train/JPEGImages/seq7/frame069.png
0
./datasets/EV18/train/JPEGImages/seq4/frame000.png
10
./datasets/EV18/train/JPEGImages/seq4/frame010.png
25
./datasets/EV18/train/JPEGImages/seq12/frame025.png
28
./datasets/EV18/train/JPEGImages/seq12/frame028.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(126.7637, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.2784, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7417, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
16
./datasets/EV18/train/JPEGImages/seq6/frame016.png
19
./datasets/EV18/train/JPEGImages/seq6/frame019.png
8
./datasets/EV18/train/JPEGImages/seq10/frame008.png
13
./datasets/EV18/train/JPEGImages/seq10/frame013.png
0
./datasets/EV18/train/JPEGImages/seq6/frame000.png
5
./datasets/EV18/train/JPEGImages/seq6/frame005.png
36
./datasets/EV18/train/JPEGImages/seq11/frame036.png
37
./datasets/EV18/train/JPEGImages/seq11/frame037.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(198.4475, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.7660, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8565, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
122
./datasets/EV18/train/JPEGImages/seq12/frame122.png
132
./datasets/EV18/train/JPEGImages/seq12/frame132.png
138
./datasets/EV18/train/JPEGImages/seq13/frame138.png
139
./datasets/EV18/train/JPEGImages/seq13/frame139.png
66
./datasets/EV18/train/JPEGImages/seq4/frame066.png
72
./datasets/EV18/train/JPEGImages/seq4/frame072.png
20
./datasets/EV18/train/JPEGImages/seq10/frame020.png
25
./datasets/EV18/train/JPEGImages/seq10/frame025.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(127.3277, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.3678, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7587, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
132
./datasets/EV18/train/JPEGImages/seq3/frame132.png
135
./datasets/EV18/train/JPEGImages/seq3/frame135.png
64
./datasets/EV18/train/JPEGImages/seq12/frame064.png
69
./datasets/EV18/train/JPEGImages/seq12/frame069.png
17
./datasets/EV18/train/JPEGImages/seq1/frame017.png
24
./datasets/EV18/train/JPEGImages/seq1/frame024.png
23
./datasets/EV18/train/JPEGImages/seq4/frame023.png
28
./datasets/EV18/train/JPEGImages/seq4/frame028.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(140.4273, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.4379, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7574, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
143
./datasets/EV18/train/JPEGImages/seq14/frame143.png
146
./datasets/EV18/train/JPEGImages/seq14/frame146.png
43
./datasets/EV18/train/JPEGImages/seq1/frame043.png
50
./datasets/EV18/train/JPEGImages/seq1/frame050.png
98
./datasets/EV18/train/JPEGImages/seq16/frame098.png
99
./datasets/EV18/train/JPEGImages/seq16/frame099.png
115
./datasets/EV18/train/JPEGImages/seq12/frame115.png
118
./datasets/EV18/train/JPEGImages/seq12/frame118.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(192.2505, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.6998, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8469, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
14
./datasets/EV18/train/JPEGImages/seq11/frame014.png
19
./datasets/EV18/train/JPEGImages/seq11/frame019.png
70
./datasets/EV18/train/JPEGImages/seq7/frame070.png
78
./datasets/EV18/train/JPEGImages/seq7/frame078.png
26
./datasets/EV18/train/JPEGImages/seq13/frame026.png
29
./datasets/EV18/train/JPEGImages/seq13/frame029.png
9
./datasets/EV18/train/JPEGImages/seq12/frame009.png
19
./datasets/EV18/train/JPEGImages/seq12/frame019.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(248.0971, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.6449, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8183, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
59
./datasets/EV18/train/JPEGImages/seq4/frame059.png
68
./datasets/EV18/train/JPEGImages/seq4/frame068.png
82
./datasets/EV18/train/JPEGImages/seq6/frame082.png
83
./datasets/EV18/train/JPEGImages/seq6/frame083.png
11
./datasets/EV18/train/JPEGImages/seq11/frame011.png
12
./datasets/EV18/train/JPEGImages/seq11/frame012.png
15
./datasets/EV18/train/JPEGImages/seq10/frame015.png
22
./datasets/EV18/train/JPEGImages/seq10/frame022.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(129.9577, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.6820, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8635, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
3
./datasets/EV18/train/JPEGImages/seq14/frame003.png
13
./datasets/EV18/train/JPEGImages/seq14/frame013.png
92
./datasets/EV18/train/JPEGImages/seq13/frame092.png
100
./datasets/EV18/train/JPEGImages/seq13/frame100.png
3
./datasets/EV18/train/JPEGImages/seq7/frame003.png
10
./datasets/EV18/train/JPEGImages/seq7/frame010.png
114
./datasets/EV18/train/JPEGImages/seq10/frame114.png
117
./datasets/EV18/train/JPEGImages/seq10/frame117.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(109.7896, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.2721, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.6896, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
118
./datasets/EV18/train/JPEGImages/seq7/frame118.png
128
./datasets/EV18/train/JPEGImages/seq7/frame128.png
21
./datasets/EV18/train/JPEGImages/seq3/frame021.png
24
./datasets/EV18/train/JPEGImages/seq3/frame024.png
35
./datasets/EV18/train/JPEGImages/seq14/frame035.png
40
./datasets/EV18/train/JPEGImages/seq14/frame040.png
137
./datasets/EV18/train/JPEGImages/seq16/frame137.png
145
./datasets/EV18/train/JPEGImages/seq16/frame145.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(207.2345, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5326, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7967, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
30
./datasets/EV18/train/JPEGImages/seq6/frame030.png
37
./datasets/EV18/train/JPEGImages/seq6/frame037.png
105
./datasets/EV18/train/JPEGImages/seq4/frame105.png
109
./datasets/EV18/train/JPEGImages/seq4/frame109.png
125
./datasets/EV18/train/JPEGImages/seq1/frame125.png
132
./datasets/EV18/train/JPEGImages/seq1/frame132.png
99
./datasets/EV18/train/JPEGImages/seq16/frame099.png
106
./datasets/EV18/train/JPEGImages/seq16/frame106.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(105.2283, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5225, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7700, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
[05/26 01:43:26 d2.utils.events]:  eta: 3:55:21  iter: 119  total_loss: 2291  loss_ce: 227.8  loss_bbox: 1.703  loss_giou: 0.8468  loss_mask: 1.455  loss_dice: 0.9463  loss_ce_dn: 1.776  loss_mask_dn: 1.481  loss_dice_dn: 0.9496  loss_bbox_dn: 0.2212  loss_giou_dn: 0.4275  loss_ce_0: 210.9  loss_mask_0: 0.8454  loss_dice_0: 0.9316  loss_bbox_0: 1.709  loss_giou_0: 0.8446  loss_ce_dn_0: 1.059  loss_mask_dn_0: 1.131  loss_dice_dn_0: 0.9335  loss_bbox_dn_0: 0.2212  loss_giou_dn_0: 0.4275  loss_ce_1: 187.3  loss_mask_1: 0.7636  loss_dice_1: 0.9313  loss_bbox_1: 1.71  loss_giou_1: 0.8431  loss_ce_dn_1: 1.114  loss_mask_dn_1: 1.079  loss_dice_dn_1: 0.9381  loss_bbox_dn_1: 0.2212  loss_giou_dn_1: 0.4275  loss_ce_2: 146.2  loss_mask_2: 0.8109  loss_dice_2: 0.9248  loss_bbox_2: 1.71  loss_giou_2: 0.843  loss_ce_dn_2: 1.056  loss_mask_dn_2: 0.9818  loss_dice_dn_2: 0.9274  loss_bbox_dn_2: 0.2212  loss_giou_dn_2: 0.4275  loss_ce_3: 227.7  loss_mask_3: 0.7436  loss_dice_3: 0.9084  loss_bbox_3: 1.713  loss_giou_3: 0.8414  loss_ce_dn_3: 1.736  loss_mask_dn_3: 0.882  loss_dice_dn_3: 0.9087  loss_bbox_dn_3: 0.2212  loss_giou_dn_3: 0.4275  loss_ce_4: 147.5  loss_mask_4: 0.8866  loss_dice_4: 0.9229  loss_bbox_4: 1.708  loss_giou_4: 0.8456  loss_ce_dn_4: 1.204  loss_mask_dn_4: 1.065  loss_dice_dn_4: 0.9269  loss_bbox_dn_4: 0.2212  loss_giou_dn_4: 0.4275  loss_ce_5: 220.9  loss_mask_5: 0.7228  loss_dice_5: 0.9228  loss_bbox_5: 1.704  loss_giou_5: 0.8419  loss_ce_dn_5: 1.966  loss_mask_dn_5: 0.775  loss_dice_dn_5: 0.9327  loss_bbox_dn_5: 0.2212  loss_giou_dn_5: 0.4275  loss_ce_6: 144.5  loss_mask_6: 0.8291  loss_dice_6: 0.9385  loss_bbox_6: 1.704  loss_giou_6: 0.8451  loss_ce_dn_6: 1.31  loss_mask_dn_6: 0.8884  loss_dice_dn_6: 0.9403  loss_bbox_dn_6: 0.2212  loss_giou_dn_6: 0.4275  loss_ce_7: 236.1  loss_mask_7: 0.9211  loss_dice_7: 0.9356  loss_bbox_7: 1.708  loss_giou_7: 0.8403  loss_ce_dn_7: 1.911  loss_mask_dn_7: 0.9435  loss_dice_dn_7: 0.9357  loss_bbox_dn_7: 0.2212  loss_giou_dn_7: 0.4275  loss_ce_8: 238.8  loss_mask_8: 1.189  loss_dice_8: 0.9308  loss_bbox_8: 1.702  loss_giou_8: 0.8449  loss_ce_dn_8: 2.003  loss_mask_dn_8: 1.203  loss_dice_dn_8: 0.9293  loss_bbox_dn_8: 0.2212  loss_giou_dn_8: 0.4275  loss_ce_interm: 211  loss_mask_interm: 0.9555  loss_dice_interm: 0.9314  loss_bbox_interm: 0.7362  loss_giou_interm: 1.063    time: 1.1697  last_time: 1.2628  data_time: 0.0147  last_data_time: 0.0183   lr: 0.0001  max_mem: 18844M
30
./datasets/EV18/train/JPEGImages/seq11/frame030.png
36
./datasets/EV18/train/JPEGImages/seq11/frame036.png
67
./datasets/EV18/train/JPEGImages/seq14/frame067.png
76
./datasets/EV18/train/JPEGImages/seq14/frame076.png
74
./datasets/EV18/train/JPEGImages/seq1/frame074.png
82
./datasets/EV18/train/JPEGImages/seq1/frame082.png
53
./datasets/EV18/train/JPEGImages/seq3/frame053.png
57
./datasets/EV18/train/JPEGImages/seq3/frame057.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(246.3159, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.6902, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8850, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
57
./datasets/EV18/train/JPEGImages/seq10/frame057.png
58
./datasets/EV18/train/JPEGImages/seq10/frame058.png
143
./datasets/EV18/train/JPEGImages/seq7/frame143.png
146
./datasets/EV18/train/JPEGImages/seq7/frame146.png
77
./datasets/EV18/train/JPEGImages/seq1/frame077.png
79
./datasets/EV18/train/JPEGImages/seq1/frame079.png
2
./datasets/EV18/train/JPEGImages/seq12/frame002.png
7
./datasets/EV18/train/JPEGImages/seq12/frame007.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(162.6560, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.6649, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8300, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
105
./datasets/EV18/train/JPEGImages/seq6/frame105.png
114
./datasets/EV18/train/JPEGImages/seq6/frame114.png
11
./datasets/EV18/train/JPEGImages/seq7/frame011.png
16
./datasets/EV18/train/JPEGImages/seq7/frame016.png
32
./datasets/EV18/train/JPEGImages/seq6/frame032.png
35
./datasets/EV18/train/JPEGImages/seq6/frame035.png
128
./datasets/EV18/train/JPEGImages/seq16/frame128.png
134
./datasets/EV18/train/JPEGImages/seq16/frame134.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(163.3646, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.6038, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8106, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
0
./datasets/EV18/train/JPEGImages/seq11/frame000.png
5
./datasets/EV18/train/JPEGImages/seq11/frame005.png
137
./datasets/EV18/train/JPEGImages/seq13/frame137.png
143
./datasets/EV18/train/JPEGImages/seq13/frame143.png
131
./datasets/EV18/train/JPEGImages/seq14/frame131.png
133
./datasets/EV18/train/JPEGImages/seq14/frame133.png
123
./datasets/EV18/train/JPEGImages/seq14/frame123.png
130
./datasets/EV18/train/JPEGImages/seq14/frame130.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(151.5901, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5421, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8007, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
52
./datasets/EV18/train/JPEGImages/seq3/frame052.png
60
./datasets/EV18/train/JPEGImages/seq3/frame060.png
95
./datasets/EV18/train/JPEGImages/seq10/frame095.png
97
./datasets/EV18/train/JPEGImages/seq10/frame097.png
111
./datasets/EV18/train/JPEGImages/seq4/frame111.png
112
./datasets/EV18/train/JPEGImages/seq4/frame112.png
134
./datasets/EV18/train/JPEGImages/seq13/frame134.png
141
./datasets/EV18/train/JPEGImages/seq13/frame141.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(125.7351, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.4025, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7535, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
19
./datasets/EV18/train/JPEGImages/seq4/frame019.png
20
./datasets/EV18/train/JPEGImages/seq4/frame020.png
83
./datasets/EV18/train/JPEGImages/seq16/frame083.png
89
./datasets/EV18/train/JPEGImages/seq16/frame089.png
124
./datasets/EV18/train/JPEGImages/seq10/frame124.png
134
./datasets/EV18/train/JPEGImages/seq10/frame134.png
90
./datasets/EV18/train/JPEGImages/seq6/frame090.png
95
./datasets/EV18/train/JPEGImages/seq6/frame095.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(131.7633, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.4051, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7549, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
13
./datasets/EV18/train/JPEGImages/seq14/frame013.png
21
./datasets/EV18/train/JPEGImages/seq14/frame021.png
12
./datasets/EV18/train/JPEGImages/seq11/frame012.png
15
./datasets/EV18/train/JPEGImages/seq11/frame015.png
60
./datasets/EV18/train/JPEGImages/seq12/frame060.png
63
./datasets/EV18/train/JPEGImages/seq12/frame063.png
34
./datasets/EV18/train/JPEGImages/seq3/frame034.png
43
./datasets/EV18/train/JPEGImages/seq3/frame043.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(180.0569, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.4639, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7810, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
135
./datasets/EV18/train/JPEGImages/seq6/frame135.png
142
./datasets/EV18/train/JPEGImages/seq6/frame142.png
8
./datasets/EV18/train/JPEGImages/seq12/frame008.png
13
./datasets/EV18/train/JPEGImages/seq12/frame013.png
16
./datasets/EV18/train/JPEGImages/seq11/frame016.png
21
./datasets/EV18/train/JPEGImages/seq11/frame021.png
74
./datasets/EV18/train/JPEGImages/seq4/frame074.png
84
./datasets/EV18/train/JPEGImages/seq4/frame084.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(140.5719, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.3631, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7525, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
133
./datasets/EV18/train/JPEGImages/seq1/frame133.png
136
./datasets/EV18/train/JPEGImages/seq1/frame136.png
135
./datasets/EV18/train/JPEGImages/seq7/frame135.png
144
./datasets/EV18/train/JPEGImages/seq7/frame144.png
56
./datasets/EV18/train/JPEGImages/seq10/frame056.png
65
./datasets/EV18/train/JPEGImages/seq10/frame065.png
62
./datasets/EV18/train/JPEGImages/seq6/frame062.png
69
./datasets/EV18/train/JPEGImages/seq6/frame069.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(195.6313, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.7108, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8503, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
136
./datasets/EV18/train/JPEGImages/seq13/frame136.png
138
./datasets/EV18/train/JPEGImages/seq13/frame138.png
63
./datasets/EV18/train/JPEGImages/seq14/frame063.png
67
./datasets/EV18/train/JPEGImages/seq14/frame067.png
66
./datasets/EV18/train/JPEGImages/seq4/frame066.png
76
./datasets/EV18/train/JPEGImages/seq4/frame076.png
81
./datasets/EV18/train/JPEGImages/seq11/frame081.png
82
./datasets/EV18/train/JPEGImages/seq11/frame082.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(106.9842, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.3274, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7331, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
54
./datasets/EV18/train/JPEGImages/seq3/frame054.png
64
./datasets/EV18/train/JPEGImages/seq3/frame064.png
17
./datasets/EV18/train/JPEGImages/seq13/frame017.png
21
./datasets/EV18/train/JPEGImages/seq13/frame021.png
76
./datasets/EV18/train/JPEGImages/seq16/frame076.png
84
./datasets/EV18/train/JPEGImages/seq16/frame084.png
114
./datasets/EV18/train/JPEGImages/seq7/frame114.png
121
./datasets/EV18/train/JPEGImages/seq7/frame121.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(189.8904, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5498, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8092, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
60
./datasets/EV18/train/JPEGImages/seq10/frame060.png
63
./datasets/EV18/train/JPEGImages/seq10/frame063.png
15
./datasets/EV18/train/JPEGImages/seq7/frame015.png
17
./datasets/EV18/train/JPEGImages/seq7/frame017.png
128
./datasets/EV18/train/JPEGImages/seq3/frame128.png
136
./datasets/EV18/train/JPEGImages/seq3/frame136.png
23
./datasets/EV18/train/JPEGImages/seq7/frame023.png
24
./datasets/EV18/train/JPEGImages/seq7/frame024.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(130.8873, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.2369, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.6511, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
21
./datasets/EV18/train/JPEGImages/seq16/frame021.png
25
./datasets/EV18/train/JPEGImages/seq16/frame025.png
143
./datasets/EV18/train/JPEGImages/seq3/frame143.png
148
./datasets/EV18/train/JPEGImages/seq3/frame148.png
61
./datasets/EV18/train/JPEGImages/seq14/frame061.png
69
./datasets/EV18/train/JPEGImages/seq14/frame069.png
109
./datasets/EV18/train/JPEGImages/seq12/frame109.png
119
./datasets/EV18/train/JPEGImages/seq12/frame119.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(134.0802, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.3925, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7442, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
46
./datasets/EV18/train/JPEGImages/seq1/frame046.png
48
./datasets/EV18/train/JPEGImages/seq1/frame048.png
1
./datasets/EV18/train/JPEGImages/seq11/frame001.png
3
./datasets/EV18/train/JPEGImages/seq11/frame003.png
3
./datasets/EV18/train/JPEGImages/seq12/frame003.png
13
./datasets/EV18/train/JPEGImages/seq12/frame013.png
49
./datasets/EV18/train/JPEGImages/seq14/frame049.png
53
./datasets/EV18/train/JPEGImages/seq14/frame053.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(153.2148, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5678, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8169, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
117
./datasets/EV18/train/JPEGImages/seq13/frame117.png
127
./datasets/EV18/train/JPEGImages/seq13/frame127.png
3
./datasets/EV18/train/JPEGImages/seq1/frame003.png
11
./datasets/EV18/train/JPEGImages/seq1/frame011.png
105
./datasets/EV18/train/JPEGImages/seq11/frame105.png
110
./datasets/EV18/train/JPEGImages/seq11/frame110.png
63
./datasets/EV18/train/JPEGImages/seq4/frame063.png
66
./datasets/EV18/train/JPEGImages/seq4/frame066.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(124.4772, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.4953, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7679, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
1
./datasets/EV18/train/JPEGImages/seq6/frame001.png
2
./datasets/EV18/train/JPEGImages/seq6/frame002.png
0
./datasets/EV18/train/JPEGImages/seq16/frame000.png
1
./datasets/EV18/train/JPEGImages/seq16/frame001.png
63
./datasets/EV18/train/JPEGImages/seq12/frame063.png
71
./datasets/EV18/train/JPEGImages/seq12/frame071.png
143
./datasets/EV18/train/JPEGImages/seq13/frame143.png
144
./datasets/EV18/train/JPEGImages/seq13/frame144.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(135.4808, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.4288, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7931, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
103
./datasets/EV18/train/JPEGImages/seq1/frame103.png
109
./datasets/EV18/train/JPEGImages/seq1/frame109.png
87
./datasets/EV18/train/JPEGImages/seq10/frame087.png
88
./datasets/EV18/train/JPEGImages/seq10/frame088.png
92
./datasets/EV18/train/JPEGImages/seq3/frame092.png
95
./datasets/EV18/train/JPEGImages/seq3/frame095.png
132
./datasets/EV18/train/JPEGImages/seq14/frame132.png
138
./datasets/EV18/train/JPEGImages/seq14/frame138.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(161.2299, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.8742, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8959, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
71
./datasets/EV18/train/JPEGImages/seq7/frame071.png
72
./datasets/EV18/train/JPEGImages/seq7/frame072.png
122
./datasets/EV18/train/JPEGImages/seq1/frame122.png
131
./datasets/EV18/train/JPEGImages/seq1/frame131.png
111
./datasets/EV18/train/JPEGImages/seq14/frame111.png
113
./datasets/EV18/train/JPEGImages/seq14/frame113.png
94
./datasets/EV18/train/JPEGImages/seq10/frame094.png
98
./datasets/EV18/train/JPEGImages/seq10/frame098.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(116.2427, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.4324, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7512, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
69
./datasets/EV18/train/JPEGImages/seq3/frame069.png
70
./datasets/EV18/train/JPEGImages/seq3/frame070.png
102
./datasets/EV18/train/JPEGImages/seq6/frame102.png
108
./datasets/EV18/train/JPEGImages/seq6/frame108.png
1
./datasets/EV18/train/JPEGImages/seq6/frame001.png
11
./datasets/EV18/train/JPEGImages/seq6/frame011.png
18
./datasets/EV18/train/JPEGImages/seq12/frame018.png
22
./datasets/EV18/train/JPEGImages/seq12/frame022.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(196.7899, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.7509, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8844, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
79
./datasets/EV18/train/JPEGImages/seq10/frame079.png
89
./datasets/EV18/train/JPEGImages/seq10/frame089.png
136
./datasets/EV18/train/JPEGImages/seq12/frame136.png
143
./datasets/EV18/train/JPEGImages/seq12/frame143.png
113
./datasets/EV18/train/JPEGImages/seq7/frame113.png
120
./datasets/EV18/train/JPEGImages/seq7/frame120.png
104
./datasets/EV18/train/JPEGImages/seq12/frame104.png
108
./datasets/EV18/train/JPEGImages/seq12/frame108.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(284.7801, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5884, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8402, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
[05/26 01:43:50 d2.utils.events]:  eta: 3:55:02  iter: 139  total_loss: 2241  loss_ce: 224.7  loss_bbox: 1.664  loss_giou: 0.8431  loss_mask: 1.52  loss_dice: 0.9502  loss_ce_dn: 1.725  loss_mask_dn: 1.513  loss_dice_dn: 0.9542  loss_bbox_dn: 0.2262  loss_giou_dn: 0.4282  loss_ce_0: 206.7  loss_mask_0: 0.8397  loss_dice_0: 0.9297  loss_bbox_0: 1.667  loss_giou_0: 0.8403  loss_ce_dn_0: 1.095  loss_mask_dn_0: 1.169  loss_dice_dn_0: 0.9341  loss_bbox_dn_0: 0.2262  loss_giou_dn_0: 0.4282  loss_ce_1: 181.9  loss_mask_1: 0.7663  loss_dice_1: 0.9394  loss_bbox_1: 1.671  loss_giou_1: 0.8402  loss_ce_dn_1: 1.136  loss_mask_dn_1: 1.092  loss_dice_dn_1: 0.9364  loss_bbox_dn_1: 0.2262  loss_giou_dn_1: 0.4282  loss_ce_2: 144.1  loss_mask_2: 0.7993  loss_dice_2: 0.9185  loss_bbox_2: 1.67  loss_giou_2: 0.8406  loss_ce_dn_2: 1.06  loss_mask_dn_2: 0.9809  loss_dice_dn_2: 0.917  loss_bbox_dn_2: 0.2262  loss_giou_dn_2: 0.4282  loss_ce_3: 222.9  loss_mask_3: 0.7455  loss_dice_3: 0.9035  loss_bbox_3: 1.67  loss_giou_3: 0.8409  loss_ce_dn_3: 1.719  loss_mask_dn_3: 0.868  loss_dice_dn_3: 0.911  loss_bbox_dn_3: 0.2262  loss_giou_dn_3: 0.4282  loss_ce_4: 140.3  loss_mask_4: 0.9027  loss_dice_4: 0.9204  loss_bbox_4: 1.67  loss_giou_4: 0.8417  loss_ce_dn_4: 1.145  loss_mask_dn_4: 1.065  loss_dice_dn_4: 0.9165  loss_bbox_dn_4: 0.2262  loss_giou_dn_4: 0.4282  loss_ce_5: 215.6  loss_mask_5: 0.7238  loss_dice_5: 0.9166  loss_bbox_5: 1.665  loss_giou_5: 0.8414  loss_ce_dn_5: 1.966  loss_mask_dn_5: 0.7728  loss_dice_dn_5: 0.9281  loss_bbox_dn_5: 0.2262  loss_giou_dn_5: 0.4282  loss_ce_6: 140.8  loss_mask_6: 0.8235  loss_dice_6: 0.9387  loss_bbox_6: 1.666  loss_giou_6: 0.8415  loss_ce_dn_6: 1.308  loss_mask_dn_6: 0.8902  loss_dice_dn_6: 0.9376  loss_bbox_dn_6: 0.2262  loss_giou_dn_6: 0.4282  loss_ce_7: 230.6  loss_mask_7: 0.9238  loss_dice_7: 0.9433  loss_bbox_7: 1.665  loss_giou_7: 0.8403  loss_ce_dn_7: 1.865  loss_mask_dn_7: 0.9496  loss_dice_dn_7: 0.9346  loss_bbox_dn_7: 0.2262  loss_giou_dn_7: 0.4282  loss_ce_8: 235.6  loss_mask_8: 1.202  loss_dice_8: 0.9304  loss_bbox_8: 1.663  loss_giou_8: 0.8446  loss_ce_dn_8: 1.93  loss_mask_dn_8: 1.219  loss_dice_dn_8: 0.9258  loss_bbox_dn_8: 0.2262  loss_giou_dn_8: 0.4282  loss_ce_interm: 206.8  loss_mask_interm: 0.9488  loss_dice_interm: 0.9409  loss_bbox_interm: 0.7256  loss_giou_interm: 1.067    time: 1.1709  last_time: 1.2229  data_time: 0.0149  last_data_time: 0.0149   lr: 0.0001  max_mem: 18844M
92
./datasets/EV18/train/JPEGImages/seq4/frame092.png
102
./datasets/EV18/train/JPEGImages/seq4/frame102.png
30
./datasets/EV18/train/JPEGImages/seq11/frame030.png
32
./datasets/EV18/train/JPEGImages/seq11/frame032.png
16
./datasets/EV18/train/JPEGImages/seq10/frame016.png
26
./datasets/EV18/train/JPEGImages/seq10/frame026.png
65
./datasets/EV18/train/JPEGImages/seq16/frame065.png
66
./datasets/EV18/train/JPEGImages/seq16/frame066.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(141.4307, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5391, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7747, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
25
./datasets/EV18/train/JPEGImages/seq6/frame025.png
27
./datasets/EV18/train/JPEGImages/seq6/frame027.png
84
./datasets/EV18/train/JPEGImages/seq3/frame084.png
86
./datasets/EV18/train/JPEGImages/seq3/frame086.png
35
./datasets/EV18/train/JPEGImages/seq13/frame035.png
36
./datasets/EV18/train/JPEGImages/seq13/frame036.png
119
./datasets/EV18/train/JPEGImages/seq3/frame119.png
121
./datasets/EV18/train/JPEGImages/seq3/frame121.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(149.9701, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.4995, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7955, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
22
./datasets/EV18/train/JPEGImages/seq16/frame022.png
25
./datasets/EV18/train/JPEGImages/seq16/frame025.png
10
./datasets/EV18/train/JPEGImages/seq4/frame010.png
17
./datasets/EV18/train/JPEGImages/seq4/frame017.png
110
./datasets/EV18/train/JPEGImages/seq1/frame110.png
111
./datasets/EV18/train/JPEGImages/seq1/frame111.png
92
./datasets/EV18/train/JPEGImages/seq13/frame092.png
102
./datasets/EV18/train/JPEGImages/seq13/frame102.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(121.7917, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.4790, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7437, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
136
./datasets/EV18/train/JPEGImages/seq4/frame136.png
140
./datasets/EV18/train/JPEGImages/seq4/frame140.png
67
./datasets/EV18/train/JPEGImages/seq16/frame067.png
76
./datasets/EV18/train/JPEGImages/seq16/frame076.png
31
./datasets/EV18/train/JPEGImages/seq11/frame031.png
36
./datasets/EV18/train/JPEGImages/seq11/frame036.png
115
./datasets/EV18/train/JPEGImages/seq7/frame115.png
122
./datasets/EV18/train/JPEGImages/seq7/frame122.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(208.2232, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5714, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7836, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
132
./datasets/EV18/train/JPEGImages/seq11/frame132.png
136
./datasets/EV18/train/JPEGImages/seq11/frame136.png
115
./datasets/EV18/train/JPEGImages/seq1/frame115.png
119
./datasets/EV18/train/JPEGImages/seq1/frame119.png
59
./datasets/EV18/train/JPEGImages/seq1/frame059.png
63
./datasets/EV18/train/JPEGImages/seq1/frame063.png
3
./datasets/EV18/train/JPEGImages/seq14/frame003.png
13
./datasets/EV18/train/JPEGImages/seq14/frame013.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(140.1346, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5295, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7319, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
58
./datasets/EV18/train/JPEGImages/seq12/frame058.png
59
./datasets/EV18/train/JPEGImages/seq12/frame059.png
24
./datasets/EV18/train/JPEGImages/seq1/frame024.png
27
./datasets/EV18/train/JPEGImages/seq1/frame027.png
12
./datasets/EV18/train/JPEGImages/seq4/frame012.png
21
./datasets/EV18/train/JPEGImages/seq4/frame021.png
138
./datasets/EV18/train/JPEGImages/seq6/frame138.png
142
./datasets/EV18/train/JPEGImages/seq6/frame142.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(148.0631, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.6542, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8171, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
95
./datasets/EV18/train/JPEGImages/seq4/frame095.png
97
./datasets/EV18/train/JPEGImages/seq4/frame097.png
88
./datasets/EV18/train/JPEGImages/seq16/frame088.png
93
./datasets/EV18/train/JPEGImages/seq16/frame093.png
33
./datasets/EV18/train/JPEGImages/seq3/frame033.png
34
./datasets/EV18/train/JPEGImages/seq3/frame034.png
106
./datasets/EV18/train/JPEGImages/seq6/frame106.png
109
./datasets/EV18/train/JPEGImages/seq6/frame109.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(156.7042, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.6332, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8261, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
53
./datasets/EV18/train/JPEGImages/seq16/frame053.png
63
./datasets/EV18/train/JPEGImages/seq16/frame063.png
11
./datasets/EV18/train/JPEGImages/seq11/frame011.png
19
./datasets/EV18/train/JPEGImages/seq11/frame019.png
2
./datasets/EV18/train/JPEGImages/seq10/frame002.png
8
./datasets/EV18/train/JPEGImages/seq10/frame008.png
104
./datasets/EV18/train/JPEGImages/seq11/frame104.png
105
./datasets/EV18/train/JPEGImages/seq11/frame105.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(205.5655, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.7445, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8527, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
131
./datasets/EV18/train/JPEGImages/seq6/frame131.png
132
./datasets/EV18/train/JPEGImages/seq6/frame132.png
60
./datasets/EV18/train/JPEGImages/seq13/frame060.png
70
./datasets/EV18/train/JPEGImages/seq13/frame070.png
19
./datasets/EV18/train/JPEGImages/seq7/frame019.png
28
./datasets/EV18/train/JPEGImages/seq7/frame028.png
12
./datasets/EV18/train/JPEGImages/seq13/frame012.png
22
./datasets/EV18/train/JPEGImages/seq13/frame022.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(141.0664, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.3089, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7150, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
56
./datasets/EV18/train/JPEGImages/seq14/frame056.png
59
./datasets/EV18/train/JPEGImages/seq14/frame059.png
118
./datasets/EV18/train/JPEGImages/seq13/frame118.png
126
./datasets/EV18/train/JPEGImages/seq13/frame126.png
25
./datasets/EV18/train/JPEGImages/seq12/frame025.png
33
./datasets/EV18/train/JPEGImages/seq12/frame033.png
98
./datasets/EV18/train/JPEGImages/seq12/frame098.png
105
./datasets/EV18/train/JPEGImages/seq12/frame105.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(129.3220, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.3975, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7509, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
38
./datasets/EV18/train/JPEGImages/seq14/frame038.png
42
./datasets/EV18/train/JPEGImages/seq14/frame042.png
104
./datasets/EV18/train/JPEGImages/seq4/frame104.png
107
./datasets/EV18/train/JPEGImages/seq4/frame107.png
102
./datasets/EV18/train/JPEGImages/seq10/frame102.png
106
./datasets/EV18/train/JPEGImages/seq10/frame106.png
94
./datasets/EV18/train/JPEGImages/seq11/frame094.png
103
./datasets/EV18/train/JPEGImages/seq11/frame103.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(128.4398, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.3778, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7616, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
23
./datasets/EV18/train/JPEGImages/seq16/frame023.png
31
./datasets/EV18/train/JPEGImages/seq16/frame031.png
49
./datasets/EV18/train/JPEGImages/seq7/frame049.png
58
./datasets/EV18/train/JPEGImages/seq7/frame058.png
68
./datasets/EV18/train/JPEGImages/seq3/frame068.png
78
./datasets/EV18/train/JPEGImages/seq3/frame078.png
130
./datasets/EV18/train/JPEGImages/seq1/frame130.png
136
./datasets/EV18/train/JPEGImages/seq1/frame136.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(102.5159, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.2487, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.6448, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
10
./datasets/EV18/train/JPEGImages/seq3/frame010.png
16
./datasets/EV18/train/JPEGImages/seq3/frame016.png
89
./datasets/EV18/train/JPEGImages/seq10/frame089.png
97
./datasets/EV18/train/JPEGImages/seq10/frame097.png
55
./datasets/EV18/train/JPEGImages/seq10/frame055.png
60
./datasets/EV18/train/JPEGImages/seq10/frame060.png
43
./datasets/EV18/train/JPEGImages/seq3/frame043.png
45
./datasets/EV18/train/JPEGImages/seq3/frame045.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(170.4757, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.6480, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8057, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
136
./datasets/EV18/train/JPEGImages/seq14/frame136.png
142
./datasets/EV18/train/JPEGImages/seq14/frame142.png
111
./datasets/EV18/train/JPEGImages/seq10/frame111.png
112
./datasets/EV18/train/JPEGImages/seq10/frame112.png
25
./datasets/EV18/train/JPEGImages/seq6/frame025.png
26
./datasets/EV18/train/JPEGImages/seq6/frame026.png
134
./datasets/EV18/train/JPEGImages/seq12/frame134.png
142
./datasets/EV18/train/JPEGImages/seq12/frame142.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(145.1768, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5047, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7938, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
96
./datasets/EV18/train/JPEGImages/seq7/frame096.png
99
./datasets/EV18/train/JPEGImages/seq7/frame099.png
133
./datasets/EV18/train/JPEGImages/seq14/frame133.png
143
./datasets/EV18/train/JPEGImages/seq14/frame143.png
102
./datasets/EV18/train/JPEGImages/seq16/frame102.png
106
./datasets/EV18/train/JPEGImages/seq16/frame106.png
134
./datasets/EV18/train/JPEGImages/seq12/frame134.png
138
./datasets/EV18/train/JPEGImages/seq12/frame138.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(123.3925, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5680, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7859, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
45
./datasets/EV18/train/JPEGImages/seq7/frame045.png
51
./datasets/EV18/train/JPEGImages/seq7/frame051.png
95
./datasets/EV18/train/JPEGImages/seq1/frame095.png
100
./datasets/EV18/train/JPEGImages/seq1/frame100.png
85
./datasets/EV18/train/JPEGImages/seq3/frame085.png
88
./datasets/EV18/train/JPEGImages/seq3/frame088.png
46
./datasets/EV18/train/JPEGImages/seq11/frame046.png
53
./datasets/EV18/train/JPEGImages/seq11/frame053.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(161.0509, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.8280, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8680, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
75
./datasets/EV18/train/JPEGImages/seq13/frame075.png
80
./datasets/EV18/train/JPEGImages/seq13/frame080.png
122
./datasets/EV18/train/JPEGImages/seq4/frame122.png
127
./datasets/EV18/train/JPEGImages/seq4/frame127.png
27
./datasets/EV18/train/JPEGImages/seq1/frame027.png
37
./datasets/EV18/train/JPEGImages/seq1/frame037.png
140
./datasets/EV18/train/JPEGImages/seq11/frame140.png
147
./datasets/EV18/train/JPEGImages/seq11/frame147.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(176.7229, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.8258, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8860, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
82
./datasets/EV18/train/JPEGImages/seq4/frame082.png
92
./datasets/EV18/train/JPEGImages/seq4/frame092.png
131
./datasets/EV18/train/JPEGImages/seq14/frame131.png
137
./datasets/EV18/train/JPEGImages/seq14/frame137.png
105
./datasets/EV18/train/JPEGImages/seq7/frame105.png
106
./datasets/EV18/train/JPEGImages/seq7/frame106.png
14
./datasets/EV18/train/JPEGImages/seq12/frame014.png
22
./datasets/EV18/train/JPEGImages/seq12/frame022.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(163.1708, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.7064, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8262, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
86
./datasets/EV18/train/JPEGImages/seq6/frame086.png
91
./datasets/EV18/train/JPEGImages/seq6/frame091.png
128
./datasets/EV18/train/JPEGImages/seq16/frame128.png
134
./datasets/EV18/train/JPEGImages/seq16/frame134.png
2
./datasets/EV18/train/JPEGImages/seq13/frame002.png
12
./datasets/EV18/train/JPEGImages/seq13/frame012.png
4
./datasets/EV18/train/JPEGImages/seq6/frame004.png
7
./datasets/EV18/train/JPEGImages/seq6/frame007.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(200.2853, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.4897, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8150, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
31
./datasets/EV18/train/JPEGImages/seq16/frame031.png
35
./datasets/EV18/train/JPEGImages/seq16/frame035.png
24
./datasets/EV18/train/JPEGImages/seq4/frame024.png
34
./datasets/EV18/train/JPEGImages/seq4/frame034.png
91
./datasets/EV18/train/JPEGImages/seq13/frame091.png
101
./datasets/EV18/train/JPEGImages/seq13/frame101.png
50
./datasets/EV18/train/JPEGImages/seq3/frame050.png
59
./datasets/EV18/train/JPEGImages/seq3/frame059.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(159.8607, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5407, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8106, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
[05/26 01:44:13 d2.utils.events]:  eta: 3:54:42  iter: 159  total_loss: 2108  loss_ce: 210.4  loss_bbox: 1.705  loss_giou: 0.8391  loss_mask: 1.518  loss_dice: 0.9427  loss_ce_dn: 1.574  loss_mask_dn: 1.434  loss_dice_dn: 0.9409  loss_bbox_dn: 0.2271  loss_giou_dn: 0.4253  loss_ce_0: 195.5  loss_mask_0: 0.8405  loss_dice_0: 0.925  loss_bbox_0: 1.701  loss_giou_0: 0.8397  loss_ce_dn_0: 1.007  loss_mask_dn_0: 1.134  loss_dice_dn_0: 0.9276  loss_bbox_dn_0: 0.2271  loss_giou_dn_0: 0.4253  loss_ce_1: 170.9  loss_mask_1: 0.7582  loss_dice_1: 0.9338  loss_bbox_1: 1.728  loss_giou_1: 0.8398  loss_ce_dn_1: 1.059  loss_mask_dn_1: 1.084  loss_dice_dn_1: 0.9299  loss_bbox_dn_1: 0.2271  loss_giou_dn_1: 0.4253  loss_ce_2: 135.6  loss_mask_2: 0.809  loss_dice_2: 0.9145  loss_bbox_2: 1.709  loss_giou_2: 0.8398  loss_ce_dn_2: 0.9894  loss_mask_dn_2: 0.984  loss_dice_dn_2: 0.915  loss_bbox_dn_2: 0.2271  loss_giou_dn_2: 0.4253  loss_ce_3: 215.1  loss_mask_3: 0.7425  loss_dice_3: 0.9068  loss_bbox_3: 1.712  loss_giou_3: 0.8399  loss_ce_dn_3: 1.502  loss_mask_dn_3: 0.8994  loss_dice_dn_3: 0.9082  loss_bbox_dn_3: 0.2271  loss_giou_dn_3: 0.4253  loss_ce_4: 132.7  loss_mask_4: 0.8978  loss_dice_4: 0.9169  loss_bbox_4: 1.714  loss_giou_4: 0.8397  loss_ce_dn_4: 1.089  loss_mask_dn_4: 1.056  loss_dice_dn_4: 0.917  loss_bbox_dn_4: 0.2271  loss_giou_dn_4: 0.4253  loss_ce_5: 203.3  loss_mask_5: 0.7217  loss_dice_5: 0.9134  loss_bbox_5: 1.701  loss_giou_5: 0.8394  loss_ce_dn_5: 1.746  loss_mask_dn_5: 0.769  loss_dice_dn_5: 0.9219  loss_bbox_dn_5: 0.2271  loss_giou_dn_5: 0.4253  loss_ce_6: 131.2  loss_mask_6: 0.8343  loss_dice_6: 0.9321  loss_bbox_6: 1.705  loss_giou_6: 0.8397  loss_ce_dn_6: 1.183  loss_mask_dn_6: 0.8892  loss_dice_dn_6: 0.9327  loss_bbox_dn_6: 0.2271  loss_giou_dn_6: 0.4253  loss_ce_7: 218  loss_mask_7: 0.9481  loss_dice_7: 0.9303  loss_bbox_7: 1.715  loss_giou_7: 0.8392  loss_ce_dn_7: 1.706  loss_mask_dn_7: 0.9462  loss_dice_dn_7: 0.9292  loss_bbox_dn_7: 0.2271  loss_giou_dn_7: 0.4253  loss_ce_8: 218.5  loss_mask_8: 1.225  loss_dice_8: 0.9202  loss_bbox_8: 1.7  loss_giou_8: 0.84  loss_ce_dn_8: 1.809  loss_mask_dn_8: 1.222  loss_dice_dn_8: 0.9184  loss_bbox_dn_8: 0.2271  loss_giou_dn_8: 0.4253  loss_ce_interm: 195.6  loss_mask_interm: 0.9259  loss_dice_interm: 0.9297  loss_bbox_interm: 0.7274  loss_giou_interm: 1.064    time: 1.1702  last_time: 1.2107  data_time: 0.0141  last_data_time: 0.0139   lr: 0.0001  max_mem: 18844M
82
./datasets/EV18/train/JPEGImages/seq7/frame082.png
89
./datasets/EV18/train/JPEGImages/seq7/frame089.png
35
./datasets/EV18/train/JPEGImages/seq6/frame035.png
37
./datasets/EV18/train/JPEGImages/seq6/frame037.png
112
./datasets/EV18/train/JPEGImages/seq13/frame112.png
119
./datasets/EV18/train/JPEGImages/seq13/frame119.png
50
./datasets/EV18/train/JPEGImages/seq13/frame050.png
59
./datasets/EV18/train/JPEGImages/seq13/frame059.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(150.2784, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.6213, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8535, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
73
./datasets/EV18/train/JPEGImages/seq10/frame073.png
76
./datasets/EV18/train/JPEGImages/seq10/frame076.png
133
./datasets/EV18/train/JPEGImages/seq7/frame133.png
137
./datasets/EV18/train/JPEGImages/seq7/frame137.png
34
./datasets/EV18/train/JPEGImages/seq3/frame034.png
44
./datasets/EV18/train/JPEGImages/seq3/frame044.png
98
./datasets/EV18/train/JPEGImages/seq1/frame098.png
101
./datasets/EV18/train/JPEGImages/seq1/frame101.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(190.9025, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.6351, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8341, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
38
./datasets/EV18/train/JPEGImages/seq10/frame038.png
45
./datasets/EV18/train/JPEGImages/seq10/frame045.png
51
./datasets/EV18/train/JPEGImages/seq16/frame051.png
54
./datasets/EV18/train/JPEGImages/seq16/frame054.png
66
./datasets/EV18/train/JPEGImages/seq11/frame066.png
70
./datasets/EV18/train/JPEGImages/seq11/frame070.png
124
./datasets/EV18/train/JPEGImages/seq1/frame124.png
129
./datasets/EV18/train/JPEGImages/seq1/frame129.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(245.7290, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.9127, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8854, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
1
./datasets/EV18/train/JPEGImages/seq3/frame001.png
9
./datasets/EV18/train/JPEGImages/seq3/frame009.png
81
./datasets/EV18/train/JPEGImages/seq14/frame081.png
83
./datasets/EV18/train/JPEGImages/seq14/frame083.png
110
./datasets/EV18/train/JPEGImages/seq6/frame110.png
116
./datasets/EV18/train/JPEGImages/seq6/frame116.png
117
./datasets/EV18/train/JPEGImages/seq11/frame117.png
121
./datasets/EV18/train/JPEGImages/seq11/frame121.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(117.7793, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.4964, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7619, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
22
./datasets/EV18/train/JPEGImages/seq1/frame022.png
27
./datasets/EV18/train/JPEGImages/seq1/frame027.png
1
./datasets/EV18/train/JPEGImages/seq11/frame001.png
2
./datasets/EV18/train/JPEGImages/seq11/frame002.png
13
./datasets/EV18/train/JPEGImages/seq4/frame013.png
16
./datasets/EV18/train/JPEGImages/seq4/frame016.png
92
./datasets/EV18/train/JPEGImages/seq16/frame092.png
99
./datasets/EV18/train/JPEGImages/seq16/frame099.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(160.4581, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5732, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7999, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
17
./datasets/EV18/train/JPEGImages/seq14/frame017.png
19
./datasets/EV18/train/JPEGImages/seq14/frame019.png
132
./datasets/EV18/train/JPEGImages/seq13/frame132.png
135
./datasets/EV18/train/JPEGImages/seq13/frame135.png
94
./datasets/EV18/train/JPEGImages/seq10/frame094.png
95
./datasets/EV18/train/JPEGImages/seq10/frame095.png
68
./datasets/EV18/train/JPEGImages/seq16/frame068.png
69
./datasets/EV18/train/JPEGImages/seq16/frame069.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(130.9147, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.3785, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7429, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
124
./datasets/EV18/train/JPEGImages/seq4/frame124.png
129
./datasets/EV18/train/JPEGImages/seq4/frame129.png
100
./datasets/EV18/train/JPEGImages/seq14/frame100.png
107
./datasets/EV18/train/JPEGImages/seq14/frame107.png
19
./datasets/EV18/train/JPEGImages/seq12/frame019.png
20
./datasets/EV18/train/JPEGImages/seq12/frame020.png
137
./datasets/EV18/train/JPEGImages/seq7/frame137.png
142
./datasets/EV18/train/JPEGImages/seq7/frame142.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(126.2948, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.4576, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7463, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
50
./datasets/EV18/train/JPEGImages/seq6/frame050.png
52
./datasets/EV18/train/JPEGImages/seq6/frame052.png
16
./datasets/EV18/train/JPEGImages/seq4/frame016.png
23
./datasets/EV18/train/JPEGImages/seq4/frame023.png
47
./datasets/EV18/train/JPEGImages/seq12/frame047.png
57
./datasets/EV18/train/JPEGImages/seq12/frame057.png
93
./datasets/EV18/train/JPEGImages/seq4/frame093.png
95
./datasets/EV18/train/JPEGImages/seq4/frame095.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(104.7760, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.3498, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7181, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
29
./datasets/EV18/train/JPEGImages/seq10/frame029.png
33
./datasets/EV18/train/JPEGImages/seq10/frame033.png
64
./datasets/EV18/train/JPEGImages/seq13/frame064.png
67
./datasets/EV18/train/JPEGImages/seq13/frame067.png
144
./datasets/EV18/train/JPEGImages/seq12/frame144.png
146
./datasets/EV18/train/JPEGImages/seq12/frame146.png
22
./datasets/EV18/train/JPEGImages/seq16/frame022.png
28
./datasets/EV18/train/JPEGImages/seq16/frame028.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(142.9589, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.2276, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.6828, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
38
./datasets/EV18/train/JPEGImages/seq11/frame038.png
48
./datasets/EV18/train/JPEGImages/seq11/frame048.png
54
./datasets/EV18/train/JPEGImages/seq12/frame054.png
58
./datasets/EV18/train/JPEGImages/seq12/frame058.png
15
./datasets/EV18/train/JPEGImages/seq7/frame015.png
24
./datasets/EV18/train/JPEGImages/seq7/frame024.png
38
./datasets/EV18/train/JPEGImages/seq13/frame038.png
48
./datasets/EV18/train/JPEGImages/seq13/frame048.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(216.7965, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.2165, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.6457, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
76
./datasets/EV18/train/JPEGImages/seq16/frame076.png
79
./datasets/EV18/train/JPEGImages/seq16/frame079.png
44
./datasets/EV18/train/JPEGImages/seq14/frame044.png
51
./datasets/EV18/train/JPEGImages/seq14/frame051.png
132
./datasets/EV18/train/JPEGImages/seq7/frame132.png
142
./datasets/EV18/train/JPEGImages/seq7/frame142.png
92
./datasets/EV18/train/JPEGImages/seq1/frame092.png
102
./datasets/EV18/train/JPEGImages/seq1/frame102.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(130.1996, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.7318, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8457, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
105
./datasets/EV18/train/JPEGImages/seq4/frame105.png
107
./datasets/EV18/train/JPEGImages/seq4/frame107.png
1
./datasets/EV18/train/JPEGImages/seq4/frame001.png
8
./datasets/EV18/train/JPEGImages/seq4/frame008.png
26
./datasets/EV18/train/JPEGImages/seq12/frame026.png
28
./datasets/EV18/train/JPEGImages/seq12/frame028.png
138
./datasets/EV18/train/JPEGImages/seq10/frame138.png
146
./datasets/EV18/train/JPEGImages/seq10/frame146.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(112.5431, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.4591, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7807, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
2
./datasets/EV18/train/JPEGImages/seq11/frame002.png
10
./datasets/EV18/train/JPEGImages/seq11/frame010.png
1
./datasets/EV18/train/JPEGImages/seq1/frame001.png
4
./datasets/EV18/train/JPEGImages/seq1/frame004.png
56
./datasets/EV18/train/JPEGImages/seq10/frame056.png
58
./datasets/EV18/train/JPEGImages/seq10/frame058.png
20
./datasets/EV18/train/JPEGImages/seq6/frame020.png
25
./datasets/EV18/train/JPEGImages/seq6/frame025.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(166.5943, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.7943, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8632, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
109
./datasets/EV18/train/JPEGImages/seq7/frame109.png
111
./datasets/EV18/train/JPEGImages/seq7/frame111.png
135
./datasets/EV18/train/JPEGImages/seq3/frame135.png
139
./datasets/EV18/train/JPEGImages/seq3/frame139.png
48
./datasets/EV18/train/JPEGImages/seq11/frame048.png
50
./datasets/EV18/train/JPEGImages/seq11/frame050.png
9
./datasets/EV18/train/JPEGImages/seq1/frame009.png
18
./datasets/EV18/train/JPEGImages/seq1/frame018.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(301.8034, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(2.0232, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.9173, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
90
./datasets/EV18/train/JPEGImages/seq6/frame090.png
99
./datasets/EV18/train/JPEGImages/seq6/frame099.png
25
./datasets/EV18/train/JPEGImages/seq3/frame025.png
26
./datasets/EV18/train/JPEGImages/seq3/frame026.png
131
./datasets/EV18/train/JPEGImages/seq14/frame131.png
139
./datasets/EV18/train/JPEGImages/seq14/frame139.png
30
./datasets/EV18/train/JPEGImages/seq13/frame030.png
34
./datasets/EV18/train/JPEGImages/seq13/frame034.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(216.4869, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5274, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8210, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
98
./datasets/EV18/train/JPEGImages/seq3/frame098.png
106
./datasets/EV18/train/JPEGImages/seq3/frame106.png
61
./datasets/EV18/train/JPEGImages/seq16/frame061.png
63
./datasets/EV18/train/JPEGImages/seq16/frame063.png
56
./datasets/EV18/train/JPEGImages/seq6/frame056.png
59
./datasets/EV18/train/JPEGImages/seq6/frame059.png
63
./datasets/EV18/train/JPEGImages/seq14/frame063.png
72
./datasets/EV18/train/JPEGImages/seq14/frame072.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(141.6888, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5238, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8017, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
17
./datasets/EV18/train/JPEGImages/seq13/frame017.png
22
./datasets/EV18/train/JPEGImages/seq13/frame022.png
137
./datasets/EV18/train/JPEGImages/seq4/frame137.png
146
./datasets/EV18/train/JPEGImages/seq4/frame146.png
117
./datasets/EV18/train/JPEGImages/seq11/frame117.png
118
./datasets/EV18/train/JPEGImages/seq11/frame118.png
136
./datasets/EV18/train/JPEGImages/seq7/frame136.png
138
./datasets/EV18/train/JPEGImages/seq7/frame138.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(105.8229, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.0680, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.5988, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
7
./datasets/EV18/train/JPEGImages/seq6/frame007.png
13
./datasets/EV18/train/JPEGImages/seq6/frame013.png
30
./datasets/EV18/train/JPEGImages/seq14/frame030.png
39
./datasets/EV18/train/JPEGImages/seq14/frame039.png
105
./datasets/EV18/train/JPEGImages/seq3/frame105.png
113
./datasets/EV18/train/JPEGImages/seq3/frame113.png
57
./datasets/EV18/train/JPEGImages/seq12/frame057.png
64
./datasets/EV18/train/JPEGImages/seq12/frame064.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(138.9999, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.6602, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8375, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
59
./datasets/EV18/train/JPEGImages/seq12/frame059.png
67
./datasets/EV18/train/JPEGImages/seq12/frame067.png
94
./datasets/EV18/train/JPEGImages/seq1/frame094.png
98
./datasets/EV18/train/JPEGImages/seq1/frame098.png
76
./datasets/EV18/train/JPEGImages/seq14/frame076.png
82
./datasets/EV18/train/JPEGImages/seq14/frame082.png
65
./datasets/EV18/train/JPEGImages/seq12/frame065.png
69
./datasets/EV18/train/JPEGImages/seq12/frame069.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(157.6874, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.7045, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8445, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
93
./datasets/EV18/train/JPEGImages/seq10/frame093.png
99
./datasets/EV18/train/JPEGImages/seq10/frame099.png
141
./datasets/EV18/train/JPEGImages/seq3/frame141.png
144
./datasets/EV18/train/JPEGImages/seq3/frame144.png
120
./datasets/EV18/train/JPEGImages/seq1/frame120.png
127
./datasets/EV18/train/JPEGImages/seq1/frame127.png
112
./datasets/EV18/train/JPEGImages/seq10/frame112.png
119
./datasets/EV18/train/JPEGImages/seq10/frame119.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(150.3290, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.2841, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.6839, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
[05/26 01:44:36 d2.utils.events]:  eta: 3:54:14  iter: 179  total_loss: 2154  loss_ce: 215.7  loss_bbox: 1.665  loss_giou: 0.8418  loss_mask: 1.52  loss_dice: 0.9532  loss_ce_dn: 1.659  loss_mask_dn: 1.492  loss_dice_dn: 0.9575  loss_bbox_dn: 0.23  loss_giou_dn: 0.4277  loss_ce_0: 202.3  loss_mask_0: 0.8305  loss_dice_0: 0.9321  loss_bbox_0: 1.667  loss_giou_0: 0.8414  loss_ce_dn_0: 1.016  loss_mask_dn_0: 1.136  loss_dice_dn_0: 0.9395  loss_bbox_dn_0: 0.23  loss_giou_dn_0: 0.4277  loss_ce_1: 180.5  loss_mask_1: 0.7625  loss_dice_1: 0.9403  loss_bbox_1: 1.675  loss_giou_1: 0.8413  loss_ce_dn_1: 1.026  loss_mask_dn_1: 1.062  loss_dice_dn_1: 0.9415  loss_bbox_dn_1: 0.23  loss_giou_dn_1: 0.4277  loss_ce_2: 140.4  loss_mask_2: 0.8115  loss_dice_2: 0.9251  loss_bbox_2: 1.675  loss_giou_2: 0.8414  loss_ce_dn_2: 0.966  loss_mask_dn_2: 0.9896  loss_dice_dn_2: 0.9225  loss_bbox_dn_2: 0.23  loss_giou_dn_2: 0.4277  loss_ce_3: 217.6  loss_mask_3: 0.7486  loss_dice_3: 0.9049  loss_bbox_3: 1.675  loss_giou_3: 0.8414  loss_ce_dn_3: 1.612  loss_mask_dn_3: 0.8809  loss_dice_dn_3: 0.9115  loss_bbox_dn_3: 0.23  loss_giou_dn_3: 0.4277  loss_ce_4: 138.1  loss_mask_4: 0.8933  loss_dice_4: 0.924  loss_bbox_4: 1.671  loss_giou_4: 0.8405  loss_ce_dn_4: 1.116  loss_mask_dn_4: 1.051  loss_dice_dn_4: 0.9262  loss_bbox_dn_4: 0.23  loss_giou_dn_4: 0.4277  loss_ce_5: 210.5  loss_mask_5: 0.7249  loss_dice_5: 0.9262  loss_bbox_5: 1.671  loss_giou_5: 0.8408  loss_ce_dn_5: 1.8  loss_mask_dn_5: 0.7709  loss_dice_dn_5: 0.9329  loss_bbox_dn_5: 0.23  loss_giou_dn_5: 0.4277  loss_ce_6: 136  loss_mask_6: 0.8316  loss_dice_6: 0.9505  loss_bbox_6: 1.666  loss_giou_6: 0.8406  loss_ce_dn_6: 1.223  loss_mask_dn_6: 0.8857  loss_dice_dn_6: 0.9482  loss_bbox_dn_6: 0.23  loss_giou_dn_6: 0.4277  loss_ce_7: 224.5  loss_mask_7: 0.9289  loss_dice_7: 0.9342  loss_bbox_7: 1.671  loss_giou_7: 0.8406  loss_ce_dn_7: 1.813  loss_mask_dn_7: 0.9433  loss_dice_dn_7: 0.9361  loss_bbox_dn_7: 0.23  loss_giou_dn_7: 0.4277  loss_ce_8: 222.9  loss_mask_8: 1.211  loss_dice_8: 0.9235  loss_bbox_8: 1.667  loss_giou_8: 0.8404  loss_ce_dn_8: 1.871  loss_mask_dn_8: 1.207  loss_dice_dn_8: 0.9231  loss_bbox_dn_8: 0.23  loss_giou_dn_8: 0.4277  loss_ce_interm: 202.4  loss_mask_interm: 0.9443  loss_dice_interm: 0.9417  loss_bbox_interm: 0.7076  loss_giou_interm: 1.071    time: 1.1709  last_time: 1.1784  data_time: 0.0129  last_data_time: 0.0140   lr: 0.0001  max_mem: 18844M
34
./datasets/EV18/train/JPEGImages/seq7/frame034.png
44
./datasets/EV18/train/JPEGImages/seq7/frame044.png
43
./datasets/EV18/train/JPEGImages/seq3/frame043.png
47
./datasets/EV18/train/JPEGImages/seq3/frame047.png
66
./datasets/EV18/train/JPEGImages/seq16/frame066.png
74
./datasets/EV18/train/JPEGImages/seq16/frame074.png
126
./datasets/EV18/train/JPEGImages/seq1/frame126.png
127
./datasets/EV18/train/JPEGImages/seq1/frame127.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(165.4709, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.6531, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8173, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
87
./datasets/EV18/train/JPEGImages/seq16/frame087.png
89
./datasets/EV18/train/JPEGImages/seq16/frame089.png
40
./datasets/EV18/train/JPEGImages/seq13/frame040.png
43
./datasets/EV18/train/JPEGImages/seq13/frame043.png
7
./datasets/EV18/train/JPEGImages/seq11/frame007.png
15
./datasets/EV18/train/JPEGImages/seq11/frame015.png
129
./datasets/EV18/train/JPEGImages/seq6/frame129.png
130
./datasets/EV18/train/JPEGImages/seq6/frame130.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(147.9452, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.4586, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7654, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
82
./datasets/EV18/train/JPEGImages/seq6/frame082.png
88
./datasets/EV18/train/JPEGImages/seq6/frame088.png
14
./datasets/EV18/train/JPEGImages/seq10/frame014.png
17
./datasets/EV18/train/JPEGImages/seq10/frame017.png
136
./datasets/EV18/train/JPEGImages/seq13/frame136.png
143
./datasets/EV18/train/JPEGImages/seq13/frame143.png
8
./datasets/EV18/train/JPEGImages/seq11/frame008.png
13
./datasets/EV18/train/JPEGImages/seq11/frame013.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(154.5411, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5258, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7805, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
49
./datasets/EV18/train/JPEGImages/seq4/frame049.png
54
./datasets/EV18/train/JPEGImages/seq4/frame054.png
78
./datasets/EV18/train/JPEGImages/seq7/frame078.png
79
./datasets/EV18/train/JPEGImages/seq7/frame079.png
67
./datasets/EV18/train/JPEGImages/seq4/frame067.png
71
./datasets/EV18/train/JPEGImages/seq4/frame071.png
5
./datasets/EV18/train/JPEGImages/seq14/frame005.png
12
./datasets/EV18/train/JPEGImages/seq14/frame012.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(83.7990, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.1535, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.6553, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
131
./datasets/EV18/train/JPEGImages/seq16/frame131.png
135
./datasets/EV18/train/JPEGImages/seq16/frame135.png
130
./datasets/EV18/train/JPEGImages/seq10/frame130.png
139
./datasets/EV18/train/JPEGImages/seq10/frame139.png
1
./datasets/EV18/train/JPEGImages/seq3/frame001.png
7
./datasets/EV18/train/JPEGImages/seq3/frame007.png
116
./datasets/EV18/train/JPEGImages/seq12/frame116.png
125
./datasets/EV18/train/JPEGImages/seq12/frame125.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(204.5727, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5473, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8099, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
17
./datasets/EV18/train/JPEGImages/seq4/frame017.png
22
./datasets/EV18/train/JPEGImages/seq4/frame022.png
31
./datasets/EV18/train/JPEGImages/seq7/frame031.png
32
./datasets/EV18/train/JPEGImages/seq7/frame032.png
108
./datasets/EV18/train/JPEGImages/seq7/frame108.png
115
./datasets/EV18/train/JPEGImages/seq7/frame115.png
19
./datasets/EV18/train/JPEGImages/seq3/frame019.png
23
./datasets/EV18/train/JPEGImages/seq3/frame023.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(216.0999, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.9081, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8899, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
47
./datasets/EV18/train/JPEGImages/seq7/frame047.png
57
./datasets/EV18/train/JPEGImages/seq7/frame057.png
71
./datasets/EV18/train/JPEGImages/seq13/frame071.png
77
./datasets/EV18/train/JPEGImages/seq13/frame077.png
94
./datasets/EV18/train/JPEGImages/seq11/frame094.png
104
./datasets/EV18/train/JPEGImages/seq11/frame104.png
43
./datasets/EV18/train/JPEGImages/seq16/frame043.png
52
./datasets/EV18/train/JPEGImages/seq16/frame052.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(159.7967, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5064, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7879, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
87
./datasets/EV18/train/JPEGImages/seq10/frame087.png
92
./datasets/EV18/train/JPEGImages/seq10/frame092.png
136
./datasets/EV18/train/JPEGImages/seq14/frame136.png
138
./datasets/EV18/train/JPEGImages/seq14/frame138.png
70
./datasets/EV18/train/JPEGImages/seq12/frame070.png
71
./datasets/EV18/train/JPEGImages/seq12/frame071.png
46
./datasets/EV18/train/JPEGImages/seq14/frame046.png
48
./datasets/EV18/train/JPEGImages/seq14/frame048.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(92.9422, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.1632, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.6754, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
4
./datasets/EV18/train/JPEGImages/seq1/frame004.png
14
./datasets/EV18/train/JPEGImages/seq1/frame014.png
45
./datasets/EV18/train/JPEGImages/seq4/frame045.png
54
./datasets/EV18/train/JPEGImages/seq4/frame054.png
127
./datasets/EV18/train/JPEGImages/seq6/frame127.png
136
./datasets/EV18/train/JPEGImages/seq6/frame136.png
29
./datasets/EV18/train/JPEGImages/seq13/frame029.png
35
./datasets/EV18/train/JPEGImages/seq13/frame035.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(77.7926, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.1702, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.6339, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
114
./datasets/EV18/train/JPEGImages/seq1/frame114.png
116
./datasets/EV18/train/JPEGImages/seq1/frame116.png
66
./datasets/EV18/train/JPEGImages/seq11/frame066.png
71
./datasets/EV18/train/JPEGImages/seq11/frame071.png
134
./datasets/EV18/train/JPEGImages/seq11/frame134.png
144
./datasets/EV18/train/JPEGImages/seq11/frame144.png
4
./datasets/EV18/train/JPEGImages/seq13/frame004.png
7
./datasets/EV18/train/JPEGImages/seq13/frame007.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(178.9224, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.7789, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8366, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
41
./datasets/EV18/train/JPEGImages/seq16/frame041.png
51
./datasets/EV18/train/JPEGImages/seq16/frame051.png
78
./datasets/EV18/train/JPEGImages/seq14/frame078.png
86
./datasets/EV18/train/JPEGImages/seq14/frame086.png
125
./datasets/EV18/train/JPEGImages/seq12/frame125.png
130
./datasets/EV18/train/JPEGImages/seq12/frame130.png
89
./datasets/EV18/train/JPEGImages/seq3/frame089.png
97
./datasets/EV18/train/JPEGImages/seq3/frame097.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(230.6116, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.7276, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8683, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
97
./datasets/EV18/train/JPEGImages/seq6/frame097.png
98
./datasets/EV18/train/JPEGImages/seq6/frame098.png
41
./datasets/EV18/train/JPEGImages/seq1/frame041.png
42
./datasets/EV18/train/JPEGImages/seq1/frame042.png
0
./datasets/EV18/train/JPEGImages/seq4/frame000.png
2
./datasets/EV18/train/JPEGImages/seq4/frame002.png
5
./datasets/EV18/train/JPEGImages/seq6/frame005.png
12
./datasets/EV18/train/JPEGImages/seq6/frame012.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(205.0689, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.8053, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.9053, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
54
./datasets/EV18/train/JPEGImages/seq10/frame054.png
63
./datasets/EV18/train/JPEGImages/seq10/frame063.png
41
./datasets/EV18/train/JPEGImages/seq3/frame041.png
51
./datasets/EV18/train/JPEGImages/seq3/frame051.png
21
./datasets/EV18/train/JPEGImages/seq14/frame021.png
22
./datasets/EV18/train/JPEGImages/seq14/frame022.png
21
./datasets/EV18/train/JPEGImages/seq7/frame021.png
22
./datasets/EV18/train/JPEGImages/seq7/frame022.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(186.3638, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5904, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8093, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
139
./datasets/EV18/train/JPEGImages/seq13/frame139.png
147
./datasets/EV18/train/JPEGImages/seq13/frame147.png
31
./datasets/EV18/train/JPEGImages/seq10/frame031.png
34
./datasets/EV18/train/JPEGImages/seq10/frame034.png
107
./datasets/EV18/train/JPEGImages/seq6/frame107.png
114
./datasets/EV18/train/JPEGImages/seq6/frame114.png
29
./datasets/EV18/train/JPEGImages/seq16/frame029.png
32
./datasets/EV18/train/JPEGImages/seq16/frame032.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(169.8237, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5406, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8095, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
48
./datasets/EV18/train/JPEGImages/seq16/frame048.png
53
./datasets/EV18/train/JPEGImages/seq16/frame053.png
31
./datasets/EV18/train/JPEGImages/seq13/frame031.png
35
./datasets/EV18/train/JPEGImages/seq13/frame035.png
126
./datasets/EV18/train/JPEGImages/seq11/frame126.png
131
./datasets/EV18/train/JPEGImages/seq11/frame131.png
104
./datasets/EV18/train/JPEGImages/seq12/frame104.png
113
./datasets/EV18/train/JPEGImages/seq12/frame113.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(142.9013, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.4096, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7415, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
92
./datasets/EV18/train/JPEGImages/seq3/frame092.png
101
./datasets/EV18/train/JPEGImages/seq3/frame101.png
89
./datasets/EV18/train/JPEGImages/seq14/frame089.png
90
./datasets/EV18/train/JPEGImages/seq14/frame090.png
34
./datasets/EV18/train/JPEGImages/seq3/frame034.png
39
./datasets/EV18/train/JPEGImages/seq3/frame039.png
23
./datasets/EV18/train/JPEGImages/seq7/frame023.png
28
./datasets/EV18/train/JPEGImages/seq7/frame028.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(139.0199, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5518, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7895, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
18
./datasets/EV18/train/JPEGImages/seq1/frame018.png
28
./datasets/EV18/train/JPEGImages/seq1/frame028.png
34
./datasets/EV18/train/JPEGImages/seq4/frame034.png
35
./datasets/EV18/train/JPEGImages/seq4/frame035.png
37
./datasets/EV18/train/JPEGImages/seq6/frame037.png
44
./datasets/EV18/train/JPEGImages/seq6/frame044.png
35
./datasets/EV18/train/JPEGImages/seq11/frame035.png
36
./datasets/EV18/train/JPEGImages/seq11/frame036.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(135.0047, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.7123, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8279, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
137
./datasets/EV18/train/JPEGImages/seq6/frame137.png
140
./datasets/EV18/train/JPEGImages/seq6/frame140.png
7
./datasets/EV18/train/JPEGImages/seq16/frame007.png
15
./datasets/EV18/train/JPEGImages/seq16/frame015.png
103
./datasets/EV18/train/JPEGImages/seq10/frame103.png
113
./datasets/EV18/train/JPEGImages/seq10/frame113.png
132
./datasets/EV18/train/JPEGImages/seq11/frame132.png
139
./datasets/EV18/train/JPEGImages/seq11/frame139.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(174.7447, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.6225, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7850, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
82
./datasets/EV18/train/JPEGImages/seq16/frame082.png
90
./datasets/EV18/train/JPEGImages/seq16/frame090.png
104
./datasets/EV18/train/JPEGImages/seq10/frame104.png
111
./datasets/EV18/train/JPEGImages/seq10/frame111.png
67
./datasets/EV18/train/JPEGImages/seq12/frame067.png
72
./datasets/EV18/train/JPEGImages/seq12/frame072.png
2
./datasets/EV18/train/JPEGImages/seq1/frame002.png
3
./datasets/EV18/train/JPEGImages/seq1/frame003.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(152.7667, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5865, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8037, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
78
./datasets/EV18/train/JPEGImages/seq7/frame078.png
82
./datasets/EV18/train/JPEGImages/seq7/frame082.png
9
./datasets/EV18/train/JPEGImages/seq4/frame009.png
18
./datasets/EV18/train/JPEGImages/seq4/frame018.png
45
./datasets/EV18/train/JPEGImages/seq14/frame045.png
49
./datasets/EV18/train/JPEGImages/seq14/frame049.png
139
./datasets/EV18/train/JPEGImages/seq13/frame139.png
142
./datasets/EV18/train/JPEGImages/seq13/frame142.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(93.2829, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.2982, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7407, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
[05/26 01:45:00 d2.utils.events]:  eta: 3:53:54  iter: 199  total_loss: 2314  loss_ce: 239.9  loss_bbox: 1.713  loss_giou: 0.8555  loss_mask: 1.488  loss_dice: 0.957  loss_ce_dn: 1.524  loss_mask_dn: 1.452  loss_dice_dn: 0.9547  loss_bbox_dn: 0.2137  loss_giou_dn: 0.4269  loss_ce_0: 211  loss_mask_0: 0.8425  loss_dice_0: 0.9257  loss_bbox_0: 1.718  loss_giou_0: 0.8549  loss_ce_dn_0: 1.034  loss_mask_dn_0: 1.144  loss_dice_dn_0: 0.9371  loss_bbox_dn_0: 0.2137  loss_giou_dn_0: 0.4269  loss_ce_1: 187.5  loss_mask_1: 0.7716  loss_dice_1: 0.9434  loss_bbox_1: 1.721  loss_giou_1: 0.8518  loss_ce_dn_1: 1.005  loss_mask_dn_1: 1.095  loss_dice_dn_1: 0.9455  loss_bbox_dn_1: 0.2137  loss_giou_dn_1: 0.4269  loss_ce_2: 146.6  loss_mask_2: 0.8087  loss_dice_2: 0.9222  loss_bbox_2: 1.721  loss_giou_2: 0.8524  loss_ce_dn_2: 0.9383  loss_mask_dn_2: 0.9994  loss_dice_dn_2: 0.9292  loss_bbox_dn_2: 0.2137  loss_giou_dn_2: 0.4269  loss_ce_3: 228  loss_mask_3: 0.7512  loss_dice_3: 0.9107  loss_bbox_3: 1.719  loss_giou_3: 0.8506  loss_ce_dn_3: 1.558  loss_mask_dn_3: 0.9108  loss_dice_dn_3: 0.9114  loss_bbox_dn_3: 0.2137  loss_giou_dn_3: 0.4269  loss_ce_4: 141.9  loss_mask_4: 0.912  loss_dice_4: 0.9222  loss_bbox_4: 1.72  loss_giou_4: 0.8506  loss_ce_dn_4: 1.085  loss_mask_dn_4: 1.061  loss_dice_dn_4: 0.9227  loss_bbox_dn_4: 0.2137  loss_giou_dn_4: 0.4269  loss_ce_5: 219.7  loss_mask_5: 0.7269  loss_dice_5: 0.9261  loss_bbox_5: 1.718  loss_giou_5: 0.8505  loss_ce_dn_5: 1.84  loss_mask_dn_5: 0.7678  loss_dice_dn_5: 0.933  loss_bbox_dn_5: 0.2137  loss_giou_dn_5: 0.4269  loss_ce_6: 147.8  loss_mask_6: 0.8377  loss_dice_6: 0.9434  loss_bbox_6: 1.72  loss_giou_6: 0.8508  loss_ce_dn_6: 1.226  loss_mask_dn_6: 0.8961  loss_dice_dn_6: 0.9451  loss_bbox_dn_6: 0.2137  loss_giou_dn_6: 0.4269  loss_ce_7: 240  loss_mask_7: 0.9134  loss_dice_7: 0.944  loss_bbox_7: 1.716  loss_giou_7: 0.8511  loss_ce_dn_7: 1.76  loss_mask_dn_7: 0.9453  loss_dice_dn_7: 0.9416  loss_bbox_dn_7: 0.2137  loss_giou_dn_7: 0.4269  loss_ce_8: 240.4  loss_mask_8: 1.2  loss_dice_8: 0.9378  loss_bbox_8: 1.716  loss_giou_8: 0.853  loss_ce_dn_8: 1.821  loss_mask_dn_8: 1.189  loss_dice_dn_8: 0.9313  loss_bbox_dn_8: 0.2137  loss_giou_dn_8: 0.4269  loss_ce_interm: 211  loss_mask_interm: 0.9394  loss_dice_interm: 0.934  loss_bbox_interm: 0.6803  loss_giou_interm: 1.047    time: 1.1723  last_time: 1.2199  data_time: 0.0141  last_data_time: 0.0131   lr: 0.0001  max_mem: 18844M
117
./datasets/EV18/train/JPEGImages/seq4/frame117.png
127
./datasets/EV18/train/JPEGImages/seq4/frame127.png
111
./datasets/EV18/train/JPEGImages/seq16/frame111.png
116
./datasets/EV18/train/JPEGImages/seq16/frame116.png
142
./datasets/EV18/train/JPEGImages/seq13/frame142.png
145
./datasets/EV18/train/JPEGImages/seq13/frame145.png
51
./datasets/EV18/train/JPEGImages/seq6/frame051.png
57
./datasets/EV18/train/JPEGImages/seq6/frame057.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(106.6066, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.4118, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7655, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
15
./datasets/EV18/train/JPEGImages/seq11/frame015.png
23
./datasets/EV18/train/JPEGImages/seq11/frame023.png
46
./datasets/EV18/train/JPEGImages/seq1/frame046.png
50
./datasets/EV18/train/JPEGImages/seq1/frame050.png
124
./datasets/EV18/train/JPEGImages/seq16/frame124.png
130
./datasets/EV18/train/JPEGImages/seq16/frame130.png
140
./datasets/EV18/train/JPEGImages/seq6/frame140.png
147
./datasets/EV18/train/JPEGImages/seq6/frame147.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(227.7245, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.7884, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8624, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
10
./datasets/EV18/train/JPEGImages/seq1/frame010.png
20
./datasets/EV18/train/JPEGImages/seq1/frame020.png
93
./datasets/EV18/train/JPEGImages/seq1/frame093.png
102
./datasets/EV18/train/JPEGImages/seq1/frame102.png
64
./datasets/EV18/train/JPEGImages/seq10/frame064.png
66
./datasets/EV18/train/JPEGImages/seq10/frame066.png
112
./datasets/EV18/train/JPEGImages/seq3/frame112.png
114
./datasets/EV18/train/JPEGImages/seq3/frame114.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(199.0168, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(2.1867, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.9388, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
118
./datasets/EV18/train/JPEGImages/seq6/frame118.png
124
./datasets/EV18/train/JPEGImages/seq6/frame124.png
107
./datasets/EV18/train/JPEGImages/seq7/frame107.png
113
./datasets/EV18/train/JPEGImages/seq7/frame113.png
30
./datasets/EV18/train/JPEGImages/seq1/frame030.png
40
./datasets/EV18/train/JPEGImages/seq1/frame040.png
37
./datasets/EV18/train/JPEGImages/seq12/frame037.png
46
./datasets/EV18/train/JPEGImages/seq12/frame046.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(167.5175, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.6748, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8036, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
6
./datasets/EV18/train/JPEGImages/seq12/frame006.png
11
./datasets/EV18/train/JPEGImages/seq12/frame011.png
35
./datasets/EV18/train/JPEGImages/seq4/frame035.png
42
./datasets/EV18/train/JPEGImages/seq4/frame042.png
86
./datasets/EV18/train/JPEGImages/seq14/frame086.png
90
./datasets/EV18/train/JPEGImages/seq14/frame090.png
7
./datasets/EV18/train/JPEGImages/seq10/frame007.png
12
./datasets/EV18/train/JPEGImages/seq10/frame012.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(119.8553, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.3784, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7325, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
106
./datasets/EV18/train/JPEGImages/seq12/frame106.png
110
./datasets/EV18/train/JPEGImages/seq12/frame110.png
0
./datasets/EV18/train/JPEGImages/seq13/frame000.png
8
./datasets/EV18/train/JPEGImages/seq13/frame008.png
9
./datasets/EV18/train/JPEGImages/seq4/frame009.png
15
./datasets/EV18/train/JPEGImages/seq4/frame015.png
88
./datasets/EV18/train/JPEGImages/seq7/frame088.png
93
./datasets/EV18/train/JPEGImages/seq7/frame093.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(155.0697, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5248, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8060, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
42
./datasets/EV18/train/JPEGImages/seq12/frame042.png
46
./datasets/EV18/train/JPEGImages/seq12/frame046.png
108
./datasets/EV18/train/JPEGImages/seq7/frame108.png
109
./datasets/EV18/train/JPEGImages/seq7/frame109.png
123
./datasets/EV18/train/JPEGImages/seq11/frame123.png
129
./datasets/EV18/train/JPEGImages/seq11/frame129.png
60
./datasets/EV18/train/JPEGImages/seq3/frame060.png
64
./datasets/EV18/train/JPEGImages/seq3/frame064.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(137.4903, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.2386, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.6295, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
24
./datasets/EV18/train/JPEGImages/seq4/frame024.png
31
./datasets/EV18/train/JPEGImages/seq4/frame031.png
144
./datasets/EV18/train/JPEGImages/seq14/frame144.png
147
./datasets/EV18/train/JPEGImages/seq14/frame147.png
115
./datasets/EV18/train/JPEGImages/seq3/frame115.png
120
./datasets/EV18/train/JPEGImages/seq3/frame120.png
132
./datasets/EV18/train/JPEGImages/seq10/frame132.png
134
./datasets/EV18/train/JPEGImages/seq10/frame134.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(171.5485, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.7364, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8377, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
62
./datasets/EV18/train/JPEGImages/seq11/frame062.png
66
./datasets/EV18/train/JPEGImages/seq11/frame066.png
136
./datasets/EV18/train/JPEGImages/seq7/frame136.png
144
./datasets/EV18/train/JPEGImages/seq7/frame144.png
66
./datasets/EV18/train/JPEGImages/seq16/frame066.png
67
./datasets/EV18/train/JPEGImages/seq16/frame067.png
74
./datasets/EV18/train/JPEGImages/seq13/frame074.png
77
./datasets/EV18/train/JPEGImages/seq13/frame077.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(249.6506, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.6751, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8321, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
125
./datasets/EV18/train/JPEGImages/seq10/frame125.png
134
./datasets/EV18/train/JPEGImages/seq10/frame134.png
100
./datasets/EV18/train/JPEGImages/seq11/frame100.png
102
./datasets/EV18/train/JPEGImages/seq11/frame102.png
98
./datasets/EV18/train/JPEGImages/seq12/frame098.png
108
./datasets/EV18/train/JPEGImages/seq12/frame108.png
97
./datasets/EV18/train/JPEGImages/seq14/frame097.png
103
./datasets/EV18/train/JPEGImages/seq14/frame103.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(132.2500, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.4291, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7332, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
74
./datasets/EV18/train/JPEGImages/seq13/frame074.png
78
./datasets/EV18/train/JPEGImages/seq13/frame078.png
67
./datasets/EV18/train/JPEGImages/seq12/frame067.png
68
./datasets/EV18/train/JPEGImages/seq12/frame068.png
74
./datasets/EV18/train/JPEGImages/seq11/frame074.png
80
./datasets/EV18/train/JPEGImages/seq11/frame080.png
56
./datasets/EV18/train/JPEGImages/seq3/frame056.png
65
./datasets/EV18/train/JPEGImages/seq3/frame065.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(146.8820, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.3751, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7447, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
65
./datasets/EV18/train/JPEGImages/seq4/frame065.png
74
./datasets/EV18/train/JPEGImages/seq4/frame074.png
60
./datasets/EV18/train/JPEGImages/seq3/frame060.png
68
./datasets/EV18/train/JPEGImages/seq3/frame068.png
57
./datasets/EV18/train/JPEGImages/seq1/frame057.png
62
./datasets/EV18/train/JPEGImages/seq1/frame062.png
18
./datasets/EV18/train/JPEGImages/seq12/frame018.png
26
./datasets/EV18/train/JPEGImages/seq12/frame026.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(140.8041, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.8273, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8630, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
56
./datasets/EV18/train/JPEGImages/seq16/frame056.png
57
./datasets/EV18/train/JPEGImages/seq16/frame057.png
122
./datasets/EV18/train/JPEGImages/seq14/frame122.png
124
./datasets/EV18/train/JPEGImages/seq14/frame124.png
78
./datasets/EV18/train/JPEGImages/seq6/frame078.png
86
./datasets/EV18/train/JPEGImages/seq6/frame086.png
43
./datasets/EV18/train/JPEGImages/seq1/frame043.png
51
./datasets/EV18/train/JPEGImages/seq1/frame051.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(177.3784, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.8048, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8716, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
113
./datasets/EV18/train/JPEGImages/seq16/frame113.png
117
./datasets/EV18/train/JPEGImages/seq16/frame117.png
103
./datasets/EV18/train/JPEGImages/seq7/frame103.png
104
./datasets/EV18/train/JPEGImages/seq7/frame104.png
4
./datasets/EV18/train/JPEGImages/seq3/frame004.png
10
./datasets/EV18/train/JPEGImages/seq3/frame010.png
119
./datasets/EV18/train/JPEGImages/seq1/frame119.png
126
./datasets/EV18/train/JPEGImages/seq1/frame126.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(149.7554, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.6652, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8166, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
72
./datasets/EV18/train/JPEGImages/seq14/frame072.png
81
./datasets/EV18/train/JPEGImages/seq14/frame081.png
113
./datasets/EV18/train/JPEGImages/seq4/frame113.png
122
./datasets/EV18/train/JPEGImages/seq4/frame122.png
113
./datasets/EV18/train/JPEGImages/seq10/frame113.png
122
./datasets/EV18/train/JPEGImages/seq10/frame122.png
2
./datasets/EV18/train/JPEGImages/seq6/frame002.png
9
./datasets/EV18/train/JPEGImages/seq6/frame009.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(108.2369, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5534, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8051, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
10
./datasets/EV18/train/JPEGImages/seq13/frame010.png
11
./datasets/EV18/train/JPEGImages/seq13/frame011.png
20
./datasets/EV18/train/JPEGImages/seq14/frame020.png
27
./datasets/EV18/train/JPEGImages/seq14/frame027.png
34
./datasets/EV18/train/JPEGImages/seq13/frame034.png
41
./datasets/EV18/train/JPEGImages/seq13/frame041.png
110
./datasets/EV18/train/JPEGImages/seq10/frame110.png
114
./datasets/EV18/train/JPEGImages/seq10/frame114.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(150.2366, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.4699, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7769, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
120
./datasets/EV18/train/JPEGImages/seq16/frame120.png
126
./datasets/EV18/train/JPEGImages/seq16/frame126.png
39
./datasets/EV18/train/JPEGImages/seq7/frame039.png
40
./datasets/EV18/train/JPEGImages/seq7/frame040.png
49
./datasets/EV18/train/JPEGImages/seq14/frame049.png
59
./datasets/EV18/train/JPEGImages/seq14/frame059.png
16
./datasets/EV18/train/JPEGImages/seq7/frame016.png
22
./datasets/EV18/train/JPEGImages/seq7/frame022.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(136.3355, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.3742, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7518, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
1
./datasets/EV18/train/JPEGImages/seq12/frame001.png
8
./datasets/EV18/train/JPEGImages/seq12/frame008.png
46
./datasets/EV18/train/JPEGImages/seq3/frame046.png
53
./datasets/EV18/train/JPEGImages/seq3/frame053.png
66
./datasets/EV18/train/JPEGImages/seq14/frame066.png
69
./datasets/EV18/train/JPEGImages/seq14/frame069.png
11
./datasets/EV18/train/JPEGImages/seq16/frame011.png
12
./datasets/EV18/train/JPEGImages/seq16/frame012.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(143.6750, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5407, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7937, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
90
./datasets/EV18/train/JPEGImages/seq6/frame090.png
93
./datasets/EV18/train/JPEGImages/seq6/frame093.png
22
./datasets/EV18/train/JPEGImages/seq13/frame022.png
24
./datasets/EV18/train/JPEGImages/seq13/frame024.png
119
./datasets/EV18/train/JPEGImages/seq11/frame119.png
123
./datasets/EV18/train/JPEGImages/seq11/frame123.png
2
./datasets/EV18/train/JPEGImages/seq10/frame002.png
10
./datasets/EV18/train/JPEGImages/seq10/frame010.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(205.4565, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5651, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8217, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
14
./datasets/EV18/train/JPEGImages/seq7/frame014.png
17
./datasets/EV18/train/JPEGImages/seq7/frame017.png
2
./datasets/EV18/train/JPEGImages/seq13/frame002.png
5
./datasets/EV18/train/JPEGImages/seq13/frame005.png
20
./datasets/EV18/train/JPEGImages/seq10/frame020.png
25
./datasets/EV18/train/JPEGImages/seq10/frame025.png
27
./datasets/EV18/train/JPEGImages/seq1/frame027.png
30
./datasets/EV18/train/JPEGImages/seq1/frame030.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(145.8059, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.4432, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7749, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
[05/26 01:45:24 d2.utils.events]:  eta: 3:53:48  iter: 219  total_loss: 2273  loss_ce: 228.7  loss_bbox: 1.66  loss_giou: 0.841  loss_mask: 1.474  loss_dice: 0.9493  loss_ce_dn: 1.828  loss_mask_dn: 1.449  loss_dice_dn: 0.946  loss_bbox_dn: 0.2265  loss_giou_dn: 0.4256  loss_ce_0: 205.1  loss_mask_0: 0.8119  loss_dice_0: 0.933  loss_bbox_0: 1.667  loss_giou_0: 0.841  loss_ce_dn_0: 1.125  loss_mask_dn_0: 1.151  loss_dice_dn_0: 0.9358  loss_bbox_dn_0: 0.2265  loss_giou_dn_0: 0.4256  loss_ce_1: 186.1  loss_mask_1: 0.768  loss_dice_1: 0.9347  loss_bbox_1: 1.668  loss_giou_1: 0.8408  loss_ce_dn_1: 1.139  loss_mask_dn_1: 1.071  loss_dice_dn_1: 0.9298  loss_bbox_dn_1: 0.2265  loss_giou_dn_1: 0.4256  loss_ce_2: 146  loss_mask_2: 0.8017  loss_dice_2: 0.923  loss_bbox_2: 1.669  loss_giou_2: 0.8408  loss_ce_dn_2: 1.076  loss_mask_dn_2: 0.9776  loss_dice_dn_2: 0.916  loss_bbox_dn_2: 0.2265  loss_giou_dn_2: 0.4256  loss_ce_3: 222.2  loss_mask_3: 0.7524  loss_dice_3: 0.9104  loss_bbox_3: 1.669  loss_giou_3: 0.8407  loss_ce_dn_3: 1.72  loss_mask_dn_3: 0.8877  loss_dice_dn_3: 0.9136  loss_bbox_dn_3: 0.2265  loss_giou_dn_3: 0.4256  loss_ce_4: 138.1  loss_mask_4: 0.8975  loss_dice_4: 0.9112  loss_bbox_4: 1.67  loss_giou_4: 0.8406  loss_ce_dn_4: 1.174  loss_mask_dn_4: 1.06  loss_dice_dn_4: 0.9186  loss_bbox_dn_4: 0.2265  loss_giou_dn_4: 0.4256  loss_ce_5: 213.2  loss_mask_5: 0.7227  loss_dice_5: 0.9139  loss_bbox_5: 1.666  loss_giou_5: 0.8407  loss_ce_dn_5: 1.927  loss_mask_dn_5: 0.7615  loss_dice_dn_5: 0.9188  loss_bbox_dn_5: 0.2265  loss_giou_dn_5: 0.4256  loss_ce_6: 139.8  loss_mask_6: 0.8264  loss_dice_6: 0.9291  loss_bbox_6: 1.664  loss_giou_6: 0.8407  loss_ce_dn_6: 1.345  loss_mask_dn_6: 0.8833  loss_dice_dn_6: 0.9332  loss_bbox_dn_6: 0.2265  loss_giou_dn_6: 0.4256  loss_ce_7: 233.8  loss_mask_7: 0.901  loss_dice_7: 0.9377  loss_bbox_7: 1.661  loss_giou_7: 0.8404  loss_ce_dn_7: 1.973  loss_mask_dn_7: 0.9055  loss_dice_dn_7: 0.9349  loss_bbox_dn_7: 0.2265  loss_giou_dn_7: 0.4256  loss_ce_8: 239.8  loss_mask_8: 1.178  loss_dice_8: 0.9258  loss_bbox_8: 1.666  loss_giou_8: 0.8405  loss_ce_dn_8: 2.072  loss_mask_dn_8: 1.187  loss_dice_dn_8: 0.9231  loss_bbox_dn_8: 0.2265  loss_giou_dn_8: 0.4256  loss_ce_interm: 205.2  loss_mask_interm: 0.9028  loss_dice_interm: 0.9392  loss_bbox_interm: 0.7126  loss_giou_interm: 1.07    time: 1.1723  last_time: 1.1083  data_time: 0.0128  last_data_time: 0.0147   lr: 0.0001  max_mem: 18844M
115
./datasets/EV18/train/JPEGImages/seq11/frame115.png
120
./datasets/EV18/train/JPEGImages/seq11/frame120.png
77
./datasets/EV18/train/JPEGImages/seq4/frame077.png
87
./datasets/EV18/train/JPEGImages/seq4/frame087.png
15
./datasets/EV18/train/JPEGImages/seq6/frame015.png
23
./datasets/EV18/train/JPEGImages/seq6/frame023.png
122
./datasets/EV18/train/JPEGImages/seq16/frame122.png
123
./datasets/EV18/train/JPEGImages/seq16/frame123.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(122.1268, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5069, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7797, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
63
./datasets/EV18/train/JPEGImages/seq4/frame063.png
67
./datasets/EV18/train/JPEGImages/seq4/frame067.png
147
./datasets/EV18/train/JPEGImages/seq11/frame147.png
148
./datasets/EV18/train/JPEGImages/seq11/frame148.png
62
./datasets/EV18/train/JPEGImages/seq16/frame062.png
71
./datasets/EV18/train/JPEGImages/seq16/frame071.png
140
./datasets/EV18/train/JPEGImages/seq3/frame140.png
145
./datasets/EV18/train/JPEGImages/seq3/frame145.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(155.4019, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5996, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8116, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
34
./datasets/EV18/train/JPEGImages/seq4/frame034.png
40
./datasets/EV18/train/JPEGImages/seq4/frame040.png
8
./datasets/EV18/train/JPEGImages/seq1/frame008.png
13
./datasets/EV18/train/JPEGImages/seq1/frame013.png
115
./datasets/EV18/train/JPEGImages/seq12/frame115.png
122
./datasets/EV18/train/JPEGImages/seq12/frame122.png
1
./datasets/EV18/train/JPEGImages/seq3/frame001.png
10
./datasets/EV18/train/JPEGImages/seq3/frame010.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(145.0851, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5734, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7965, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
22
./datasets/EV18/train/JPEGImages/seq6/frame022.png
23
./datasets/EV18/train/JPEGImages/seq6/frame023.png
30
./datasets/EV18/train/JPEGImages/seq1/frame030.png
33
./datasets/EV18/train/JPEGImages/seq1/frame033.png
133
./datasets/EV18/train/JPEGImages/seq7/frame133.png
141
./datasets/EV18/train/JPEGImages/seq7/frame141.png
20
./datasets/EV18/train/JPEGImages/seq6/frame020.png
23
./datasets/EV18/train/JPEGImages/seq6/frame023.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(193.6654, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.8418, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.9010, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
128
./datasets/EV18/train/JPEGImages/seq11/frame128.png
136
./datasets/EV18/train/JPEGImages/seq11/frame136.png
88
./datasets/EV18/train/JPEGImages/seq10/frame088.png
97
./datasets/EV18/train/JPEGImages/seq10/frame097.png
32
./datasets/EV18/train/JPEGImages/seq7/frame032.png
36
./datasets/EV18/train/JPEGImages/seq7/frame036.png
61
./datasets/EV18/train/JPEGImages/seq16/frame061.png
64
./datasets/EV18/train/JPEGImages/seq16/frame064.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(241.1830, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.7756, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8694, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
78
./datasets/EV18/train/JPEGImages/seq12/frame078.png
86
./datasets/EV18/train/JPEGImages/seq12/frame086.png
114
./datasets/EV18/train/JPEGImages/seq1/frame114.png
117
./datasets/EV18/train/JPEGImages/seq1/frame117.png
25
./datasets/EV18/train/JPEGImages/seq3/frame025.png
33
./datasets/EV18/train/JPEGImages/seq3/frame033.png
54
./datasets/EV18/train/JPEGImages/seq12/frame054.png
57
./datasets/EV18/train/JPEGImages/seq12/frame057.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(258.1180, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.7917, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8483, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
69
./datasets/EV18/train/JPEGImages/seq12/frame069.png
77
./datasets/EV18/train/JPEGImages/seq12/frame077.png
38
./datasets/EV18/train/JPEGImages/seq14/frame038.png
42
./datasets/EV18/train/JPEGImages/seq14/frame042.png
67
./datasets/EV18/train/JPEGImages/seq3/frame067.png
75
./datasets/EV18/train/JPEGImages/seq3/frame075.png
4
./datasets/EV18/train/JPEGImages/seq6/frame004.png
13
./datasets/EV18/train/JPEGImages/seq6/frame013.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(144.1811, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.3567, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7312, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
2
./datasets/EV18/train/JPEGImages/seq10/frame002.png
3
./datasets/EV18/train/JPEGImages/seq10/frame003.png
69
./datasets/EV18/train/JPEGImages/seq4/frame069.png
75
./datasets/EV18/train/JPEGImages/seq4/frame075.png
60
./datasets/EV18/train/JPEGImages/seq11/frame060.png
68
./datasets/EV18/train/JPEGImages/seq11/frame068.png
65
./datasets/EV18/train/JPEGImages/seq7/frame065.png
71
./datasets/EV18/train/JPEGImages/seq7/frame071.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(114.1704, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.3490, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7068, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
109
./datasets/EV18/train/JPEGImages/seq13/frame109.png
113
./datasets/EV18/train/JPEGImages/seq13/frame113.png
134
./datasets/EV18/train/JPEGImages/seq4/frame134.png
138
./datasets/EV18/train/JPEGImages/seq4/frame138.png
127
./datasets/EV18/train/JPEGImages/seq1/frame127.png
134
./datasets/EV18/train/JPEGImages/seq1/frame134.png
25
./datasets/EV18/train/JPEGImages/seq13/frame025.png
33
./datasets/EV18/train/JPEGImages/seq13/frame033.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(141.5680, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.4480, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7924, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
16
./datasets/EV18/train/JPEGImages/seq12/frame016.png
19
./datasets/EV18/train/JPEGImages/seq12/frame019.png
60
./datasets/EV18/train/JPEGImages/seq13/frame060.png
70
./datasets/EV18/train/JPEGImages/seq13/frame070.png
78
./datasets/EV18/train/JPEGImages/seq6/frame078.png
81
./datasets/EV18/train/JPEGImages/seq6/frame081.png
93
./datasets/EV18/train/JPEGImages/seq6/frame093.png
99
./datasets/EV18/train/JPEGImages/seq6/frame099.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(187.8299, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5645, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7977, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
54
./datasets/EV18/train/JPEGImages/seq4/frame054.png
60
./datasets/EV18/train/JPEGImages/seq4/frame060.png
28
./datasets/EV18/train/JPEGImages/seq10/frame028.png
32
./datasets/EV18/train/JPEGImages/seq10/frame032.png
53
./datasets/EV18/train/JPEGImages/seq14/frame053.png
63
./datasets/EV18/train/JPEGImages/seq14/frame063.png
74
./datasets/EV18/train/JPEGImages/seq11/frame074.png
82
./datasets/EV18/train/JPEGImages/seq11/frame082.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(108.8755, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.2775, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7163, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
96
./datasets/EV18/train/JPEGImages/seq7/frame096.png
97
./datasets/EV18/train/JPEGImages/seq7/frame097.png
46
./datasets/EV18/train/JPEGImages/seq16/frame046.png
47
./datasets/EV18/train/JPEGImages/seq16/frame047.png
87
./datasets/EV18/train/JPEGImages/seq14/frame087.png
91
./datasets/EV18/train/JPEGImages/seq14/frame091.png
78
./datasets/EV18/train/JPEGImages/seq13/frame078.png
84
./datasets/EV18/train/JPEGImages/seq13/frame084.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(134.5891, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5541, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8155, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
45
./datasets/EV18/train/JPEGImages/seq10/frame045.png
50
./datasets/EV18/train/JPEGImages/seq10/frame050.png
61
./datasets/EV18/train/JPEGImages/seq3/frame061.png
69
./datasets/EV18/train/JPEGImages/seq3/frame069.png
62
./datasets/EV18/train/JPEGImages/seq12/frame062.png
69
./datasets/EV18/train/JPEGImages/seq12/frame069.png
78
./datasets/EV18/train/JPEGImages/seq6/frame078.png
79
./datasets/EV18/train/JPEGImages/seq6/frame079.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(166.2887, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.6978, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8382, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
59
./datasets/EV18/train/JPEGImages/seq11/frame059.png
65
./datasets/EV18/train/JPEGImages/seq11/frame065.png
3
./datasets/EV18/train/JPEGImages/seq14/frame003.png
9
./datasets/EV18/train/JPEGImages/seq14/frame009.png
15
./datasets/EV18/train/JPEGImages/seq6/frame015.png
18
./datasets/EV18/train/JPEGImages/seq6/frame018.png
29
./datasets/EV18/train/JPEGImages/seq16/frame029.png
37
./datasets/EV18/train/JPEGImages/seq16/frame037.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(127.5714, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.4950, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7625, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
10
./datasets/EV18/train/JPEGImages/seq11/frame010.png
17
./datasets/EV18/train/JPEGImages/seq11/frame017.png
87
./datasets/EV18/train/JPEGImages/seq14/frame087.png
88
./datasets/EV18/train/JPEGImages/seq14/frame088.png
1
./datasets/EV18/train/JPEGImages/seq1/frame001.png
11
./datasets/EV18/train/JPEGImages/seq1/frame011.png
6
./datasets/EV18/train/JPEGImages/seq16/frame006.png
15
./datasets/EV18/train/JPEGImages/seq16/frame015.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(180.9890, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.6697, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8574, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
26
./datasets/EV18/train/JPEGImages/seq7/frame026.png
28
./datasets/EV18/train/JPEGImages/seq7/frame028.png
107
./datasets/EV18/train/JPEGImages/seq11/frame107.png
117
./datasets/EV18/train/JPEGImages/seq11/frame117.png
120
./datasets/EV18/train/JPEGImages/seq7/frame120.png
125
./datasets/EV18/train/JPEGImages/seq7/frame125.png
83
./datasets/EV18/train/JPEGImages/seq6/frame083.png
87
./datasets/EV18/train/JPEGImages/seq6/frame087.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(135.0517, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5031, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7514, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
105
./datasets/EV18/train/JPEGImages/seq16/frame105.png
109
./datasets/EV18/train/JPEGImages/seq16/frame109.png
84
./datasets/EV18/train/JPEGImages/seq1/frame084.png
91
./datasets/EV18/train/JPEGImages/seq1/frame091.png
96
./datasets/EV18/train/JPEGImages/seq3/frame096.png
104
./datasets/EV18/train/JPEGImages/seq3/frame104.png
28
./datasets/EV18/train/JPEGImages/seq4/frame028.png
36
./datasets/EV18/train/JPEGImages/seq4/frame036.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(136.6804, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.7914, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8549, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
81
./datasets/EV18/train/JPEGImages/seq10/frame081.png
89
./datasets/EV18/train/JPEGImages/seq10/frame089.png
65
./datasets/EV18/train/JPEGImages/seq13/frame065.png
66
./datasets/EV18/train/JPEGImages/seq13/frame066.png
138
./datasets/EV18/train/JPEGImages/seq12/frame138.png
140
./datasets/EV18/train/JPEGImages/seq12/frame140.png
28
./datasets/EV18/train/JPEGImages/seq3/frame028.png
35
./datasets/EV18/train/JPEGImages/seq3/frame035.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(191.4259, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.4486, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7910, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
72
./datasets/EV18/train/JPEGImages/seq4/frame072.png
76
./datasets/EV18/train/JPEGImages/seq4/frame076.png
141
./datasets/EV18/train/JPEGImages/seq13/frame141.png
148
./datasets/EV18/train/JPEGImages/seq13/frame148.png
34
./datasets/EV18/train/JPEGImages/seq14/frame034.png
43
./datasets/EV18/train/JPEGImages/seq14/frame043.png
26
./datasets/EV18/train/JPEGImages/seq10/frame026.png
35
./datasets/EV18/train/JPEGImages/seq10/frame035.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(100.0914, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.3883, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7471, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
39
./datasets/EV18/train/JPEGImages/seq4/frame039.png
46
./datasets/EV18/train/JPEGImages/seq4/frame046.png
137
./datasets/EV18/train/JPEGImages/seq3/frame137.png
140
./datasets/EV18/train/JPEGImages/seq3/frame140.png
45
./datasets/EV18/train/JPEGImages/seq1/frame045.png
48
./datasets/EV18/train/JPEGImages/seq1/frame048.png
22
./datasets/EV18/train/JPEGImages/seq1/frame022.png
24
./datasets/EV18/train/JPEGImages/seq1/frame024.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(109.8317, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5118, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7746, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
[05/26 01:45:47 d2.utils.events]:  eta: 3:53:28  iter: 239  total_loss: 2112  loss_ce: 212.8  loss_bbox: 1.733  loss_giou: 0.8568  loss_mask: 1.431  loss_dice: 0.9536  loss_ce_dn: 1.858  loss_mask_dn: 1.44  loss_dice_dn: 0.9533  loss_bbox_dn: 0.2226  loss_giou_dn: 0.4277  loss_ce_0: 190.2  loss_mask_0: 0.8352  loss_dice_0: 0.9325  loss_bbox_0: 1.732  loss_giou_0: 0.8567  loss_ce_dn_0: 1.108  loss_mask_dn_0: 1.122  loss_dice_dn_0: 0.9392  loss_bbox_dn_0: 0.2226  loss_giou_dn_0: 0.4277  loss_ce_1: 169.4  loss_mask_1: 0.7504  loss_dice_1: 0.9353  loss_bbox_1: 1.74  loss_giou_1: 0.8498  loss_ce_dn_1: 1.129  loss_mask_dn_1: 1.08  loss_dice_dn_1: 0.9474  loss_bbox_dn_1: 0.2226  loss_giou_dn_1: 0.4277  loss_ce_2: 133.9  loss_mask_2: 0.807  loss_dice_2: 0.9334  loss_bbox_2: 1.735  loss_giou_2: 0.8512  loss_ce_dn_2: 1.086  loss_mask_dn_2: 1.015  loss_dice_dn_2: 0.9282  loss_bbox_dn_2: 0.2226  loss_giou_dn_2: 0.4277  loss_ce_3: 217.8  loss_mask_3: 0.7564  loss_dice_3: 0.9176  loss_bbox_3: 1.741  loss_giou_3: 0.8505  loss_ce_dn_3: 1.814  loss_mask_dn_3: 0.91  loss_dice_dn_3: 0.9177  loss_bbox_dn_3: 0.2226  loss_giou_dn_3: 0.4277  loss_ce_4: 134.2  loss_mask_4: 0.8887  loss_dice_4: 0.9281  loss_bbox_4: 1.736  loss_giou_4: 0.8492  loss_ce_dn_4: 1.213  loss_mask_dn_4: 1.074  loss_dice_dn_4: 0.9265  loss_bbox_dn_4: 0.2226  loss_giou_dn_4: 0.4277  loss_ce_5: 202  loss_mask_5: 0.7225  loss_dice_5: 0.9199  loss_bbox_5: 1.734  loss_giou_5: 0.8516  loss_ce_dn_5: 1.982  loss_mask_dn_5: 0.7749  loss_dice_dn_5: 0.9326  loss_bbox_dn_5: 0.2226  loss_giou_dn_5: 0.4277  loss_ce_6: 134.8  loss_mask_6: 0.8262  loss_dice_6: 0.9424  loss_bbox_6: 1.734  loss_giou_6: 0.8566  loss_ce_dn_6: 1.37  loss_mask_dn_6: 0.8747  loss_dice_dn_6: 0.9415  loss_bbox_dn_6: 0.2226  loss_giou_dn_6: 0.4277  loss_ce_7: 223.7  loss_mask_7: 0.8931  loss_dice_7: 0.9425  loss_bbox_7: 1.734  loss_giou_7: 0.8513  loss_ce_dn_7: 2.059  loss_mask_dn_7: 0.8913  loss_dice_dn_7: 0.9413  loss_bbox_dn_7: 0.2226  loss_giou_dn_7: 0.4277  loss_ce_8: 221.6  loss_mask_8: 1.167  loss_dice_8: 0.9292  loss_bbox_8: 1.734  loss_giou_8: 0.8565  loss_ce_dn_8: 2.108  loss_mask_dn_8: 1.179  loss_dice_dn_8: 0.9301  loss_bbox_dn_8: 0.2226  loss_giou_dn_8: 0.4277  loss_ce_interm: 190.4  loss_mask_interm: 0.8967  loss_dice_interm: 0.9381  loss_bbox_interm: 0.6923  loss_giou_interm: 1.042    time: 1.1721  last_time: 1.1976  data_time: 0.0120  last_data_time: 0.0134   lr: 0.0001  max_mem: 18844M
80
./datasets/EV18/train/JPEGImages/seq7/frame080.png
86
./datasets/EV18/train/JPEGImages/seq7/frame086.png
55
./datasets/EV18/train/JPEGImages/seq4/frame055.png
60
./datasets/EV18/train/JPEGImages/seq4/frame060.png
22
./datasets/EV18/train/JPEGImages/seq6/frame022.png
30
./datasets/EV18/train/JPEGImages/seq6/frame030.png
126
./datasets/EV18/train/JPEGImages/seq3/frame126.png
129
./datasets/EV18/train/JPEGImages/seq3/frame129.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(102.3000, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.3498, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7183, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
67
./datasets/EV18/train/JPEGImages/seq1/frame067.png
76
./datasets/EV18/train/JPEGImages/seq1/frame076.png
4
./datasets/EV18/train/JPEGImages/seq16/frame004.png
10
./datasets/EV18/train/JPEGImages/seq16/frame010.png
5
./datasets/EV18/train/JPEGImages/seq4/frame005.png
14
./datasets/EV18/train/JPEGImages/seq4/frame014.png
33
./datasets/EV18/train/JPEGImages/seq10/frame033.png
43
./datasets/EV18/train/JPEGImages/seq10/frame043.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(139.0112, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5849, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8096, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
59
./datasets/EV18/train/JPEGImages/seq11/frame059.png
62
./datasets/EV18/train/JPEGImages/seq11/frame062.png
41
./datasets/EV18/train/JPEGImages/seq16/frame041.png
45
./datasets/EV18/train/JPEGImages/seq16/frame045.png
2
./datasets/EV18/train/JPEGImages/seq13/frame002.png
12
./datasets/EV18/train/JPEGImages/seq13/frame012.png
120
./datasets/EV18/train/JPEGImages/seq14/frame120.png
127
./datasets/EV18/train/JPEGImages/seq14/frame127.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(156.8706, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5307, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8018, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
36
./datasets/EV18/train/JPEGImages/seq12/frame036.png
37
./datasets/EV18/train/JPEGImages/seq12/frame037.png
99
./datasets/EV18/train/JPEGImages/seq1/frame099.png
104
./datasets/EV18/train/JPEGImages/seq1/frame104.png
135
./datasets/EV18/train/JPEGImages/seq14/frame135.png
136
./datasets/EV18/train/JPEGImages/seq14/frame136.png
19
./datasets/EV18/train/JPEGImages/seq11/frame019.png
26
./datasets/EV18/train/JPEGImages/seq11/frame026.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(136.2201, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5614, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7871, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
140
./datasets/EV18/train/JPEGImages/seq14/frame140.png
148
./datasets/EV18/train/JPEGImages/seq14/frame148.png
80
./datasets/EV18/train/JPEGImages/seq12/frame080.png
89
./datasets/EV18/train/JPEGImages/seq12/frame089.png
120
./datasets/EV18/train/JPEGImages/seq10/frame120.png
121
./datasets/EV18/train/JPEGImages/seq10/frame121.png
114
./datasets/EV18/train/JPEGImages/seq11/frame114.png
116
./datasets/EV18/train/JPEGImages/seq11/frame116.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(116.2013, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.2456, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.6984, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
2
./datasets/EV18/train/JPEGImages/seq16/frame002.png
11
./datasets/EV18/train/JPEGImages/seq16/frame011.png
94
./datasets/EV18/train/JPEGImages/seq13/frame094.png
103
./datasets/EV18/train/JPEGImages/seq13/frame103.png
108
./datasets/EV18/train/JPEGImages/seq6/frame108.png
117
./datasets/EV18/train/JPEGImages/seq6/frame117.png
120
./datasets/EV18/train/JPEGImages/seq1/frame120.png
125
./datasets/EV18/train/JPEGImages/seq1/frame125.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(175.0501, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5926, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8224, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
13
./datasets/EV18/train/JPEGImages/seq10/frame013.png
14
./datasets/EV18/train/JPEGImages/seq10/frame014.png
12
./datasets/EV18/train/JPEGImages/seq13/frame012.png
16
./datasets/EV18/train/JPEGImages/seq13/frame016.png
107
./datasets/EV18/train/JPEGImages/seq7/frame107.png
115
./datasets/EV18/train/JPEGImages/seq7/frame115.png
114
./datasets/EV18/train/JPEGImages/seq4/frame114.png
117
./datasets/EV18/train/JPEGImages/seq4/frame117.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(171.4707, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.6909, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8340, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
10
./datasets/EV18/train/JPEGImages/seq7/frame010.png
11
./datasets/EV18/train/JPEGImages/seq7/frame011.png
87
./datasets/EV18/train/JPEGImages/seq12/frame087.png
97
./datasets/EV18/train/JPEGImages/seq12/frame097.png
129
./datasets/EV18/train/JPEGImages/seq3/frame129.png
138
./datasets/EV18/train/JPEGImages/seq3/frame138.png
133
./datasets/EV18/train/JPEGImages/seq7/frame133.png
134
./datasets/EV18/train/JPEGImages/seq7/frame134.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(158.0407, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.3593, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.6902, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
75
./datasets/EV18/train/JPEGImages/seq3/frame075.png
83
./datasets/EV18/train/JPEGImages/seq3/frame083.png
20
./datasets/EV18/train/JPEGImages/seq12/frame020.png
29
./datasets/EV18/train/JPEGImages/seq12/frame029.png
39
./datasets/EV18/train/JPEGImages/seq16/frame039.png
46
./datasets/EV18/train/JPEGImages/seq16/frame046.png
13
./datasets/EV18/train/JPEGImages/seq11/frame013.png
20
./datasets/EV18/train/JPEGImages/seq11/frame020.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(421.5257, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.7363, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8457, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
10
./datasets/EV18/train/JPEGImages/seq7/frame010.png
20
./datasets/EV18/train/JPEGImages/seq7/frame020.png
96
./datasets/EV18/train/JPEGImages/seq1/frame096.png
102
./datasets/EV18/train/JPEGImages/seq1/frame102.png
114
./datasets/EV18/train/JPEGImages/seq12/frame114.png
117
./datasets/EV18/train/JPEGImages/seq12/frame117.png
61
./datasets/EV18/train/JPEGImages/seq7/frame061.png
67
./datasets/EV18/train/JPEGImages/seq7/frame067.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(197.7205, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.7877, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8561, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
117
./datasets/EV18/train/JPEGImages/seq4/frame117.png
119
./datasets/EV18/train/JPEGImages/seq4/frame119.png
56
./datasets/EV18/train/JPEGImages/seq10/frame056.png
60
./datasets/EV18/train/JPEGImages/seq10/frame060.png
119
./datasets/EV18/train/JPEGImages/seq4/frame119.png
121
./datasets/EV18/train/JPEGImages/seq4/frame121.png
68
./datasets/EV18/train/JPEGImages/seq6/frame068.png
74
./datasets/EV18/train/JPEGImages/seq6/frame074.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(121.5500, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5494, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8042, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
137
./datasets/EV18/train/JPEGImages/seq10/frame137.png
141
./datasets/EV18/train/JPEGImages/seq10/frame141.png
129
./datasets/EV18/train/JPEGImages/seq10/frame129.png
138
./datasets/EV18/train/JPEGImages/seq10/frame138.png
75
./datasets/EV18/train/JPEGImages/seq4/frame075.png
85
./datasets/EV18/train/JPEGImages/seq4/frame085.png
7
./datasets/EV18/train/JPEGImages/seq13/frame007.png
11
./datasets/EV18/train/JPEGImages/seq13/frame011.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(138.5573, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.3754, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7477, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
67
./datasets/EV18/train/JPEGImages/seq13/frame067.png
71
./datasets/EV18/train/JPEGImages/seq13/frame071.png
58
./datasets/EV18/train/JPEGImages/seq6/frame058.png
61
./datasets/EV18/train/JPEGImages/seq6/frame061.png
18
./datasets/EV18/train/JPEGImages/seq16/frame018.png
22
./datasets/EV18/train/JPEGImages/seq16/frame022.png
23
./datasets/EV18/train/JPEGImages/seq12/frame023.png
30
./datasets/EV18/train/JPEGImages/seq12/frame030.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(163.2832, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.2634, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7003, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
44
./datasets/EV18/train/JPEGImages/seq13/frame044.png
45
./datasets/EV18/train/JPEGImages/seq13/frame045.png
130
./datasets/EV18/train/JPEGImages/seq11/frame130.png
133
./datasets/EV18/train/JPEGImages/seq11/frame133.png
103
./datasets/EV18/train/JPEGImages/seq14/frame103.png
111
./datasets/EV18/train/JPEGImages/seq14/frame111.png
20
./datasets/EV18/train/JPEGImages/seq6/frame020.png
27
./datasets/EV18/train/JPEGImages/seq6/frame027.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(120.3299, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.3855, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7448, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
43
./datasets/EV18/train/JPEGImages/seq14/frame043.png
49
./datasets/EV18/train/JPEGImages/seq14/frame049.png
26
./datasets/EV18/train/JPEGImages/seq11/frame026.png
28
./datasets/EV18/train/JPEGImages/seq11/frame028.png
65
./datasets/EV18/train/JPEGImages/seq14/frame065.png
74
./datasets/EV18/train/JPEGImages/seq14/frame074.png
33
./datasets/EV18/train/JPEGImages/seq1/frame033.png
40
./datasets/EV18/train/JPEGImages/seq1/frame040.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(149.8024, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5955, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8350, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
122
./datasets/EV18/train/JPEGImages/seq3/frame122.png
132
./datasets/EV18/train/JPEGImages/seq3/frame132.png
129
./datasets/EV18/train/JPEGImages/seq16/frame129.png
136
./datasets/EV18/train/JPEGImages/seq16/frame136.png
19
./datasets/EV18/train/JPEGImages/seq3/frame019.png
21
./datasets/EV18/train/JPEGImages/seq3/frame021.png
74
./datasets/EV18/train/JPEGImages/seq12/frame074.png
81
./datasets/EV18/train/JPEGImages/seq12/frame081.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(200.4690, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.6251, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8250, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
33
./datasets/EV18/train/JPEGImages/seq14/frame033.png
39
./datasets/EV18/train/JPEGImages/seq14/frame039.png
18
./datasets/EV18/train/JPEGImages/seq3/frame018.png
24
./datasets/EV18/train/JPEGImages/seq3/frame024.png
85
./datasets/EV18/train/JPEGImages/seq16/frame085.png
88
./datasets/EV18/train/JPEGImages/seq16/frame088.png
141
./datasets/EV18/train/JPEGImages/seq16/frame141.png
142
./datasets/EV18/train/JPEGImages/seq16/frame142.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(149.3882, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.4826, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7945, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
85
./datasets/EV18/train/JPEGImages/seq10/frame085.png
95
./datasets/EV18/train/JPEGImages/seq10/frame095.png
110
./datasets/EV18/train/JPEGImages/seq7/frame110.png
113
./datasets/EV18/train/JPEGImages/seq7/frame113.png
23
./datasets/EV18/train/JPEGImages/seq13/frame023.png
26
./datasets/EV18/train/JPEGImages/seq13/frame026.png
137
./datasets/EV18/train/JPEGImages/seq14/frame137.png
146
./datasets/EV18/train/JPEGImages/seq14/frame146.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(147.8102, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.2584, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7003, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
30
./datasets/EV18/train/JPEGImages/seq11/frame030.png
36
./datasets/EV18/train/JPEGImages/seq11/frame036.png
78
./datasets/EV18/train/JPEGImages/seq13/frame078.png
81
./datasets/EV18/train/JPEGImages/seq13/frame081.png
13
./datasets/EV18/train/JPEGImages/seq7/frame013.png
14
./datasets/EV18/train/JPEGImages/seq7/frame014.png
56
./datasets/EV18/train/JPEGImages/seq12/frame056.png
66
./datasets/EV18/train/JPEGImages/seq12/frame066.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(160.0458, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.3985, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7356, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
57
./datasets/EV18/train/JPEGImages/seq1/frame057.png
60
./datasets/EV18/train/JPEGImages/seq1/frame060.png
143
./datasets/EV18/train/JPEGImages/seq6/frame143.png
147
./datasets/EV18/train/JPEGImages/seq6/frame147.png
11
./datasets/EV18/train/JPEGImages/seq10/frame011.png
14
./datasets/EV18/train/JPEGImages/seq10/frame014.png
69
./datasets/EV18/train/JPEGImages/seq16/frame069.png
73
./datasets/EV18/train/JPEGImages/seq16/frame073.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(200.6202, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.7882, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8538, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
[05/26 01:46:11 d2.utils.events]:  eta: 3:53:17  iter: 259  total_loss: 2298  loss_ce: 234  loss_bbox: 1.646  loss_giou: 0.8422  loss_mask: 1.469  loss_dice: 0.9467  loss_ce_dn: 1.763  loss_mask_dn: 1.445  loss_dice_dn: 0.9493  loss_bbox_dn: 0.2318  loss_giou_dn: 0.4255  loss_ce_0: 213.9  loss_mask_0: 0.8371  loss_dice_0: 0.9311  loss_bbox_0: 1.651  loss_giou_0: 0.842  loss_ce_dn_0: 1.085  loss_mask_dn_0: 1.133  loss_dice_dn_0: 0.9278  loss_bbox_dn_0: 0.2318  loss_giou_dn_0: 0.4255  loss_ce_1: 193.6  loss_mask_1: 0.7551  loss_dice_1: 0.9344  loss_bbox_1: 1.655  loss_giou_1: 0.8428  loss_ce_dn_1: 1.137  loss_mask_dn_1: 1.07  loss_dice_dn_1: 0.9363  loss_bbox_dn_1: 0.2318  loss_giou_dn_1: 0.4255  loss_ce_2: 145.9  loss_mask_2: 0.8104  loss_dice_2: 0.9244  loss_bbox_2: 1.649  loss_giou_2: 0.842  loss_ce_dn_2: 1.071  loss_mask_dn_2: 0.9968  loss_dice_dn_2: 0.9131  loss_bbox_dn_2: 0.2318  loss_giou_dn_2: 0.4255  loss_ce_3: 224.5  loss_mask_3: 0.7515  loss_dice_3: 0.9064  loss_bbox_3: 1.648  loss_giou_3: 0.8421  loss_ce_dn_3: 1.757  loss_mask_dn_3: 0.8931  loss_dice_dn_3: 0.9124  loss_bbox_dn_3: 0.2318  loss_giou_dn_3: 0.4255  loss_ce_4: 141.6  loss_mask_4: 0.8945  loss_dice_4: 0.9207  loss_bbox_4: 1.649  loss_giou_4: 0.8421  loss_ce_dn_4: 1.195  loss_mask_dn_4: 1.06  loss_dice_dn_4: 0.9165  loss_bbox_dn_4: 0.2318  loss_giou_dn_4: 0.4255  loss_ce_5: 219.3  loss_mask_5: 0.7279  loss_dice_5: 0.9127  loss_bbox_5: 1.648  loss_giou_5: 0.8419  loss_ce_dn_5: 1.986  loss_mask_dn_5: 0.7727  loss_dice_dn_5: 0.9194  loss_bbox_dn_5: 0.2318  loss_giou_dn_5: 0.4255  loss_ce_6: 145.9  loss_mask_6: 0.8305  loss_dice_6: 0.9358  loss_bbox_6: 1.648  loss_giou_6: 0.8422  loss_ce_dn_6: 1.389  loss_mask_dn_6: 0.8926  loss_dice_dn_6: 0.9356  loss_bbox_dn_6: 0.2318  loss_giou_dn_6: 0.4255  loss_ce_7: 239.2  loss_mask_7: 0.9126  loss_dice_7: 0.9308  loss_bbox_7: 1.647  loss_giou_7: 0.8421  loss_ce_dn_7: 2.006  loss_mask_dn_7: 0.9266  loss_dice_dn_7: 0.928  loss_bbox_dn_7: 0.2318  loss_giou_dn_7: 0.4255  loss_ce_8: 240.6  loss_mask_8: 1.188  loss_dice_8: 0.9257  loss_bbox_8: 1.649  loss_giou_8: 0.8422  loss_ce_dn_8: 2.003  loss_mask_dn_8: 1.185  loss_dice_dn_8: 0.9193  loss_bbox_dn_8: 0.2318  loss_giou_dn_8: 0.4255  loss_ce_interm: 214  loss_mask_interm: 0.9228  loss_dice_interm: 0.9375  loss_bbox_interm: 0.75  loss_giou_interm: 1.069    time: 1.1725  last_time: 1.2035  data_time: 0.0131  last_data_time: 0.0149   lr: 0.0001  max_mem: 18844M
18
./datasets/EV18/train/JPEGImages/seq10/frame018.png
21
./datasets/EV18/train/JPEGImages/seq10/frame021.png
45
./datasets/EV18/train/JPEGImages/seq4/frame045.png
46
./datasets/EV18/train/JPEGImages/seq4/frame046.png
84
./datasets/EV18/train/JPEGImages/seq4/frame084.png
94
./datasets/EV18/train/JPEGImages/seq4/frame094.png
35
./datasets/EV18/train/JPEGImages/seq14/frame035.png
39
./datasets/EV18/train/JPEGImages/seq14/frame039.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(75.0835, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.2672, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.6771, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
117
./datasets/EV18/train/JPEGImages/seq6/frame117.png
121
./datasets/EV18/train/JPEGImages/seq6/frame121.png
88
./datasets/EV18/train/JPEGImages/seq3/frame088.png
93
./datasets/EV18/train/JPEGImages/seq3/frame093.png
142
./datasets/EV18/train/JPEGImages/seq1/frame142.png
148
./datasets/EV18/train/JPEGImages/seq1/frame148.png
143
./datasets/EV18/train/JPEGImages/seq7/frame143.png
147
./datasets/EV18/train/JPEGImages/seq7/frame147.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(159.2222, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.6595, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8116, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
136
./datasets/EV18/train/JPEGImages/seq1/frame136.png
141
./datasets/EV18/train/JPEGImages/seq1/frame141.png
93
./datasets/EV18/train/JPEGImages/seq6/frame093.png
100
./datasets/EV18/train/JPEGImages/seq6/frame100.png
74
./datasets/EV18/train/JPEGImages/seq11/frame074.png
80
./datasets/EV18/train/JPEGImages/seq11/frame080.png
124
./datasets/EV18/train/JPEGImages/seq13/frame124.png
127
./datasets/EV18/train/JPEGImages/seq13/frame127.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(139.2054, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5043, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7772, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
124
./datasets/EV18/train/JPEGImages/seq3/frame124.png
129
./datasets/EV18/train/JPEGImages/seq3/frame129.png
127
./datasets/EV18/train/JPEGImages/seq12/frame127.png
135
./datasets/EV18/train/JPEGImages/seq12/frame135.png
111
./datasets/EV18/train/JPEGImages/seq4/frame111.png
113
./datasets/EV18/train/JPEGImages/seq4/frame113.png
106
./datasets/EV18/train/JPEGImages/seq11/frame106.png
108
./datasets/EV18/train/JPEGImages/seq11/frame108.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(128.8240, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.4111, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7381, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
57
./datasets/EV18/train/JPEGImages/seq6/frame057.png
66
./datasets/EV18/train/JPEGImages/seq6/frame066.png
49
./datasets/EV18/train/JPEGImages/seq14/frame049.png
59
./datasets/EV18/train/JPEGImages/seq14/frame059.png
117
./datasets/EV18/train/JPEGImages/seq16/frame117.png
120
./datasets/EV18/train/JPEGImages/seq16/frame120.png
66
./datasets/EV18/train/JPEGImages/seq10/frame066.png
68
./datasets/EV18/train/JPEGImages/seq10/frame068.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(174.1462, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5523, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8263, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
64
./datasets/EV18/train/JPEGImages/seq1/frame064.png
72
./datasets/EV18/train/JPEGImages/seq1/frame072.png
23
./datasets/EV18/train/JPEGImages/seq3/frame023.png
29
./datasets/EV18/train/JPEGImages/seq3/frame029.png
32
./datasets/EV18/train/JPEGImages/seq10/frame032.png
34
./datasets/EV18/train/JPEGImages/seq10/frame034.png
96
./datasets/EV18/train/JPEGImages/seq13/frame096.png
106
./datasets/EV18/train/JPEGImages/seq13/frame106.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(197.6426, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.6896, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8409, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
17
./datasets/EV18/train/JPEGImages/seq12/frame017.png
23
./datasets/EV18/train/JPEGImages/seq12/frame023.png
34
./datasets/EV18/train/JPEGImages/seq7/frame034.png
43
./datasets/EV18/train/JPEGImages/seq7/frame043.png
41
./datasets/EV18/train/JPEGImages/seq11/frame041.png
46
./datasets/EV18/train/JPEGImages/seq11/frame046.png
112
./datasets/EV18/train/JPEGImages/seq6/frame112.png
121
./datasets/EV18/train/JPEGImages/seq6/frame121.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(205.3551, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.6236, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8110, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
2
./datasets/EV18/train/JPEGImages/seq4/frame002.png
8
./datasets/EV18/train/JPEGImages/seq4/frame008.png
113
./datasets/EV18/train/JPEGImages/seq12/frame113.png
121
./datasets/EV18/train/JPEGImages/seq12/frame121.png
126
./datasets/EV18/train/JPEGImages/seq12/frame126.png
132
./datasets/EV18/train/JPEGImages/seq12/frame132.png
55
./datasets/EV18/train/JPEGImages/seq3/frame055.png
56
./datasets/EV18/train/JPEGImages/seq3/frame056.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(186.7045, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.6427, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8421, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
87
./datasets/EV18/train/JPEGImages/seq4/frame087.png
89
./datasets/EV18/train/JPEGImages/seq4/frame089.png
82
./datasets/EV18/train/JPEGImages/seq13/frame082.png
88
./datasets/EV18/train/JPEGImages/seq13/frame088.png
95
./datasets/EV18/train/JPEGImages/seq1/frame095.png
99
./datasets/EV18/train/JPEGImages/seq1/frame099.png
133
./datasets/EV18/train/JPEGImages/seq7/frame133.png
137
./datasets/EV18/train/JPEGImages/seq7/frame137.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(175.7564, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.6500, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8000, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
59
./datasets/EV18/train/JPEGImages/seq11/frame059.png
60
./datasets/EV18/train/JPEGImages/seq11/frame060.png
125
./datasets/EV18/train/JPEGImages/seq1/frame125.png
135
./datasets/EV18/train/JPEGImages/seq1/frame135.png
42
./datasets/EV18/train/JPEGImages/seq4/frame042.png
51
./datasets/EV18/train/JPEGImages/seq4/frame051.png
65
./datasets/EV18/train/JPEGImages/seq7/frame065.png
74
./datasets/EV18/train/JPEGImages/seq7/frame074.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(96.8958, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.3074, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.6746, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
132
./datasets/EV18/train/JPEGImages/seq10/frame132.png
139
./datasets/EV18/train/JPEGImages/seq10/frame139.png
19
./datasets/EV18/train/JPEGImages/seq3/frame019.png
21
./datasets/EV18/train/JPEGImages/seq3/frame021.png
6
./datasets/EV18/train/JPEGImages/seq14/frame006.png
12
./datasets/EV18/train/JPEGImages/seq14/frame012.png
96
./datasets/EV18/train/JPEGImages/seq16/frame096.png
103
./datasets/EV18/train/JPEGImages/seq16/frame103.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(156.2217, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5185, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7799, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
109
./datasets/EV18/train/JPEGImages/seq13/frame109.png
110
./datasets/EV18/train/JPEGImages/seq13/frame110.png
49
./datasets/EV18/train/JPEGImages/seq11/frame049.png
53
./datasets/EV18/train/JPEGImages/seq11/frame053.png
44
./datasets/EV18/train/JPEGImages/seq14/frame044.png
45
./datasets/EV18/train/JPEGImages/seq14/frame045.png
100
./datasets/EV18/train/JPEGImages/seq16/frame100.png
109
./datasets/EV18/train/JPEGImages/seq16/frame109.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(93.3605, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.2282, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.6872, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
65
./datasets/EV18/train/JPEGImages/seq6/frame065.png
70
./datasets/EV18/train/JPEGImages/seq6/frame070.png
127
./datasets/EV18/train/JPEGImages/seq1/frame127.png
132
./datasets/EV18/train/JPEGImages/seq1/frame132.png
90
./datasets/EV18/train/JPEGImages/seq6/frame090.png
93
./datasets/EV18/train/JPEGImages/seq6/frame093.png
11
./datasets/EV18/train/JPEGImages/seq4/frame011.png
17
./datasets/EV18/train/JPEGImages/seq4/frame017.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(134.9267, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5331, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7926, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
54
./datasets/EV18/train/JPEGImages/seq3/frame054.png
59
./datasets/EV18/train/JPEGImages/seq3/frame059.png
138
./datasets/EV18/train/JPEGImages/seq1/frame138.png
146
./datasets/EV18/train/JPEGImages/seq1/frame146.png
1
./datasets/EV18/train/JPEGImages/seq1/frame001.png
2
./datasets/EV18/train/JPEGImages/seq1/frame002.png
75
./datasets/EV18/train/JPEGImages/seq12/frame075.png
79
./datasets/EV18/train/JPEGImages/seq12/frame079.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(152.4900, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.6908, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8421, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
115
./datasets/EV18/train/JPEGImages/seq3/frame115.png
117
./datasets/EV18/train/JPEGImages/seq3/frame117.png
79
./datasets/EV18/train/JPEGImages/seq16/frame079.png
87
./datasets/EV18/train/JPEGImages/seq16/frame087.png
117
./datasets/EV18/train/JPEGImages/seq13/frame117.png
122
./datasets/EV18/train/JPEGImages/seq13/frame122.png
35
./datasets/EV18/train/JPEGImages/seq11/frame035.png
45
./datasets/EV18/train/JPEGImages/seq11/frame045.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(200.0363, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.6292, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8212, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
83
./datasets/EV18/train/JPEGImages/seq13/frame083.png
84
./datasets/EV18/train/JPEGImages/seq13/frame084.png
17
./datasets/EV18/train/JPEGImages/seq14/frame017.png
20
./datasets/EV18/train/JPEGImages/seq14/frame020.png
123
./datasets/EV18/train/JPEGImages/seq11/frame123.png
124
./datasets/EV18/train/JPEGImages/seq11/frame124.png
30
./datasets/EV18/train/JPEGImages/seq6/frame030.png
32
./datasets/EV18/train/JPEGImages/seq6/frame032.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(107.3820, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.3333, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7026, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
72
./datasets/EV18/train/JPEGImages/seq11/frame072.png
82
./datasets/EV18/train/JPEGImages/seq11/frame082.png
84
./datasets/EV18/train/JPEGImages/seq4/frame084.png
92
./datasets/EV18/train/JPEGImages/seq4/frame092.png
116
./datasets/EV18/train/JPEGImages/seq14/frame116.png
118
./datasets/EV18/train/JPEGImages/seq14/frame118.png
121
./datasets/EV18/train/JPEGImages/seq16/frame121.png
131
./datasets/EV18/train/JPEGImages/seq16/frame131.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(119.2790, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5014, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7914, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
84
./datasets/EV18/train/JPEGImages/seq7/frame084.png
90
./datasets/EV18/train/JPEGImages/seq7/frame090.png
7
./datasets/EV18/train/JPEGImages/seq6/frame007.png
10
./datasets/EV18/train/JPEGImages/seq6/frame010.png
77
./datasets/EV18/train/JPEGImages/seq7/frame077.png
78
./datasets/EV18/train/JPEGImages/seq7/frame078.png
44
./datasets/EV18/train/JPEGImages/seq3/frame044.png
54
./datasets/EV18/train/JPEGImages/seq3/frame054.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(114.8211, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.4766, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7788, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
38
./datasets/EV18/train/JPEGImages/seq10/frame038.png
44
./datasets/EV18/train/JPEGImages/seq10/frame044.png
128
./datasets/EV18/train/JPEGImages/seq12/frame128.png
130
./datasets/EV18/train/JPEGImages/seq12/frame130.png
47
./datasets/EV18/train/JPEGImages/seq7/frame047.png
55
./datasets/EV18/train/JPEGImages/seq7/frame055.png
75
./datasets/EV18/train/JPEGImages/seq10/frame075.png
82
./datasets/EV18/train/JPEGImages/seq10/frame082.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(152.4772, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.6877, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8236, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
86
./datasets/EV18/train/JPEGImages/seq12/frame086.png
94
./datasets/EV18/train/JPEGImages/seq12/frame094.png
73
./datasets/EV18/train/JPEGImages/seq14/frame073.png
76
./datasets/EV18/train/JPEGImages/seq14/frame076.png
6
./datasets/EV18/train/JPEGImages/seq16/frame006.png
12
./datasets/EV18/train/JPEGImages/seq16/frame012.png
15
./datasets/EV18/train/JPEGImages/seq10/frame015.png
16
./datasets/EV18/train/JPEGImages/seq10/frame016.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(162.6994, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.4634, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7592, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
[05/26 01:46:34 d2.utils.events]:  eta: 3:52:59  iter: 279  total_loss: 2177  loss_ce: 219.9  loss_bbox: 1.675  loss_giou: 0.8493  loss_mask: 1.452  loss_dice: 0.957  loss_ce_dn: 1.84  loss_mask_dn: 1.427  loss_dice_dn: 0.9544  loss_bbox_dn: 0.2265  loss_giou_dn: 0.4244  loss_ce_0: 198.7  loss_mask_0: 0.815  loss_dice_0: 0.9237  loss_bbox_0: 1.686  loss_giou_0: 0.849  loss_ce_dn_0: 1.134  loss_mask_dn_0: 1.135  loss_dice_dn_0: 0.9389  loss_bbox_dn_0: 0.2265  loss_giou_dn_0: 0.4244  loss_ce_1: 173.9  loss_mask_1: 0.7504  loss_dice_1: 0.9346  loss_bbox_1: 1.686  loss_giou_1: 0.8423  loss_ce_dn_1: 1.149  loss_mask_dn_1: 1.07  loss_dice_dn_1: 0.9458  loss_bbox_dn_1: 0.2265  loss_giou_dn_1: 0.4244  loss_ce_2: 138.6  loss_mask_2: 0.8078  loss_dice_2: 0.9269  loss_bbox_2: 1.681  loss_giou_2: 0.8419  loss_ce_dn_2: 1.095  loss_mask_dn_2: 1.005  loss_dice_dn_2: 0.9269  loss_bbox_dn_2: 0.2265  loss_giou_dn_2: 0.4244  loss_ce_3: 220.9  loss_mask_3: 0.7467  loss_dice_3: 0.9001  loss_bbox_3: 1.687  loss_giou_3: 0.8437  loss_ce_dn_3: 1.753  loss_mask_dn_3: 0.9324  loss_dice_dn_3: 0.9119  loss_bbox_dn_3: 0.2265  loss_giou_dn_3: 0.4244  loss_ce_4: 139.4  loss_mask_4: 0.8901  loss_dice_4: 0.9243  loss_bbox_4: 1.685  loss_giou_4: 0.8432  loss_ce_dn_4: 1.162  loss_mask_dn_4: 1.061  loss_dice_dn_4: 0.9225  loss_bbox_dn_4: 0.2265  loss_giou_dn_4: 0.4244  loss_ce_5: 205.3  loss_mask_5: 0.724  loss_dice_5: 0.9173  loss_bbox_5: 1.676  loss_giou_5: 0.8441  loss_ce_dn_5: 2.01  loss_mask_dn_5: 0.7715  loss_dice_dn_5: 0.9323  loss_bbox_dn_5: 0.2265  loss_giou_dn_5: 0.4244  loss_ce_6: 137.6  loss_mask_6: 0.8258  loss_dice_6: 0.9486  loss_bbox_6: 1.675  loss_giou_6: 0.8417  loss_ce_dn_6: 1.368  loss_mask_dn_6: 0.8978  loss_dice_dn_6: 0.948  loss_bbox_dn_6: 0.2265  loss_giou_dn_6: 0.4244  loss_ce_7: 224.6  loss_mask_7: 0.8836  loss_dice_7: 0.9409  loss_bbox_7: 1.687  loss_giou_7: 0.8419  loss_ce_dn_7: 2.01  loss_mask_dn_7: 0.9084  loss_dice_dn_7: 0.9367  loss_bbox_dn_7: 0.2265  loss_giou_dn_7: 0.4244  loss_ce_8: 228.7  loss_mask_8: 1.181  loss_dice_8: 0.9296  loss_bbox_8: 1.678  loss_giou_8: 0.8443  loss_ce_dn_8: 2.085  loss_mask_dn_8: 1.175  loss_dice_dn_8: 0.9242  loss_bbox_dn_8: 0.2265  loss_giou_dn_8: 0.4244  loss_ce_interm: 198.8  loss_mask_interm: 0.908  loss_dice_interm: 0.9348  loss_bbox_interm: 0.7592  loss_giou_interm: 1.036    time: 1.1727  last_time: 1.2007  data_time: 0.0133  last_data_time: 0.0121   lr: 0.0001  max_mem: 18844M
97
./datasets/EV18/train/JPEGImages/seq13/frame097.png
103
./datasets/EV18/train/JPEGImages/seq13/frame103.png
10
./datasets/EV18/train/JPEGImages/seq3/frame010.png
19
./datasets/EV18/train/JPEGImages/seq3/frame019.png
131
./datasets/EV18/train/JPEGImages/seq13/frame131.png
141
./datasets/EV18/train/JPEGImages/seq13/frame141.png
29
./datasets/EV18/train/JPEGImages/seq16/frame029.png
31
./datasets/EV18/train/JPEGImages/seq16/frame031.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(161.5938, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5095, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7962, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
116
./datasets/EV18/train/JPEGImages/seq10/frame116.png
125
./datasets/EV18/train/JPEGImages/seq10/frame125.png
57
./datasets/EV18/train/JPEGImages/seq11/frame057.png
60
./datasets/EV18/train/JPEGImages/seq11/frame060.png
69
./datasets/EV18/train/JPEGImages/seq10/frame069.png
72
./datasets/EV18/train/JPEGImages/seq10/frame072.png
46
./datasets/EV18/train/JPEGImages/seq7/frame046.png
54
./datasets/EV18/train/JPEGImages/seq7/frame054.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(122.1768, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.2755, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.6471, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
34
./datasets/EV18/train/JPEGImages/seq4/frame034.png
35
./datasets/EV18/train/JPEGImages/seq4/frame035.png
42
./datasets/EV18/train/JPEGImages/seq12/frame042.png
51
./datasets/EV18/train/JPEGImages/seq12/frame051.png
50
./datasets/EV18/train/JPEGImages/seq4/frame050.png
58
./datasets/EV18/train/JPEGImages/seq4/frame058.png
122
./datasets/EV18/train/JPEGImages/seq6/frame122.png
125
./datasets/EV18/train/JPEGImages/seq6/frame125.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(84.7454, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.1350, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.6481, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
0
./datasets/EV18/train/JPEGImages/seq12/frame000.png
7
./datasets/EV18/train/JPEGImages/seq12/frame007.png
10
./datasets/EV18/train/JPEGImages/seq7/frame010.png
13
./datasets/EV18/train/JPEGImages/seq7/frame013.png
144
./datasets/EV18/train/JPEGImages/seq4/frame144.png
146
./datasets/EV18/train/JPEGImages/seq4/frame146.png
36
./datasets/EV18/train/JPEGImages/seq16/frame036.png
45
./datasets/EV18/train/JPEGImages/seq16/frame045.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(194.7637, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.6844, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8346, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
63
./datasets/EV18/train/JPEGImages/seq1/frame063.png
67
./datasets/EV18/train/JPEGImages/seq1/frame067.png
30
./datasets/EV18/train/JPEGImages/seq10/frame030.png
32
./datasets/EV18/train/JPEGImages/seq10/frame032.png
61
./datasets/EV18/train/JPEGImages/seq11/frame061.png
63
./datasets/EV18/train/JPEGImages/seq11/frame063.png
57
./datasets/EV18/train/JPEGImages/seq3/frame057.png
63
./datasets/EV18/train/JPEGImages/seq3/frame063.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(157.9073, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5681, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7767, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
26
./datasets/EV18/train/JPEGImages/seq4/frame026.png
27
./datasets/EV18/train/JPEGImages/seq4/frame027.png
88
./datasets/EV18/train/JPEGImages/seq14/frame088.png
90
./datasets/EV18/train/JPEGImages/seq14/frame090.png
85
./datasets/EV18/train/JPEGImages/seq3/frame085.png
88
./datasets/EV18/train/JPEGImages/seq3/frame088.png
29
./datasets/EV18/train/JPEGImages/seq11/frame029.png
32
./datasets/EV18/train/JPEGImages/seq11/frame032.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(117.1484, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5179, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7715, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
71
./datasets/EV18/train/JPEGImages/seq14/frame071.png
81
./datasets/EV18/train/JPEGImages/seq14/frame081.png
25
./datasets/EV18/train/JPEGImages/seq7/frame025.png
31
./datasets/EV18/train/JPEGImages/seq7/frame031.png
50
./datasets/EV18/train/JPEGImages/seq6/frame050.png
53
./datasets/EV18/train/JPEGImages/seq6/frame053.png
48
./datasets/EV18/train/JPEGImages/seq13/frame048.png
55
./datasets/EV18/train/JPEGImages/seq13/frame055.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(175.8999, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5941, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8322, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
108
./datasets/EV18/train/JPEGImages/seq16/frame108.png
114
./datasets/EV18/train/JPEGImages/seq16/frame114.png
18
./datasets/EV18/train/JPEGImages/seq1/frame018.png
27
./datasets/EV18/train/JPEGImages/seq1/frame027.png
1
./datasets/EV18/train/JPEGImages/seq1/frame001.png
7
./datasets/EV18/train/JPEGImages/seq1/frame007.png
118
./datasets/EV18/train/JPEGImages/seq14/frame118.png
121
./datasets/EV18/train/JPEGImages/seq14/frame121.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(139.0181, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.7950, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8653, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
0
./datasets/EV18/train/JPEGImages/seq13/frame000.png
4
./datasets/EV18/train/JPEGImages/seq13/frame004.png
68
./datasets/EV18/train/JPEGImages/seq14/frame068.png
76
./datasets/EV18/train/JPEGImages/seq14/frame076.png
64
./datasets/EV18/train/JPEGImages/seq1/frame064.png
67
./datasets/EV18/train/JPEGImages/seq1/frame067.png
59
./datasets/EV18/train/JPEGImages/seq12/frame059.png
63
./datasets/EV18/train/JPEGImages/seq12/frame063.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(159.9412, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.6783, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8413, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
34
./datasets/EV18/train/JPEGImages/seq6/frame034.png
37
./datasets/EV18/train/JPEGImages/seq6/frame037.png
119
./datasets/EV18/train/JPEGImages/seq3/frame119.png
124
./datasets/EV18/train/JPEGImages/seq3/frame124.png
129
./datasets/EV18/train/JPEGImages/seq1/frame129.png
130
./datasets/EV18/train/JPEGImages/seq1/frame130.png
112
./datasets/EV18/train/JPEGImages/seq3/frame112.png
113
./datasets/EV18/train/JPEGImages/seq3/frame113.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(155.8229, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.7909, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8442, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
0
./datasets/EV18/train/JPEGImages/seq12/frame000.png
6
./datasets/EV18/train/JPEGImages/seq12/frame006.png
68
./datasets/EV18/train/JPEGImages/seq7/frame068.png
69
./datasets/EV18/train/JPEGImages/seq7/frame069.png
48
./datasets/EV18/train/JPEGImages/seq11/frame048.png
57
./datasets/EV18/train/JPEGImages/seq11/frame057.png
32
./datasets/EV18/train/JPEGImages/seq6/frame032.png
42
./datasets/EV18/train/JPEGImages/seq6/frame042.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(244.6728, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.9746, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.9043, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
5
./datasets/EV18/train/JPEGImages/seq16/frame005.png
15
./datasets/EV18/train/JPEGImages/seq16/frame015.png
81
./datasets/EV18/train/JPEGImages/seq4/frame081.png
86
./datasets/EV18/train/JPEGImages/seq4/frame086.png
51
./datasets/EV18/train/JPEGImages/seq4/frame051.png
55
./datasets/EV18/train/JPEGImages/seq4/frame055.png
69
./datasets/EV18/train/JPEGImages/seq14/frame069.png
75
./datasets/EV18/train/JPEGImages/seq14/frame075.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(130.5563, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.4700, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7826, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
42
./datasets/EV18/train/JPEGImages/seq6/frame042.png
43
./datasets/EV18/train/JPEGImages/seq6/frame043.png
121
./datasets/EV18/train/JPEGImages/seq16/frame121.png
128
./datasets/EV18/train/JPEGImages/seq16/frame128.png
22
./datasets/EV18/train/JPEGImages/seq10/frame022.png
32
./datasets/EV18/train/JPEGImages/seq10/frame032.png
37
./datasets/EV18/train/JPEGImages/seq10/frame037.png
39
./datasets/EV18/train/JPEGImages/seq10/frame039.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(170.4833, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.6221, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8211, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
44
./datasets/EV18/train/JPEGImages/seq14/frame044.png
50
./datasets/EV18/train/JPEGImages/seq14/frame050.png
103
./datasets/EV18/train/JPEGImages/seq11/frame103.png
107
./datasets/EV18/train/JPEGImages/seq11/frame107.png
61
./datasets/EV18/train/JPEGImages/seq1/frame061.png
68
./datasets/EV18/train/JPEGImages/seq1/frame068.png
9
./datasets/EV18/train/JPEGImages/seq11/frame009.png
14
./datasets/EV18/train/JPEGImages/seq11/frame014.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(162.8248, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5842, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8150, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
62
./datasets/EV18/train/JPEGImages/seq3/frame062.png
70
./datasets/EV18/train/JPEGImages/seq3/frame070.png
68
./datasets/EV18/train/JPEGImages/seq4/frame068.png
69
./datasets/EV18/train/JPEGImages/seq4/frame069.png
62
./datasets/EV18/train/JPEGImages/seq13/frame062.png
69
./datasets/EV18/train/JPEGImages/seq13/frame069.png
64
./datasets/EV18/train/JPEGImages/seq7/frame064.png
65
./datasets/EV18/train/JPEGImages/seq7/frame065.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(144.3115, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.3222, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7374, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
13
./datasets/EV18/train/JPEGImages/seq12/frame013.png
17
./datasets/EV18/train/JPEGImages/seq12/frame017.png
109
./datasets/EV18/train/JPEGImages/seq13/frame109.png
111
./datasets/EV18/train/JPEGImages/seq13/frame111.png
44
./datasets/EV18/train/JPEGImages/seq6/frame044.png
49
./datasets/EV18/train/JPEGImages/seq6/frame049.png
102
./datasets/EV18/train/JPEGImages/seq13/frame102.png
105
./datasets/EV18/train/JPEGImages/seq13/frame105.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(189.9292, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.4520, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7839, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
125
./datasets/EV18/train/JPEGImages/seq7/frame125.png
131
./datasets/EV18/train/JPEGImages/seq7/frame131.png
64
./datasets/EV18/train/JPEGImages/seq7/frame064.png
67
./datasets/EV18/train/JPEGImages/seq7/frame067.png
109
./datasets/EV18/train/JPEGImages/seq4/frame109.png
114
./datasets/EV18/train/JPEGImages/seq4/frame114.png
1
./datasets/EV18/train/JPEGImages/seq6/frame001.png
4
./datasets/EV18/train/JPEGImages/seq6/frame004.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(122.7719, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5143, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7902, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
133
./datasets/EV18/train/JPEGImages/seq11/frame133.png
142
./datasets/EV18/train/JPEGImages/seq11/frame142.png
79
./datasets/EV18/train/JPEGImages/seq7/frame079.png
85
./datasets/EV18/train/JPEGImages/seq7/frame085.png
9
./datasets/EV18/train/JPEGImages/seq1/frame009.png
17
./datasets/EV18/train/JPEGImages/seq1/frame017.png
70
./datasets/EV18/train/JPEGImages/seq1/frame070.png
75
./datasets/EV18/train/JPEGImages/seq1/frame075.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(138.2739, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.6333, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7984, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
45
./datasets/EV18/train/JPEGImages/seq10/frame045.png
49
./datasets/EV18/train/JPEGImages/seq10/frame049.png
11
./datasets/EV18/train/JPEGImages/seq10/frame011.png
15
./datasets/EV18/train/JPEGImages/seq10/frame015.png
131
./datasets/EV18/train/JPEGImages/seq14/frame131.png
136
./datasets/EV18/train/JPEGImages/seq14/frame136.png
36
./datasets/EV18/train/JPEGImages/seq11/frame036.png
46
./datasets/EV18/train/JPEGImages/seq11/frame046.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(228.0757, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.6277, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8086, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
11
./datasets/EV18/train/JPEGImages/seq4/frame011.png
18
./datasets/EV18/train/JPEGImages/seq4/frame018.png
69
./datasets/EV18/train/JPEGImages/seq13/frame069.png
75
./datasets/EV18/train/JPEGImages/seq13/frame075.png
121
./datasets/EV18/train/JPEGImages/seq10/frame121.png
126
./datasets/EV18/train/JPEGImages/seq10/frame126.png
40
./datasets/EV18/train/JPEGImages/seq14/frame040.png
45
./datasets/EV18/train/JPEGImages/seq14/frame045.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(124.8706, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.4132, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7596, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
[05/26 01:46:57 d2.utils.events]:  eta: 3:52:30  iter: 299  total_loss: 2256  loss_ce: 226.4  loss_bbox: 1.648  loss_giou: 0.8448  loss_mask: 1.443  loss_dice: 0.9573  loss_ce_dn: 1.735  loss_mask_dn: 1.428  loss_dice_dn: 0.9585  loss_bbox_dn: 0.2256  loss_giou_dn: 0.4255  loss_ce_0: 203.5  loss_mask_0: 0.8313  loss_dice_0: 0.9387  loss_bbox_0: 1.655  loss_giou_0: 0.8442  loss_ce_dn_0: 1.037  loss_mask_dn_0: 1.159  loss_dice_dn_0: 0.947  loss_bbox_dn_0: 0.2256  loss_giou_dn_0: 0.4255  loss_ce_1: 182.6  loss_mask_1: 0.7556  loss_dice_1: 0.9491  loss_bbox_1: 1.656  loss_giou_1: 0.8442  loss_ce_dn_1: 1.073  loss_mask_dn_1: 1.063  loss_dice_dn_1: 0.9463  loss_bbox_dn_1: 0.2256  loss_giou_dn_1: 0.4255  loss_ce_2: 141  loss_mask_2: 0.8071  loss_dice_2: 0.9321  loss_bbox_2: 1.656  loss_giou_2: 0.8443  loss_ce_dn_2: 0.9989  loss_mask_dn_2: 0.9899  loss_dice_dn_2: 0.9257  loss_bbox_dn_2: 0.2256  loss_giou_dn_2: 0.4255  loss_ce_3: 221.4  loss_mask_3: 0.755  loss_dice_3: 0.9134  loss_bbox_3: 1.666  loss_giou_3: 0.8441  loss_ce_dn_3: 1.655  loss_mask_dn_3: 0.9044  loss_dice_dn_3: 0.9085  loss_bbox_dn_3: 0.2256  loss_giou_dn_3: 0.4255  loss_ce_4: 140.5  loss_mask_4: 0.8984  loss_dice_4: 0.9336  loss_bbox_4: 1.651  loss_giou_4: 0.8444  loss_ce_dn_4: 1.136  loss_mask_dn_4: 1.064  loss_dice_dn_4: 0.9253  loss_bbox_dn_4: 0.2256  loss_giou_dn_4: 0.4255  loss_ce_5: 212.5  loss_mask_5: 0.718  loss_dice_5: 0.9273  loss_bbox_5: 1.65  loss_giou_5: 0.8441  loss_ce_dn_5: 1.784  loss_mask_dn_5: 0.7674  loss_dice_dn_5: 0.9373  loss_bbox_dn_5: 0.2256  loss_giou_dn_5: 0.4255  loss_ce_6: 141.1  loss_mask_6: 0.8284  loss_dice_6: 0.9452  loss_bbox_6: 1.653  loss_giou_6: 0.8442  loss_ce_dn_6: 1.342  loss_mask_dn_6: 0.8798  loss_dice_dn_6: 0.947  loss_bbox_dn_6: 0.2256  loss_giou_dn_6: 0.4255  loss_ce_7: 234.5  loss_mask_7: 0.9183  loss_dice_7: 0.9421  loss_bbox_7: 1.651  loss_giou_7: 0.8442  loss_ce_dn_7: 1.876  loss_mask_dn_7: 0.9185  loss_dice_dn_7: 0.9457  loss_bbox_dn_7: 0.2256  loss_giou_dn_7: 0.4255  loss_ce_8: 233.7  loss_mask_8: 1.191  loss_dice_8: 0.9301  loss_bbox_8: 1.649  loss_giou_8: 0.8449  loss_ce_dn_8: 1.881  loss_mask_dn_8: 1.21  loss_dice_dn_8: 0.9285  loss_bbox_dn_8: 0.2256  loss_giou_dn_8: 0.4255  loss_ce_interm: 203.6  loss_mask_interm: 0.9469  loss_dice_interm: 0.9429  loss_bbox_interm: 0.7065  loss_giou_interm: 1.052    time: 1.1719  last_time: 1.1012  data_time: 0.0119  last_data_time: 0.0114   lr: 0.0001  max_mem: 18844M
46
./datasets/EV18/train/JPEGImages/seq16/frame046.png
48
./datasets/EV18/train/JPEGImages/seq16/frame048.png
138
./datasets/EV18/train/JPEGImages/seq13/frame138.png
148
./datasets/EV18/train/JPEGImages/seq13/frame148.png
21
./datasets/EV18/train/JPEGImages/seq3/frame021.png
28
./datasets/EV18/train/JPEGImages/seq3/frame028.png
102
./datasets/EV18/train/JPEGImages/seq12/frame102.png
112
./datasets/EV18/train/JPEGImages/seq12/frame112.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(141.4908, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.3796, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7303, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
95
./datasets/EV18/train/JPEGImages/seq14/frame095.png
98
./datasets/EV18/train/JPEGImages/seq14/frame098.png
70
./datasets/EV18/train/JPEGImages/seq3/frame070.png
79
./datasets/EV18/train/JPEGImages/seq3/frame079.png
17
./datasets/EV18/train/JPEGImages/seq7/frame017.png
25
./datasets/EV18/train/JPEGImages/seq7/frame025.png
130
./datasets/EV18/train/JPEGImages/seq10/frame130.png
140
./datasets/EV18/train/JPEGImages/seq10/frame140.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(136.5616, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.3539, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7330, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
1
./datasets/EV18/train/JPEGImages/seq12/frame001.png
8
./datasets/EV18/train/JPEGImages/seq12/frame008.png
63
./datasets/EV18/train/JPEGImages/seq16/frame063.png
67
./datasets/EV18/train/JPEGImages/seq16/frame067.png
122
./datasets/EV18/train/JPEGImages/seq1/frame122.png
129
./datasets/EV18/train/JPEGImages/seq1/frame129.png
1
./datasets/EV18/train/JPEGImages/seq6/frame001.png
6
./datasets/EV18/train/JPEGImages/seq6/frame006.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(139.1387, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.4543, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7769, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
42
./datasets/EV18/train/JPEGImages/seq16/frame042.png
44
./datasets/EV18/train/JPEGImages/seq16/frame044.png
46
./datasets/EV18/train/JPEGImages/seq12/frame046.png
55
./datasets/EV18/train/JPEGImages/seq12/frame055.png
52
./datasets/EV18/train/JPEGImages/seq11/frame052.png
58
./datasets/EV18/train/JPEGImages/seq11/frame058.png
89
./datasets/EV18/train/JPEGImages/seq6/frame089.png
94
./datasets/EV18/train/JPEGImages/seq6/frame094.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(204.1817, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.4454, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7408, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
36
./datasets/EV18/train/JPEGImages/seq12/frame036.png
40
./datasets/EV18/train/JPEGImages/seq12/frame040.png
115
./datasets/EV18/train/JPEGImages/seq3/frame115.png
121
./datasets/EV18/train/JPEGImages/seq3/frame121.png
114
./datasets/EV18/train/JPEGImages/seq13/frame114.png
123
./datasets/EV18/train/JPEGImages/seq13/frame123.png
81
./datasets/EV18/train/JPEGImages/seq1/frame081.png
89
./datasets/EV18/train/JPEGImages/seq1/frame089.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(143.9495, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.4269, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7471, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
6
./datasets/EV18/train/JPEGImages/seq12/frame006.png
8
./datasets/EV18/train/JPEGImages/seq12/frame008.png
1
./datasets/EV18/train/JPEGImages/seq16/frame001.png
3
./datasets/EV18/train/JPEGImages/seq16/frame003.png
80
./datasets/EV18/train/JPEGImages/seq7/frame080.png
85
./datasets/EV18/train/JPEGImages/seq7/frame085.png
145
./datasets/EV18/train/JPEGImages/seq6/frame145.png
148
./datasets/EV18/train/JPEGImages/seq6/frame148.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(163.3869, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.7057, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8590, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
127
./datasets/EV18/train/JPEGImages/seq4/frame127.png
129
./datasets/EV18/train/JPEGImages/seq4/frame129.png
6
./datasets/EV18/train/JPEGImages/seq3/frame006.png
8
./datasets/EV18/train/JPEGImages/seq3/frame008.png
75
./datasets/EV18/train/JPEGImages/seq12/frame075.png
83
./datasets/EV18/train/JPEGImages/seq12/frame083.png
137
./datasets/EV18/train/JPEGImages/seq4/frame137.png
143
./datasets/EV18/train/JPEGImages/seq4/frame143.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(108.8968, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.3257, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.6860, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
18
./datasets/EV18/train/JPEGImages/seq11/frame018.png
20
./datasets/EV18/train/JPEGImages/seq11/frame020.png
96
./datasets/EV18/train/JPEGImages/seq4/frame096.png
101
./datasets/EV18/train/JPEGImages/seq4/frame101.png
118
./datasets/EV18/train/JPEGImages/seq13/frame118.png
127
./datasets/EV18/train/JPEGImages/seq13/frame127.png
31
./datasets/EV18/train/JPEGImages/seq16/frame031.png
35
./datasets/EV18/train/JPEGImages/seq16/frame035.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(137.3442, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.4393, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7660, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
128
./datasets/EV18/train/JPEGImages/seq13/frame128.png
134
./datasets/EV18/train/JPEGImages/seq13/frame134.png
9
./datasets/EV18/train/JPEGImages/seq6/frame009.png
13
./datasets/EV18/train/JPEGImages/seq6/frame013.png
4
./datasets/EV18/train/JPEGImages/seq7/frame004.png
10
./datasets/EV18/train/JPEGImages/seq7/frame010.png
133
./datasets/EV18/train/JPEGImages/seq16/frame133.png
134
./datasets/EV18/train/JPEGImages/seq16/frame134.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(142.1790, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.3083, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7072, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
102
./datasets/EV18/train/JPEGImages/seq1/frame102.png
111
./datasets/EV18/train/JPEGImages/seq1/frame111.png
68
./datasets/EV18/train/JPEGImages/seq3/frame068.png
70
./datasets/EV18/train/JPEGImages/seq3/frame070.png
46
./datasets/EV18/train/JPEGImages/seq6/frame046.png
50
./datasets/EV18/train/JPEGImages/seq6/frame050.png
120
./datasets/EV18/train/JPEGImages/seq14/frame120.png
129
./datasets/EV18/train/JPEGImages/seq14/frame129.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(125.3441, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.2166, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.6488, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
123
./datasets/EV18/train/JPEGImages/seq16/frame123.png
128
./datasets/EV18/train/JPEGImages/seq16/frame128.png
22
./datasets/EV18/train/JPEGImages/seq14/frame022.png
27
./datasets/EV18/train/JPEGImages/seq14/frame027.png
53
./datasets/EV18/train/JPEGImages/seq10/frame053.png
57
./datasets/EV18/train/JPEGImages/seq10/frame057.png
138
./datasets/EV18/train/JPEGImages/seq11/frame138.png
145
./datasets/EV18/train/JPEGImages/seq11/frame145.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(158.7416, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.7038, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8308, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
62
./datasets/EV18/train/JPEGImages/seq10/frame062.png
71
./datasets/EV18/train/JPEGImages/seq10/frame071.png
122
./datasets/EV18/train/JPEGImages/seq14/frame122.png
123
./datasets/EV18/train/JPEGImages/seq14/frame123.png
131
./datasets/EV18/train/JPEGImages/seq3/frame131.png
140
./datasets/EV18/train/JPEGImages/seq3/frame140.png
126
./datasets/EV18/train/JPEGImages/seq7/frame126.png
127
./datasets/EV18/train/JPEGImages/seq7/frame127.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(200.4389, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.4799, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7724, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
50
./datasets/EV18/train/JPEGImages/seq4/frame050.png
56
./datasets/EV18/train/JPEGImages/seq4/frame056.png
40
./datasets/EV18/train/JPEGImages/seq1/frame040.png
44
./datasets/EV18/train/JPEGImages/seq1/frame044.png
19
./datasets/EV18/train/JPEGImages/seq1/frame019.png
27
./datasets/EV18/train/JPEGImages/seq1/frame027.png
59
./datasets/EV18/train/JPEGImages/seq10/frame059.png
67
./datasets/EV18/train/JPEGImages/seq10/frame067.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(102.1695, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.4577, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7656, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
125
./datasets/EV18/train/JPEGImages/seq4/frame125.png
129
./datasets/EV18/train/JPEGImages/seq4/frame129.png
65
./datasets/EV18/train/JPEGImages/seq11/frame065.png
75
./datasets/EV18/train/JPEGImages/seq11/frame075.png
127
./datasets/EV18/train/JPEGImages/seq12/frame127.png
132
./datasets/EV18/train/JPEGImages/seq12/frame132.png
64
./datasets/EV18/train/JPEGImages/seq1/frame064.png
68
./datasets/EV18/train/JPEGImages/seq1/frame068.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(175.5494, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.8174, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8388, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
137
./datasets/EV18/train/JPEGImages/seq11/frame137.png
142
./datasets/EV18/train/JPEGImages/seq11/frame142.png
41
./datasets/EV18/train/JPEGImages/seq12/frame041.png
51
./datasets/EV18/train/JPEGImages/seq12/frame051.png
112
./datasets/EV18/train/JPEGImages/seq13/frame112.png
121
./datasets/EV18/train/JPEGImages/seq13/frame121.png
123
./datasets/EV18/train/JPEGImages/seq16/frame123.png
130
./datasets/EV18/train/JPEGImages/seq16/frame130.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(167.8849, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.3983, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7439, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
125
./datasets/EV18/train/JPEGImages/seq16/frame125.png
133
./datasets/EV18/train/JPEGImages/seq16/frame133.png
14
./datasets/EV18/train/JPEGImages/seq13/frame014.png
15
./datasets/EV18/train/JPEGImages/seq13/frame015.png
122
./datasets/EV18/train/JPEGImages/seq1/frame122.png
125
./datasets/EV18/train/JPEGImages/seq1/frame125.png
66
./datasets/EV18/train/JPEGImages/seq12/frame066.png
67
./datasets/EV18/train/JPEGImages/seq12/frame067.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(181.2342, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5635, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8027, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
132
./datasets/EV18/train/JPEGImages/seq10/frame132.png
138
./datasets/EV18/train/JPEGImages/seq10/frame138.png
17
./datasets/EV18/train/JPEGImages/seq6/frame017.png
19
./datasets/EV18/train/JPEGImages/seq6/frame019.png
137
./datasets/EV18/train/JPEGImages/seq12/frame137.png
141
./datasets/EV18/train/JPEGImages/seq12/frame141.png
15
./datasets/EV18/train/JPEGImages/seq7/frame015.png
16
./datasets/EV18/train/JPEGImages/seq7/frame016.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(114.1444, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.3079, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.6894, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
142
./datasets/EV18/train/JPEGImages/seq10/frame142.png
144
./datasets/EV18/train/JPEGImages/seq10/frame144.png
131
./datasets/EV18/train/JPEGImages/seq6/frame131.png
137
./datasets/EV18/train/JPEGImages/seq6/frame137.png
14
./datasets/EV18/train/JPEGImages/seq4/frame014.png
19
./datasets/EV18/train/JPEGImages/seq4/frame019.png
139
./datasets/EV18/train/JPEGImages/seq16/frame139.png
143
./datasets/EV18/train/JPEGImages/seq16/frame143.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(112.5263, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.3927, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7328, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
15
./datasets/EV18/train/JPEGImages/seq13/frame015.png
17
./datasets/EV18/train/JPEGImages/seq13/frame017.png
81
./datasets/EV18/train/JPEGImages/seq14/frame081.png
85
./datasets/EV18/train/JPEGImages/seq14/frame085.png
109
./datasets/EV18/train/JPEGImages/seq11/frame109.png
111
./datasets/EV18/train/JPEGImages/seq11/frame111.png
56
./datasets/EV18/train/JPEGImages/seq3/frame056.png
65
./datasets/EV18/train/JPEGImages/seq3/frame065.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(125.3118, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.3933, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7242, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
4
./datasets/EV18/train/JPEGImages/seq14/frame004.png
6
./datasets/EV18/train/JPEGImages/seq14/frame006.png
52
./datasets/EV18/train/JPEGImages/seq3/frame052.png
62
./datasets/EV18/train/JPEGImages/seq3/frame062.png
7
./datasets/EV18/train/JPEGImages/seq7/frame007.png
8
./datasets/EV18/train/JPEGImages/seq7/frame008.png
56
./datasets/EV18/train/JPEGImages/seq7/frame056.png
61
./datasets/EV18/train/JPEGImages/seq7/frame061.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(200.6135, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.6167, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8126, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
[05/26 01:47:21 d2.utils.events]:  eta: 3:52:05  iter: 319  total_loss: 2317  loss_ce: 231.5  loss_bbox: 1.611  loss_giou: 0.8255  loss_mask: 1.539  loss_dice: 0.9416  loss_ce_dn: 1.655  loss_mask_dn: 1.533  loss_dice_dn: 0.9479  loss_bbox_dn: 0.2393  loss_giou_dn: 0.4264  loss_ce_0: 220.7  loss_mask_0: 0.8446  loss_dice_0: 0.924  loss_bbox_0: 1.627  loss_giou_0: 0.8258  loss_ce_dn_0: 1.076  loss_mask_dn_0: 1.14  loss_dice_dn_0: 0.9213  loss_bbox_dn_0: 0.2393  loss_giou_dn_0: 0.4264  loss_ce_1: 190.1  loss_mask_1: 0.7663  loss_dice_1: 0.9305  loss_bbox_1: 1.627  loss_giou_1: 0.8258  loss_ce_dn_1: 1.107  loss_mask_dn_1: 1.095  loss_dice_dn_1: 0.9246  loss_bbox_dn_1: 0.2393  loss_giou_dn_1: 0.4264  loss_ce_2: 155.1  loss_mask_2: 0.7954  loss_dice_2: 0.9047  loss_bbox_2: 1.615  loss_giou_2: 0.8259  loss_ce_dn_2: 1.042  loss_mask_dn_2: 0.9741  loss_dice_dn_2: 0.903  loss_bbox_dn_2: 0.2393  loss_giou_dn_2: 0.4264  loss_ce_3: 231.1  loss_mask_3: 0.7482  loss_dice_3: 0.9025  loss_bbox_3: 1.628  loss_giou_3: 0.8258  loss_ce_dn_3: 1.621  loss_mask_dn_3: 0.8784  loss_dice_dn_3: 0.8985  loss_bbox_dn_3: 0.2393  loss_giou_dn_3: 0.4264  loss_ce_4: 148.5  loss_mask_4: 0.9066  loss_dice_4: 0.9003  loss_bbox_4: 1.621  loss_giou_4: 0.8259  loss_ce_dn_4: 1.145  loss_mask_dn_4: 1.063  loss_dice_dn_4: 0.9147  loss_bbox_dn_4: 0.2393  loss_giou_dn_4: 0.4264  loss_ce_5: 227.8  loss_mask_5: 0.7234  loss_dice_5: 0.904  loss_bbox_5: 1.612  loss_giou_5: 0.8255  loss_ce_dn_5: 1.92  loss_mask_dn_5: 0.7627  loss_dice_dn_5: 0.9167  loss_bbox_dn_5: 0.2393  loss_giou_dn_5: 0.4264  loss_ce_6: 145.3  loss_mask_6: 0.8333  loss_dice_6: 0.9215  loss_bbox_6: 1.614  loss_giou_6: 0.8258  loss_ce_dn_6: 1.258  loss_mask_dn_6: 0.8939  loss_dice_dn_6: 0.9255  loss_bbox_dn_6: 0.2393  loss_giou_dn_6: 0.4264  loss_ce_7: 235.8  loss_mask_7: 0.9514  loss_dice_7: 0.9249  loss_bbox_7: 1.623  loss_giou_7: 0.8257  loss_ce_dn_7: 1.819  loss_mask_dn_7: 0.9823  loss_dice_dn_7: 0.9203  loss_bbox_dn_7: 0.2393  loss_giou_dn_7: 0.4264  loss_ce_8: 240.7  loss_mask_8: 1.214  loss_dice_8: 0.9161  loss_bbox_8: 1.614  loss_giou_8: 0.8259  loss_ce_dn_8: 1.931  loss_mask_dn_8: 1.239  loss_dice_dn_8: 0.912  loss_bbox_dn_8: 0.2393  loss_giou_dn_8: 0.4264  loss_ce_interm: 220.8  loss_mask_interm: 0.9716  loss_dice_interm: 0.9269  loss_bbox_interm: 0.7796  loss_giou_interm: 1.038    time: 1.1715  last_time: 1.1952  data_time: 0.0117  last_data_time: 0.0114   lr: 0.0001  max_mem: 18844M
119
./datasets/EV18/train/JPEGImages/seq14/frame119.png
124
./datasets/EV18/train/JPEGImages/seq14/frame124.png
93
./datasets/EV18/train/JPEGImages/seq6/frame093.png
95
./datasets/EV18/train/JPEGImages/seq6/frame095.png
52
./datasets/EV18/train/JPEGImages/seq14/frame052.png
58
./datasets/EV18/train/JPEGImages/seq14/frame058.png
58
./datasets/EV18/train/JPEGImages/seq13/frame058.png
65
./datasets/EV18/train/JPEGImages/seq13/frame065.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(121.3173, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.3793, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7449, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
116
./datasets/EV18/train/JPEGImages/seq6/frame116.png
126
./datasets/EV18/train/JPEGImages/seq6/frame126.png
131
./datasets/EV18/train/JPEGImages/seq16/frame131.png
140
./datasets/EV18/train/JPEGImages/seq16/frame140.png
1
./datasets/EV18/train/JPEGImages/seq12/frame001.png
3
./datasets/EV18/train/JPEGImages/seq12/frame003.png
81
./datasets/EV18/train/JPEGImages/seq11/frame081.png
86
./datasets/EV18/train/JPEGImages/seq11/frame086.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(174.0528, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.4230, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7889, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
100
./datasets/EV18/train/JPEGImages/seq10/frame100.png
107
./datasets/EV18/train/JPEGImages/seq10/frame107.png
81
./datasets/EV18/train/JPEGImages/seq4/frame081.png
85
./datasets/EV18/train/JPEGImages/seq4/frame085.png
0
./datasets/EV18/train/JPEGImages/seq3/frame000.png
7
./datasets/EV18/train/JPEGImages/seq3/frame007.png
84
./datasets/EV18/train/JPEGImages/seq7/frame084.png
89
./datasets/EV18/train/JPEGImages/seq7/frame089.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(162.5800, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.6200, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8104, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
104
./datasets/EV18/train/JPEGImages/seq1/frame104.png
108
./datasets/EV18/train/JPEGImages/seq1/frame108.png
20
./datasets/EV18/train/JPEGImages/seq7/frame020.png
21
./datasets/EV18/train/JPEGImages/seq7/frame021.png
135
./datasets/EV18/train/JPEGImages/seq10/frame135.png
140
./datasets/EV18/train/JPEGImages/seq10/frame140.png
96
./datasets/EV18/train/JPEGImages/seq3/frame096.png
99
./datasets/EV18/train/JPEGImages/seq3/frame099.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(110.2415, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.5786, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7654, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
9
./datasets/EV18/train/JPEGImages/seq11/frame009.png
10
./datasets/EV18/train/JPEGImages/seq11/frame010.png
57
./datasets/EV18/train/JPEGImages/seq3/frame057.png
65
./datasets/EV18/train/JPEGImages/seq3/frame065.png
7
./datasets/EV18/train/JPEGImages/seq12/frame007.png
11
./datasets/EV18/train/JPEGImages/seq12/frame011.png
46
./datasets/EV18/train/JPEGImages/seq4/frame046.png
52
./datasets/EV18/train/JPEGImages/seq4/frame052.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(117.3767, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.2768, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.6729, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
142
./datasets/EV18/train/JPEGImages/seq13/frame142.png
145
./datasets/EV18/train/JPEGImages/seq13/frame145.png
108
./datasets/EV18/train/JPEGImages/seq14/frame108.png
114
./datasets/EV18/train/JPEGImages/seq14/frame114.png
81
./datasets/EV18/train/JPEGImages/seq3/frame081.png
86
./datasets/EV18/train/JPEGImages/seq3/frame086.png
44
./datasets/EV18/train/JPEGImages/seq7/frame044.png
53
./datasets/EV18/train/JPEGImages/seq7/frame053.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(123.3056, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.3675, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7510, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
60
./datasets/EV18/train/JPEGImages/seq13/frame060.png
63
./datasets/EV18/train/JPEGImages/seq13/frame063.png
83
./datasets/EV18/train/JPEGImages/seq10/frame083.png
85
./datasets/EV18/train/JPEGImages/seq10/frame085.png
50
./datasets/EV18/train/JPEGImages/seq16/frame050.png
55
./datasets/EV18/train/JPEGImages/seq16/frame055.png
54
./datasets/EV18/train/JPEGImages/seq11/frame054.png
61
./datasets/EV18/train/JPEGImages/seq11/frame061.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(164.6770, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.4807, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.7769, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
96
./datasets/EV18/train/JPEGImages/seq4/frame096.png
98
./datasets/EV18/train/JPEGImages/seq4/frame098.png
76
./datasets/EV18/train/JPEGImages/seq6/frame076.png
79
./datasets/EV18/train/JPEGImages/seq6/frame079.png
77
./datasets/EV18/train/JPEGImages/seq1/frame077.png
84
./datasets/EV18/train/JPEGImages/seq1/frame084.png
23
./datasets/EV18/train/JPEGImages/seq1/frame023.png
27
./datasets/EV18/train/JPEGImages/seq1/frame027.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 399, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
loss computed: boxes
losses: {'loss_ce': tensor(123.6356, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(1.6961, device='cuda:0', grad_fn=<DivBackward0>), 'loss_giou': tensor(0.8395, device='cuda:0', grad_fn=<DivBackward0>)}
training iteration 1
46
./datasets/EV18/train/JPEGImages/seq6/frame046.png
47
./datasets/EV18/train/JPEGImages/seq6/frame047.png
112
./datasets/EV18/train/JPEGImages/seq13/frame112.png
116
./datasets/EV18/train/JPEGImages/seq13/frame116.png
47
./datasets/EV18/train/JPEGImages/seq16/frame047.png
54
./datasets/EV18/train/JPEGImages/seq16/frame054.png
79
./datasets/EV18/train/JPEGImages/seq3/frame079.png
86
./datasets/EV18/train/JPEGImages/seq3/frame086.png

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9

 dec_layers = 9, Each produces 300 queries: 9x300x256
torch.Size([4, 400, 256])
9
inside criteria
inside criteria
['labels', 'boxes']
loss computed: labels
